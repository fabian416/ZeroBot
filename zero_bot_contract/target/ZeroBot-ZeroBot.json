{"transpiled":true,"noir_version":"1.0.0-beta.5+0000000000000000000000000000000000000000","name":"ZeroBot","functions":[{"name":"constructor","is_unconstrained":true,"custom_attributes":["public","initializer"],"abi":{"parameters":[],"return_type":null,"error_types":{"2233873454491509486":{"error_kind":"string","string":"Initializer address is not the contract deployer"},"5019202896831570965":{"error_kind":"string","string":"attempt to add with overflow"},"14225679739041873922":{"error_kind":"string","string":"Index out of bounds"},"17618083556256589634":{"error_kind":"string","string":"Initialization hash does not match"},"17843811134343075018":{"error_kind":"string","string":"Stack too deep"}}},"bytecode":"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","debug_symbols":"tZnbbuM4DIbfJde90ImU2FcZDAaZTjoIEKRFpl1gUfTdl7RIOp2FhKy7cxN/pq3fFEVTkvO2+3H4/vrz2/H8+PRrd//lbff9cjydjj+/nZ4e9i/HpzNb33ZBfoh/y92OYHdf+UDLIYaiRz2Peh71POHuvvExFz22fixZj3oOSY+1H5HPYxCoChUUWjBgzZgFmgJlA7WkkA3MEkWHO5JSNqgKORmgQokGYkEGKAakgKJDAlWhJgOzNLM0s0gcE/cii4cd+FJKDDEZiIUfkVM0QIVslmyWwo5l0SmkAGaBpiCudjBLNUs1i7jaARUoGkCHEoKBPAIEmkLMBmZJZklmkTh3QAWJcwdQgGAgj+AOFkmADqTQ7FIzC5mF1AIS3g5VQcLbARUkvB30EZCDgQgWgaYgmduhKkA0QAUMBtYcSWHpxQJmaXZPM4ukca4CtQOGpBDNsvjDiYSFL5UgUBUAFMSNDvyIEgVIQca9Q1Vo0QAM7Gay5qSWGrKBNq8xGoCB3Zzs5mQ3S/aWJEAKEtWSBZqCBHMBlJtBQCxcHGplCwQBtoAIivMdSEF8BmklPgO3apKrQAKkEM0iuYrcqiUOJiaBqpBBoQSDYiCt2MMmUUUeuCZR7VAVxLEOoEB6D4VowL1AdpUkMzuQQioKkpAdQKGYZfEHpTIng6qAoFCDgd0s7/sCzVrJa45LaccOMch7rlScmtHibidvkaKT27KrZFfJriL5i22hZiQZ3ElSWAmNZPiVyKhpVJmqEUUns8Ul1jJ5LNMIkkxRMhA1LAROZLTMaJ3YvxqFJKOVqpEUNSW3FbcVt4HbwG3oeug26aUSOJFR8xbNW1CyHskI1iTT7eJ9p6b9yIv3ndy2eN9J2uZlyo5ObpOyXMtC4ERG6Mpo8cvyjnZq0akakT+XzFZ8PIqPR/HxWCaYTmlp+/5+t7PVyreXy+Egi5Wr5Qsvap73l8P5ZXd/fj2d7nZ/7U+vy02/nvfn5fiyv/BV1jycf/CRBR+Pp4PQ+93aOoyb8ihIrVmaxxziKkH4QSNONIDQJDDiqpA/KKSxQqFQVaHQlQLGDwp5rMC1ralCK1hGCrNeoExK2ouWRr2AsQK/KlEV+F3JrsA58EECJ060kM2JBmOJm73AocTNoaBRKGisUNG6wTOdty/pZg946jUPaq0jD+JEIvMaViVyLmEch0lecuFMFstUxsNxux9503hcR6OVYTTgDw5IK2FNzOE7HutYghei5gOUkIavaJt4wfOrV6vAZWcoMvOjlNUPaNskZGtlEjSSSJOAIllm1bCOaEq3J0XDdURaHFbdSdEEXq9bNzCOu1EmeUWe3bxMjaPZI8H/MaizYMS0BmP4hqTJmPLkZzMIrz3GEm0WDPRJiNeY66i23wJKs7ek2mTKL8w6JrwnvtmPtnalcXCHfuRJRGst5BXjakz+pTEpnxlsUMrVpM6r1o8KeVaAySczXtmONSYpCok8oGGbAlmOY4Rt/Uh57UdJ2zRqtMxIddaT9mc1Iq6FB2vbplHrOqNR2qZBwVcplMYa07LhI8tf4PJwVps5QVa7+LnDKlxm2ZV96Qq8D1n7gTd7wR8Lg3tR2tCLycoTQjMJxuGsWCYVtEG0WLTrV+32Mp7WwsU72jDsx6R+EliC82eBLbHkES2rD8MRne2pcszN91T8yo1mRZjUTqgmgWHoBORP76mgfHpTNesGRssqzOM91SQvS00+idRShz5M8pIwe04gDlN7Wnuz78u4kseNc0Aj1wjjeoWz1AoeDf4gBNs0ohcL/tOjbdRA94P3A9s08lp8M230A5L3Ba6y479poM8j0GhjX9a5iL9NbdQoxTVg3JeJRC2+qSi4RYCKVXCCtkXg1gSd+eB1i9K2TnhuUoVPRuF3ga98un84Xj78zfguUpfj/vvpoKePr+eHq6svfz/bFfub8vny9HD48Xo5iNL6XyX/fOHPoXc8hXyV779yyimeEsgpf178wpsTvopf38WZfwA=","brillig_names":["constructor"]},{"name":"public_dispatch","is_unconstrained":true,"custom_attributes":["public"],"abi":{"parameters":[{"name":"selector","type":{"kind":"field"},"visibility":"private"}],"return_type":null,"error_types":{"2233873454491509486":{"error_kind":"string","string":"Initializer address is not the contract deployer"},"2830029349304997821":{"error_kind":"fmtstring","length":27,"item_types":[{"kind":"field"}]},"5019202896831570965":{"error_kind":"string","string":"attempt to add with overflow"},"14225679739041873922":{"error_kind":"string","string":"Index out of bounds"},"17618083556256589634":{"error_kind":"string","string":"Initialization hash does not match"},"17843811134343075018":{"error_kind":"string","string":"Stack too deep"}}},"bytecode":"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","debug_symbols":"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","brillig_names":["public_dispatch"]},{"name":"sync_private_state","is_unconstrained":true,"custom_attributes":["utility"],"abi":{"parameters":[],"return_type":null,"error_types":{"576755928210959028":{"error_kind":"string","string":"0 has a square root; you cannot claim it is not square"},"2709101749560550278":{"error_kind":"string","string":"Cannot serialize point at infinity as bytes."},"2896122431943215824":{"error_kind":"fmtstring","length":144,"item_types":[{"kind":"integer","sign":"unsigned","width":32}]},"2920182694213909827":{"error_kind":"string","string":"attempt to subtract with overflow"},"3305101268118424981":{"error_kind":"string","string":"Attempted to delete past the length of a CapsuleArray"},"3367683922240523006":{"error_kind":"fmtstring","length":58,"item_types":[{"kind":"field"}]},"5019202896831570965":{"error_kind":"string","string":"attempt to add with overflow"},"5727012404371710682":{"error_kind":"string","string":"push out of bounds"},"5870202753060865374":{"error_kind":"fmtstring","length":61,"item_types":[{"kind":"field"},{"kind":"field"}]},"6336853191198150230":{"error_kind":"fmtstring","length":77,"item_types":[{"kind":"integer","sign":"unsigned","width":32}]},"6485997221020871071":{"error_kind":"string","string":"call to assert_max_bit_size"},"6753155520859132764":{"error_kind":"string","string":"Failed to deliver note"},"7233212735005103307":{"error_kind":"string","string":"attempt to multiply with overflow"},"8270195893599566439":{"error_kind":"string","string":"Invalid public keys hint for address"},"8830323656616886390":{"error_kind":"string","string":"Got a public log emitted by a different contract"},"12099279057757775880":{"error_kind":"string","string":"DST_LEN too large for offset"},"12822839658937144934":{"error_kind":"fmtstring","length":75,"item_types":[]},"13649294680379557736":{"error_kind":"string","string":"extend_from_bounded_vec out of bounds"},"14225679739041873922":{"error_kind":"string","string":"Index out of bounds"},"14514982005979867414":{"error_kind":"string","string":"attempt to bit-shift with overflow"},"14657895983200220173":{"error_kind":"string","string":"Attempted to read past the length of a CapsuleArray"},"15366650908120444287":{"error_kind":"fmtstring","length":48,"item_types":[{"kind":"field"},{"kind":"field"}]},"16218014537381711836":{"error_kind":"string","string":"Value does not fit in field"},"16446004518090376065":{"error_kind":"string","string":"Input length must be a multiple of 32"},"16954218183513903507":{"error_kind":"string","string":"Attempted to read past end of BoundedVec"},"17843811134343075018":{"error_kind":"string","string":"Stack too deep"},"17879506016437779469":{"error_kind":"fmtstring","length":128,"item_types":[{"kind":"integer","sign":"unsigned","width":32}]},"18194595712952743247":{"error_kind":"fmtstring","length":98,"item_types":[{"kind":"integer","sign":"unsigned","width":32},{"kind":"integer","sign":"unsigned","width":32},{"kind":"field"}]}}},"bytecode":"H4sIAAAAAAAA/+29CZBcx3Ut+Aq9AF1AowsAsS+sJiRSlEipll5tfRmSSMkWKVorJVlrdVcVRJHiAoDgTrxGY+FOkBIp2ZJlW4stL7JlS5Zsy/I64/D8P+MfmvC3/xL22J6w53vmx9gR8/0jHDOeGTywbtWpU/fle6/rZneJ6IwA+tXLzHNv3rx58+byMnNBJ+Raf4eDPoKAfHTypb9jrd8bIH7o4r8jrd+l/kJ5jOha4s+V5ufGlPIZ8l8da2Hm/OCXBN+T/EsbWzifDTv4WBahu+niv83wfG/Q0Q9f5Zf681n+HY4yi+68OQzaoUO3XJ2bqVbmZiqVeqNUq8/MNuers6XqwnR1fnGhXKpOV+bqs7VqqdSoNhanSvWZ+el6ozY/XW0u1OZnBPsGFbvaWLgINV2bmVsoN2szzdLC1Oxctdacna3X6vNTjdnpUr28OFNerJSbc3O16ena4vR8udxszE8359rYN4ZeZFYR/Lf4wW/bhLd6wa9OC/4PA/5wYNtmo/AjfvDb8nmbH/x2/d7Uwg88yObm0Efdltv4b/eCX5oS/Fv84FcF/0cBP+dBd97hB7/N/zv94Ld1811+5N8U/He38APALs9VK5XZ6vzsxX6pXipP1Rcrcxet/8JUabFUW6w05qfK882pylR1sb64MDc1Vys3S83a4nxz7iVwwX6PF96rbd18rxfZV9v9yq2KbEr9hbZNfl889orFL9jvV7Artepiab5Zqk3P1WYbc9MXu+vSxYeFuUZzplJbuNhxV+rlcrkxdfG/SqM+Nb9QnykvzDRmK9MLF8m16/QDoY86LS8K/o8Z48/USvONmZlZwf+gMf7Cwsxs7aI8Bf9DxvjVxZlGszrbtgcfNsavTU81m9PVmuB/xBh/ulxqTFdm27r5UWP8+YXS9MzcXFt/PmaMf9HvrNbnawuCX7OWz0KjtFgvz4+3cBZa+EIjCkJ70Zh2K8zniF7Qwud3Qj9PvFr7xTmih/ygfGT8IrKrh728FpQ4tDEcN6S8Ezoa1gcNsT5kiPVhQ6yPGGJ91BDrY4ZY0q79trWpdj9a94Jfbc8DNbzglxqC3/SBX+74jkcBP7Djv43/ccDPecC/zY/82/if8COf9rjp9ha+D+w7/Mim7YN90g9+e1xwpx/8to96lx/8tm242w/+vODf4we/7aMe84Pf9vGO+8Fv+6gn/ODXBf9eL/jltnxOAr6d7ay0bdt9XvCrbfz7/eC37dsDXvCn2vgP+sFvz6s85Ae/bZ8f9oPfts+P+MFv+z6PesGfbo+RT3nBn2nrT+gHvz1HseQHvz3netoPflv/l/3gt/X/jB/8tv6f9YPf9k/O+cFv+yfn/eC3/ZPH/OC3+8fH/eC3/Ycn/OC3/Ycn/eC37edTfvDb9vNpL/izbf/hGT/4bfv5rB/8tv284Ae/bT+f84Pftp/P+8Fv289P+cFv27dP+8Fv27cX/OC37duLfvDb9uczLfxg5dhVfhHt6Yn28/zD9pfwtlz8t7WFfbRx4k133LV4+y33fnKhcQxnvKWEAfyV56GgN0So2zuob77rzhPHaosn3livH2scP84IGxTkIAY1D6gfr91254/U4/jJiHZr49jx2+66k9GGU6LJvqURSG/oE5fGW3ijxB/S3khSsKFdrms1z1JG+nni1Xh8X84RPeGH5YPrIlHcJoXXghLHdbhJobNJoVNQ4tiH7gfrGUOsM4ZYTxliWZbxCUOs84ZYTxpinTXEOmmIZSl7yzb07IBinTLEstQJS9lb6tdpQyzLtm2pE0uGWJY2+nlDrEHtH2Vs4te3Ks2NK7QlSBx+M4E+FQf2xJHvCP+ftndwOZ2EyCueaD03GycWP/6e2tGjjfrNdx09HjiyRUG2zfP7QRMhu4X5FGUIgmTxju3o4HI65gercYziNip5cwqWNtBhlUaZj8bwgBhSV+gOGw4lqmnKgfRXayihmQptKCHyGfMjn0qO8JGfMUU+rMNcd9E/+YxnBLAwPX7yhenxWfLju3/f+lsIetuRfEqQU+KGlHci30jm/zOVDeuG9dRPPUyV0+qp0M8HPttNR081vdC6tLGgt54tt2+lqVfNtm1W4gRrS+s36immz0MZMT0+S35893etv4WgV6dZTzcr5cF3qKd/1XoeiynPkdbvUl9hdlbrp7gdoJwst6OnbQdCPx/41LtOO9DqSbMnIrstCq8FJY6nfrYodLYodApKHLuj/WA9ZYi1ZIi1bIj17IBinTfEetIQ66wh1klDrMcNsSz1fhDl5eoHs2JFwVJXLxhinTPEstRVyzKeMsQa1Lb9giHWfYZYshTLfqbgR2Es6G171mM3pCflwHdIP0+82vLT8ZU0uWo+rchn3I982vyMK/yMK/KRutyqxAmWTFXhmAHTj0MZMT0+S358V2pVWIEwo8Bjhq1KefAdjhlenesuG9YN66nPekB6wje+Q/r5wGe7KTn1Qmv/Y0FvPRvKp5SmXpFfqcsJJU6w5FMr1FNMvxXKiOnxWfLjuzeQnqJOs55OKOXBd6inc6SnWDesp17qodxMradCPx/4bDcdPdX0YlyR41jQW8+G8imlqVfkV+qyoMQJ1rbWb9RTTD8BZcT0+Cz58d3NpKeo0/wJWkEpD75DPX1LC3cspjxHWr9LfYXpKa0u7fBny+NKObmdoazt9Lqaup0J/XzQqxc+2tk24idOD0R22xVeC0oc68h2hc52hU5BieNxTT9Yy4ZYJw2xlgyxHjfEOmWIdd4Q6wlDLEudOG2I9agh1rNGWJp97oevZ4z4isIFQyzLtv2CIZalLbRsj08aYlnW44uGWJY6YSl7q7YdGJfRUieeMsQaVDthydfl4DOt92lrJ3vL9njGEMuyjJ8aUL4s/QnLMkpfK2NFHFvmWn/Hgt62ZzjObuSInpQD3yH9PPFqy09nnK3JdZsiV5HdDoXXghLH4+wdCp0dCp2CEsd9Rj9Yy4ZYJw2xLMt43hDrSUOsC4ZYlrJ/wRBrvR6zYb1oiGWpE6cNsZ4yxLK0X88aYlnK3lJXLWU/qPbLUlct9esJQyzLerTUL8s2ZKlfzxhinTLEsizjoPpylmW09CcGtR4H1Zf7lCHWoPo5lj7muj/x8mhDlnbCki8r/YqeeV61H76eM+IrCpayt/QBpK/l/W6CHwW/c2iV1HtseQ7Nyx6shDk0bW/dWNCrh4byKaepZ+RX6vIKJU6wdrZ+454wTL8Dyojp8Vny47sjLaEUCDMKvCfsCqU8+E7kG+0J+4HWj7GY8hxp/S71F+Z4PlRoIG2Uk6HepbqqAunnA59612kHWj1p9kVkt1PhtRD06g7rw06Fzk6FzjrWYGH9qBGWy4ZJfBTGlHzW9hbpSTnwHdLPB17tQtklV81einx2+ZFPe4/yLoWfXYp8pC53K3GCtaf1G/sjTL8Lyojp8Vny47s69Ue7IS23gd1KefAd9kcf2dBdNqwb1lM/9ZD+mw+hnw98tpuOnmp6obX/saC3ng3lU0pTr8iv1OUeJU6w9rZ+o55i+t1QRkyPz5If3x0jPUWdZj3do5QH36Ge3tH6MRHEt8807RlxNbvNMsR83B681He5UUrbHoR+PvDZPjvtYXdKuYp89niRT72ZRn+QX6nLvUqcYO1r/cb2gOn3QBkxPT5Lfny3TO0B2w63h71KefAdtodHyG5j3bCeeqmHUqmZVk+Ffj7waSc7eqrphdb/jQW99WzITyNNvSK/Upf7lDjB2t/6jXqK6fdCGTE9Pkt+fPcc6SnqNH+rt08pD75DPX2SxrtcniOt36W+QqOs1aUdfq199f0+L/iV+TGlvuzwF9pX1x/wgz8j+Ae94M+16/eQF/zptnyu9INfF/yiH/1p8z/pBb9aFfyrvOA32vwf9oI/1cZ/hRf8hXb7faUX/Pm2/l/tRz7t+r3GC35zWvBf5Uc+bf6v9cN/2/6/BvAt5yIE/3ov+KWqyOO6oBOGlDIJffFFXg3pczF/BYvjhFaesHz5fVrZkH8e910H/KAM4rCuy4g1psT5qNPXOMqN9McdvHI5onBfaCOTKJw2xHrEEOsZIyzNt+2Hr/sN+dprxJfm//aDtd8Qa8QIKwp8tWI/fB0w4it6PjigWIcMsa40xCoaYk0aYl1liHXYCCsKnw7t+HqFIV9PG/L1SiO+ouerDbGs+o7o+RpDrFcZYl1rhBUFnjsdFCxZQ/Y73zU173e+q1rzO981Vfc73zVd9TvfNTXrd75ralF8dekPhQbqVhHe240rplJ/Cyr088SrLT+d8V2R+GH58P6dSYXXghLHbXRSoTOp0CkocbyXtx+s5w2xThliPW6Idd4Q67Qh1klDrCcMsZYNsZ4dUCxLXT1riGUl++iZ++1B0VXL9njBEGtQ2+NzhliWbWhQZX/OEMvSTlj2tZY22lL2lvIaVP2y9E0s69FS9peDnXjBCCt65jFsP3w9ZMjXfiO+LLGi8EBox9cBQ76sZB+FRw2xLHWC59L7wRoxwoqClU5E4RFDrAcNsSz1y5IvK10dZFu41ZAvS121rEdLuzqo8rLUVZ5bHQRdjYKl/XrREMvS/zpjiGU5p2Dpk1uOFSznHsW/l3nsQxCXa/31uwZQWvEawCE//DjXAA4pctX2wxryU09Tz8iv1OVVSpxgHW79xr39mH4Syojp8Vny47svtiquQJhR4L39VynlwXci32hv/+eHustWhHSsp37qIf0dsEI/H3htN2WXXhQVOWp6IXkLShz79GnrS6t73vvWD9ZThlhLhljLhljPDijWeUOsJw2xzhpinTTEetoQy7INWdbj84ZYpwyxLhhiWbZtS/2ybEOWdvVykP0ThliWNlpsofYdlaH/UdK+czLEb39zcNghC6TPe3EkXvsrWBwntPKEZVy2sqtsyD/XM/rhKIM4rMMZsbRv43zU6VWOciN9v98CTlf8fgs4PeP3W8Cppuj8K0GeOZLdNV7qci71WSpCP0+8+mpT1xA/LB8eD71K4bWgxPHevVcpdF6l0Ckocdxv94P1vCHWKUOsxw2xzhtinTbEOmmI9bQh1jOGWJayH1RdvWCItWyIZalfljbnKUOsy0H2TxhiWZbx2QHFsmzbZw2xrGQfPfO+3EHR1UH1ASyx1vvt9X77+6XvWO+31/vt9X775Sn7QdXV5wyxLOVlaXMsZX/OEMuyDVn224NqowfVn7Aso6Xva1mPlrK/HOzEC0ZY0TPvz+kH6ypDLKt58uj5sBFWFHjvcT98bTXk6yEjvqLwqCHWI0ZY0TOvf63L3l1G/naiH6z9hlgHjLCiYCmvq434stTVKFi2oUHV+0Et48vdFlryFYX1vuP7v++IwsNGWNGz5Z4HK3lFzwcN+XrQkC+rvjYKlv2jpbwGse+IwouGWJZjvjOGWJZrOpbzAJbzE5b7c/j7Ntwblmv91c6Lj+gcaf0u9RfqOaIn5cB3SD9PvBrzU3bJ9RpFrtp594b8LOYIH/m5VpGP1OVrlDjBknMy8fs2TH8tlBHT47Pkx3f/3/BLfwuEGQX+vk07Kx3fiXyj79v+ebi7bFg3rKd+6qGS+vs2oZ8PvLabsksvtPav6YXk1eqL+/209aVhnTfEetYQa8kQ6ylDrOcNsZYNsZ4ZUL5OG2KdNMR6wRDrPkOsFw2xLOX1pCGWZXu8YIhlqfeWttCyHs8YYlnaHEudeMIQy1L2pwaUr6cNsSx1wtI3sey3LetxUO2XpX5ZtsdBtdGWWJb6ddYQS2Qv4xUc3+Rafz3fATeVI3pSDnyH9PPEqy0/nbGeJtdrFblmuV8sera8s8nqHq8oPGWItWSItWyI9eyAYp03xHrSEOusIdZJQyyru5GicMoQy7I9XjDEstQvS3k9bohlqV+WbcjSrlrqhKVdHdS2bdkeLdvQ84ZYlu3xctCvJwyxLH0A6WsnWnHob0/CM8YhHZfPj/kl3biSL9f66/cO3/nU53UI/bwiEx8+/3Up5Sqyu17htaDE8d6V6xU61yt0Ckoc9039YD1viHXKEOtxQ6zzhlinDbFOGmI9bYj1jCGWpewHVVcvGGItG2JZ6pelzXnKEOtykP0ThliWZXx2QLEs2/ZZQywr2UfPfF7HoOjqoPoAlliD2m9byt7SB7C00Zb+xKDq6nq/vXZ92rpPng1r3SdfO/1a9wvXTr/OGmINquwHVVefM8SylJelzbGU/TlDLMs2ZNl3DKqNHtQ+zbKMlr6vZT1ayv5ysBMvGGFFz7zHqR++HjDk6yojvqLnrYZYlutDlvI6aMjXo0Z8ReERI6zomb/pHwSdiAJ/2zwIsrds29bt0aoNRc+HjbCiYNkeLwf94vOG+sHab4h1wAgrCpbyutqIL0tbGAVLGz2oej+oZXy597WWfEVh3Tf5/u87ovCwEZalPxEFK3lFz5Y++YOGfFn1tVGw7B8t5TWIfUcUXjTEspxTOGOIZbluZTnP9LghluX+QpmzGg+67b/gR0H2+aKti+gcaf0u9RdSn+Mi9PNBb19lyE97n++eoFeuWxW5inz2+uFnIUf4yM9eRT5Sl/uUOMESO4znDWH6vVBGttv7gY8RevefRl/6WyDMKPB5Q/uU8uA7kW8E+e9Gu8uGdcN66qceyqnPxRL6+cBruym79GKPIkdNLyRvQYnjOZy09aXVPe9N6AfrKUOsJUOsZUOsZwcU67wh1pOGWGcNsU4aYj1tiGXZhizr8XlDrFOGWBcMsSzbtqV+WfJlWY+WfFnaCUudsKzHJwyxLO292FXxrdgnONL6XeorTE+Lb4K+TC7opo2+iaFfN5cjeiInfIf088SrLT8dv06rN5QP+3X7FV4LShzX4X6Fzn6FTkGJ47bZD9ZjhliWfD1lhBU9jwU2WNZlPGmI9YQh1rOGWGcNsSzldcEQ69OGWE8bYi0bYlnK/rwh1mlDLMsyvmCIdZ8hlsxHs28RhSOtvxe7w+rcTLUyN1Op1BulWn1mtjlfnS1VF6ar84sL5VJ1ujJXn61VS6VGtbE4VarPzE/XG7X56WpzoTY/69d3mJ4fC3ptvKFvUhb8A37wK4J/0A9+VfCv8oM/JfiH/eBPC/4r/ODP+D1Do9zW/+v94M8J/mv94Lfb1+v84NcEv+QHvy74ZT/4DcGv+MFvCn7VC36lJPhTfvDb9nPaD37bfs74wW/bz1k/+G37OecHv20/5/3gt+3nD/jBb9vPH/SD37afr/eD37af/8oPftt+vsEP/oLg/5Af/EXBP+IHv23/3+gHv23/3+QHv23/3+wFv9q2/zf4wW/b/xv94Lft/1v84Lft/1v94Lft5w/7wW/bzx/xg9+2b2/zg9+2bzf5wW/bt5v94Lft29v94Lft2y1+8Nv27Uf94Lft2zu84E+17c87/eC37c+7/OC37c+7/eC3/c/3+MFv+5/v9YPftp+3+sFv28/3+cFv+5/v94Pfts8f8IPfts8/5ge/bZ8/6Ae/bZ8/5Ae/bZ8/7Ae/bZ8/4ge/bZ8/6gV/uu1/fswPftv+1/zgt+3/gh/8tv1f9IPftv91P/ht+9/wg9+2/00/+G37f9QPftv+fzzohA52tbFwcallujYzt1Bu1maapYWp2blqrTk7W6/V56cas9OlenlxprxYKTfn5mrT07XF6flyudmYn27OtXm/TcXuJ3TWRT7hQy7lZtsu3A74OTP+59r4d3jBL7Xb1Se9yKfetst3KnVbmarPLNRKs83ZWm2uebETrdQv/pm5qDXN6UptvrpYu6hF9YVGbaG6OF9ZrFfq1cbcRVvTqM7PNBqdPusua70pl9pyv9uL3DvrIfeYy33u0v/RNvjPbXwJawL4F1obqVyyj2kEnm8Lu9NIPKb/Xv6lvxG9n2qBjlOeAJ7HKL+tnSrP54heQLQCop9XZONjj9YQ8cPy4T1awwqvBYqLAq/ZDyt0hhU6GtaLhlgnDbGeNsRaNsR60hDrtCHWeUMsyzKeNcQaVP06ZYj1jCHWBUMsS/2ylNfjhliW+mXZhp4yxLLUCUu7Kns5xwK9LzzS+l3qK8zMS1+L4w4JEofjBu6jb4f0N4SddByG6DeWadPFf3t3dHA5HfODvswnAF+TkwRtT76ljyP4G/3gV0WnRoNumXKZNsbISuK1v0Gg+4dCKx/0yt2Hf6iVDfnn9jIK/PA+fQ1rNCPWmBLno05HHOVG+uMOXrVyDJNMNHuUU2Qi7zc6+ML0EwptySsy3ARxhjKsuGSIbVHob4HnemPh3qM333U0oDBEchC57aF0bwk7cmAdHI3BCug3f5s9BHgY/I4Z17YfkHdZ+wG0VZ+guJXavSiwbdDqMKrff3HMLcTpUNq5BUm/YVOHXq71vBlobnbQ3EJxmD4KbyH641C2ISXNZuJR0m9s8RX9ubZVf5rshJ8xyv9y0mUpU1ZdxnpE3hATz5/Auo2rlx1QL9ft6PDM9LYE8eWQ3x9X6AnvBUobBanjbfDecI4r9X2HQj9PvBr3Q20fZhvxw/IRXdsCcrzjrlr9zbW7j997R2MDiXICnhG+QHCSBtNiKABLmJ7zs6reHPbm4yCiHCGeXwWm62DreSLobfp8jBryMKS8Y/O8VeFfm349GnbHoTt0E8WNOOJGHXEblXJJ3CbIdxvlyyuYEZ07N3XwULZR0NRLzLUm5zhdisO6kbAw/zbC2p6AdQthYf7thLUjAevthIX5dxDWFQlYdxAW5r+CsHYmYH2SsDD/TsLalYB1J2Fh/l2EtTsB6y7Cwvy7CWtPAtbdhIX5+dikvQlY9xAW5ufr2PYlYB0jLMzPx9/uT8A6TliYn4/kO5CAdYKwMD8ff3swAatBWJhf8o4rWNwlH4L3hl1g6qPJhH6eePXVJR8KeuWK8mH370qF14ISx3brSoXOlQodDWuHIdYVhlg7DbF2GWLtNsTaY4i11xBrnyHWfkMstltJ/fW7wpf+uvpryYe6i+mGII3WRyNGnD+AU15JfsHNxLNGU/MxPxF2x+EUHPumOF00QXE4lbaN4tDHZLuP02zbKS4PcVIe9DFHqDz3tN77Ha6XSlhfcbJCGedi/gZBuukczMe2f9yQDmLdGnbTmTCkg345l6dgSAexbgi76WxX6IjecBs80vpd6i8005QD6ecD3a4cseGnLLLY6ZDFLi+0p1JPh+wiWez0JAtpZ9p4AnWFlxy0McNOJT1OnxxtnLg4if+mB95TO4orFmg6mR0+uXcH/b4ihq0jlG4X/Ra3hPlALAzMB0/PcPojCenxeVh5HwVtuMWurFZt2impBSX/HgednX3S2anQ8XyicNnvqSWdVUDXCWZI33Wqb1ozwKez+T51Vyubq561U3ddWGlO6EMsvyfddOrUddow0s962jCuJqGdu6J1ZFrk1n1hUzc22weUg5/dJdWZtPoo9FdrJ2ralXDNVZe8BYqLAt+Woa1Kjyh0NKynDLGeM8R60hDrtCHWSUMsyzJa1qNlGZcMsSzL+IQh1tOGWI8bYi0bYl0wxDpviGWpE5bt0bINWeqEpbzOGmI9a4hlKfszhliWsn/GEMtSXpa28JQhlqW8BtUWWsrL0uZcDj6TpU5Y9ttWso+exwIbrChY6r2l7M8ZYlnqvWUZLe2EpQ9gKa8XDLHSfK2ZU7DkvbbDXZuXulx2uE9TOosd7tP0bijQd7jjjmqeDwsgvd/52GolR/S4jAHRzxOvxvXfnrPSti1p854iuwMKrwUljm+71rY0HVDoFJQ47rf7wXrCEOtpQ6zHDbGWDbEuGGKdN8Sy1IknDbFOGmJZ6oSlvM4aYlnK64whlqW8njPEstTV04ZYl0M9PmOIZSkvy37olCGWpbwGtR+ylJelvbfUL0ubY9keLXXC0meykn30zHMwg6L3lrI/Z4hlqfeWZbS0E2cNsSzl9YIhlszBaJ+4xN2kjnRcN2Bh/v0psLTxsKTXPgNxzfXgZymSV+YecDu8j7kerT7wsx2hv5K5HpFbmdLxXA/atoMxWAH9LtO7uLmekdY72bd0vmU8Rb6e9qOpW815v6Lr00Ttk0l8x/qL+bfFYI0EHbniiQA7Al1WT7dkFdX763Z0YyZtt5U61srK+wn3xNDPQTlHKO3zwFtlRzwtH3LV6Gztk85Whc64ki8X81fo8Dumo/Gs3fIr+hHNlf7kWCcP19eQklc+keQ6+x04vfKnW5jaZ5Rx+psDeriP+sawO73YZjxdAtOwvkv6r4BOXUv6voPKjOXUeBZM3O+IPB8NdR5+geyTp73Aqn0SWtqnSHyCqfYpFr5jvduoyEGjc02fdK5R6Iwr+fptRxrPrrWEldJBLGmTfnUj+6kmLGc8nZn3HePJynyC2CchDte4OAzRb5RFlG86xWkoftfSVk+GeykOZYg2iYMmQ5FFWhlOBL0y5La9TSmH1u75e42s7X6ngwekM05x40QX47DNbqJ0OYU/VzvepNDx+21Adh3cSXGog7soDnVwN8WhDrJe3wlx/OnlXRA3QnF3QxyfUoenem+iuGMQl7U9SL1EmLcZnRaGfs7tFDeq4Pr9tLFaTdMvIf088WrLT2cNWmv/2qmKIrtdCq8FiovCg2EnHccNKe82OLDOG2I9a4i1ZIj1lCHW84ZYy4ZYzwwoX6cNsU4aYr1giHWfIdaLhliW8nrSEMuyPV4wxLLUe0tbaFmPZwyxLOvR0n5ZyutpQ6xThliW8rJsQ5b+hKW8HjfEWrera2dXrWQfPfMa9KDovaXszxliWeq9ZRkt7cRZQ6xB9VfvN8QSf5Xnt6JnXE+ROQA8is5yLXgtzx3BMvG5IyirXMxfweI4Pndkl5+yOc8dcekBzvnxEYP9nDsiWKt17shuR7mR/riDV60cOwxlkuZ2Cm1uKWvdakfVSl7Pbay9n2OHQ05Iv59vdyqU7sawIweuu90xWAH9rtC7uP0c2plEuFZdz+s841q1dvzvCKX/PKxVH209a+sCciTeRNCra4XWs9/bXbLP8+coDuf5487yCgJ9jlzKlPUWAvy+i3kTTKwzvIVgBOIx/Yl8h5fiQR0zB5j4nZvsV5H0sjYZd0MF8yDp7wceeA+BpBmOKddoDOYzoIsP5XXMQMHUyrWJysU8bCQeJP0pKNdhONMY08hvtK+3h9285RVaQcw7xMa8HOeim5Q3esYbKjiOdYXlhfnjZMq6Iukfc+jKiMIDlpfrlXngNJtieHhK4QGPPFy86+4HWjdGBBRQ3MIG/uaq5CoYUXDigoghKt4zeR1HfrvUD7ehjCo0RmN4xLyReMTE1Rt3NE40YgS0gcByMcQ2BHpgWxkAhucbw1J/m8o3t4344cd5c5v2Dbd2TLHk1dbkeX9TWjpbgk5bP37irmNxuoB9p6YLwzH0c0r+wIGFebSbo5AOlznrLZIbFf41Opv6pLMpJZ3tfdLZnpLOzj7p7FToMJbmr0ZhMezEY/pfBDt+9UEdc0MMplyZIum1MUROKY+81+ZAdihl1M422BUk00ZZcr+3OyOvSXMQvHdIG8um5fXGcHV5Hc7I6yaFNvb9Fzu32042jt1y14kGmytkI6DnMXrHJ51zdzYaw+oWSsfboHl6iP2RK+h3XuFPC1wtGi9DQXKQJiqy+g66WjFNNAj0Jipqz8NfzKsNf7Vt+ji1yCq6D3jX+GiE3WWT9H/gMD/a5zOuk7m1T1K0T320W3MOUBzKCbfVX8IOezFFN4YhztCNWbx0Qd7BDh8sn5EwvSyiwLLTbvbBz2v4qF/89GgfxeF2Of4kKkmvWF9x25vkxU8LpL4egHTsnjwIv4coPdKU9A8BHW1IJHlHKP2fKUMizeURfsYov63OzC6KDB8OeoPEPQK02QV+FNK/Oeyk46BN70iZIlmMZZjewXpE3hATbQzWbVy9/A3UC18yifQeDOLLIb9HFHosS4mPgtTxo/Dero6nazmiJ2XDd0g/H/TK1sdw61Hih+WjuQ2OSyYfhmeE/wDBSRpMi+EDwBKm5/xc7fuUfBxElCPE87/ALNx/oRlhbPrsziAPQ8o7Hh2MKvxrdDb1SWeTQkc7wf1o2B03pJRVu+iSL548BnF8meXxoLdcEnfCgXmvA/OkI+4+R9z9Styly4u2dHhkc6w1Df4CEusurh3EYd1IWJj/UcI6lYDFF2Ri/lOEFSZg8QWZmD8krKUELL4gE/MvEdbpBCy+IBPznyas5QQsviAT8y8T1pkELL4gE/OfIayzCVh8QSbmP0tY5xKw+IJMzH+OsM4nYB0jLMx/nrAeS8DiCzIx/2OE9XgC1gnCwvyPE9YTCVgNwsL8TxDWkwlY7yIszP8kYT2VgMWXyWH+pwjraQdW9Mxfg2L+pwnrmQQsHpZhfsk7rmBJPyTu17Pw3s7dKaf+Ckbo54lXW3467tezQa9cUT7s6l9QeC0ocdgXYRzSuaDQ0bAeNsR61BDrlCFWaIi1ZIh12hBr2RDrjCHWWUOsc4ZY5w2xHjPEetwQ6wlDrCcNsZ4yxOK+zOXXR88yZeby6yUf2jOeHhqiPJgeMeLGDbiC8GgCz1cRzysdP0TPhwlrpeOH6PkVhLXS8UP0fB1hYX62uacTsK4nLMyfZfwQPb+WsFY6foieX0dY/Ywf7g27sfoZP3yAsFY6foieS0E31krHD9FzmbBWOn6IniuEtdLxQ/RcJayVjh+i5ynCWun4IXqeJqx+xg8zhOUaPzybgDVLWJj/WcK6kIA1R1iY/wJhPZeANU9YmP85wno+AesHCAvzP09Yn0rA+kHCwvyfIqxPJ2C9nrAw/6cJ64UErH9FWJj/BcJ6MQHrDYSF+V8krM8kYP0QYWH+zxDWZxOwjhAW5v8sYf14AtYbCQvz/zhh/UQC1psIC/P/BGF9LgHrzYSF+T9HWJ9PwLqBsDD/5wnrJxOwbiQszP+ThPWFBKy3EBbm/wJh/ZQDKwrvCbuxMP9PEdZPJ2C9lbAw/08T1s8E7jK+NejGwvw/Q1hfTMD6YcLC/F8krC85sKJQD7uxMP+XCOvLCXz9CPGF+b9MWF9JwHobYX0Z4r5CWD+bgHUTYWH+nyWsn0vAupmwMP/PEdZXE7DeTliY/6uE9fMJWLcQFub/ecL6hQSsHyUszP8LhPWLDqwoyC66CSX/LxLWLyXw9Q7iC/P/EmF9LQHrnYSF+b9GWL+cgPUuwsL8v0xYv5KA9W7Cwvy/QlhfT8B6D2Fh/q8T1q8mYL2XsDD/rxLWryVg3UpYmP/XCOsbCVjvIyzM/w3C+mYC1vsJC/N/k7B+PQHrA4SF+X+dsL6VgPVjhIX5v0VY307A+iBhYf5vE9ZvJGB9iLAw/28Q1m8mYH2YsDD/bxLWbyVgfYSwMP9vEdZ3ErA+SliY/zuE9dsJWB8jLMz/24T13QSsGmFh/u8S1u8kYC0QFub/HcL63QSsRcLC/JJ3XMHKtf7K+tPvwXu79Z6pco7oSTnwHdLPE6+2/HTWn34v6JUryofXn35f4bWgxPGc4+8rdH5foaNhnTLECg2xlgyxThtiLRtinTHEOmuIdc4Q67wh1mOGWI8bYj1hiPWkIdZThlhPG2I9a4h1wRDrOUOs5w2xPmWI9WlDrBcMsV40xPqMIdZnDbF+3BDrJwyxPmeI9XlDrJ80xPqCIdZPGWL9tCHWzxhifdEQ60uGWF82xPqKIdbPGmL9nCHWVw2xft4Q6xcMsX7REOuXDLG+Zoj1y4ZYv2KI9XVDrF81xPo1Q6xvGGJ90xDr1w2xvmWI9W1DrN8wxPpNQ6zfMsT6jiHWbxtifdcQi+cck/bJ1VvPrn1yki+EOP7EcIjyYHrEiNuHNwQ8hwk8N4jnfvbjNQkL8y8R1ukErKOEhfmz7sfjW2i0/Xjad3CfCLvjcH6Wv2EYhjj+tg5vJHmY4vA7OJ6XPgFxj1LcvRB3iuJOQlxIcfdB3BLF3Q9xIiP8Dk6+jxQZ3dN6P0ZlE1kdaf0u9Rm0m8tYjlhvuZi/QdBdhxLYBmA+nu9+2JAOYsln2qKjqL94ghrGCR1+x3Qw/yMxWHE3RQ5DPKZ/pFX32k2R2t7kIXj3FkdZJa/oFNu1I63fpf5CWfCX/OBXXfYXy8RtEGWXRb+QVp6wrGXnKhvyz3oYAj9p9o2HGbHGlDgfdXrKUW7N5mq8auWIa5tIJ6/IxNU/a/Xh6p9FhthHGsqw4pIhtkWhv5JTa0Vu+ymd2J0NQRDr6zBWQL/307uhQD+1VrNtm2P4FLpJdhzzSzrXERZp7IZGR+NZ6OD5AngK7+foW3nROzzyA79r2Q/xmP4vtncwv9DC1L67iWsrOaAnfVcUpO6Zv7ijYoZj+PsS9Ht8guewUub9Dp4FE31H5PloqPPwVfK7PPWRqt8ltLQTyPgbUyyLViesdw8pcoiTbRTQT0E/BtP/ckY/BfWb/RTkSfJqYz2Wg0bH1U8+lJLOlj7pbFHo9OuHaHQ0nnlMFQW0J98heyJ6h20L88p38COU/t+APfkdhz3h/SnsO7GNZXsi9OLsCeunpP9Dhz3RfPObw3ieBRP1FHlmeyLp/5jsSRh0l/1I63epz6DZE6Gl9Zd8U2vW/nJckYPv/pJvOD1lSAexpK1ovhzbn5Do8DuX/QmpPHHt9c+26DS19oq6O0LpPwXt9T9Qe0V9F5lresN91CmFLreZIOgdn0XBZctOxWCl7aMk/V87+ijXWCMKrrG0a84R02Ea1/zfkIMG6i2+F984zsdBOppfPhyDm1N4lNsQ/I7t5yrSFnAOU4LELSs8S9wZSP/usJOOwxD9xjJFuvKmgx1cTsf8hBC3HIOp2Yvbw+60UuYNCu4S4UrcSNArLzlni9t/rlWYqP3/ty06HutJFG5tRfodv85VuX4xcP2yfDho9St8R/V7T4b6xTo8Q3FIR3wAHs8hRiT7zS2ig9qWVtJe7umzvWjy5DUCre9EeY4QxmtB38fHu3mSNNxfREHaj7RZkd+wkj8K7PtJ+m0tmpF8vntQp+9qb0Gg2wWUA5/JuBzovGhllrSvIX08Q3mOtH6X+gpTZanHs8Qz0j7niXaO6AWBPs8r9McVfoTvvBI33Aev0+XZ2crMVH26uTAzNz3dyBG+8MrveI5SOwtim5JeZP2YF1lX69qR0OdBrlEYhrhzFDcCccJj1IZ+72A3/+c98Z9G/ki/oKS/Meyky1KXBYUOjzn6wTq1QqztQXcb0PrCEPJxX7gEcXgO6Nti7HIaWye2je0+lpPt4FvJ1i0T7SOt36W+QnVK80fZ1p31RDutrRP640F83eaVuH5sXX16qjzVnJ9eqDerjfpsMxf09glDyju2dZreFpT0nm1FSbN1bM+GIe4sxaGtEx41W+enX6yW0sgf6ReU9Gzr0tZlQaHDtq4frFMrxBJbh34Q+6kh5GM/dUkpD9o6Hpe9nWySn6Pv9TlCtqnIbxRwDL0EcmL5Mg6+Q78Z8/CcjaR/L/jt7xrX+ZMy3KTwp+0pwnK9bzw+3ZKSLhoqT7TeH22cePfHa8ca9Xc3Fo81TgwFOntcRC4+D6cCShcFnp45Sb85njGlCx4OkgOqBGJpVYfY3PV+EIY8/4ZM2DDROtL6W+ozaENH7mr9LONVUg8rhH4+6FU5H9tHtKlNlA93j6Ef+ZSi4QdPfUehGfbKhvkQfeFtgBKv/ZXy8jvuJuKG8kkmMM5k3Q8m67bxTnq2AVpd8DRzmqV4fIfpb6c4XDrLOfB5GuQuaMeHaWoHXR0ph9+bfipl7aYf1Cd0o+L0X7u+QdKHSnptSci1tUjTLdQl0RGtniWPthw+QbxmXfqfUOj4blMTVB7UY3bxsi49avqbtIR2JqZNxi2hVSEe05+BJbTzVJ+YH+V8qVxhJ26V2kwla5vR6sHVZpK27IsMtSXW94bdcVqb0eTKujOk8KD1c5ruDMXQicJCuHI6nF/SpfFTuF860vpd6iuUU/spQn+1/JThlHIV+TziRz6lNLZIs5/acir3KWhjtOGPttwXAh88XPxyy6i4ti642qi2BH9pSyANi3z7W672sFI6iCXXw4y0fsuY5ZfBV/ul8fj8ciXMKOTRtj1weVCHsA/6VeqDcDnGtfzPY6yboA/65gp9Cp/bCZP6Eb5qR9tSxVibFb6i57tbz1LHMhXzu1DH340Z7kcB6+cPqH7QFmr1I7S1aQTJi7jM4x8Bj/+do+0hj38cky56vifoTce2KAh0f4frcAmwtPSCN0Lp/8eU4wbRB78+UFkdN2D9sw+Utj9iOWF6xBAbVKD0LMMoiF78r6AX/47at2ZHV9qG4/zVONvveXpyPq2PIvTzgU+fqeOjaFcBunQiVPhfCOPTJ+mQpI/mUtjOFwArbD3jVYRL9I77KJdPEwW0PX83rmNg+TS/SI7BR4w0tj+rPmtlGoR2k0avNToun+khQzrYnvlzryXi4Ujrd6m/MCWyPw18aj4y0o/+LUMZhghDSx8S/4y/TOkl/zCkF4woSHvgfu/arS/9jXT8n6nvdZUxCnLtY07haUhJExLPZ4IObY3ntxPPkv7/hb6at8dLfvRNcRsZfxLQ5mlrB5NvLj8D+dPYUW25DpfkhB9tm/ZZyofLglznGjYvzWs4ZwiHy7kB3m1XsLWl6ejfkdbvUp9B8GTpdhhonFf4GaH0E1u7+XqcZOqSWfTvMYUuHrO4neg+RnQjHfoT0iHhDccDIWBynYREg/m8g+Il/U5ozztaz9pWFuwf92/VaeP44ZyD17MKr9hmTobd8ZJ+L8jrewd1XpEf5HXt5id131x4vFTOsFs+mv3A9Cu1H9rWgSWKw744JDra3KCrj5H8ozHpcV4A018D9SxjK9e8ZoQv/ZI2b8FzAA9BGVz9VNLy+vVbddy4z8saYXd5Jf3rYZ6jtFWnHQVsg5WMtG+Mof1ft3Uwp0mG2tyHpf+n1dUVQXe5sn5ag/n5kwkfn1EhTa1/Zl8/DHrLEzroYP6QyoP5hFfP/mzqsavQzysy8TF2XQp65epa0zmtpH/EkX5ZSR8q6XHsirY1ILo4dl2mdy5bnGQXbs5oF3DuGNP/MdiFHyW7oO2V0WzGzkDnJQjcdVRQ8vNxSL7GhTupPI84ypN1PRfzr9anpDuJTpzefIT0ZqWfSv886E3NoTe89qmtdWt1kGYO3lUHwynpPNonnbSfmb6cdeoeI536DOjUCYef93KXc2hIJ4Q4qTPut1i+GCd0+J3LT1qi8sTpzfJWnWZavZH0p0BvzqXQG60O4o5aQrqrtfdnteyhC0vzvSV9qKR3+WCaLmnz0drnnaLbfj9vSb+fROjniVdbfjr+rjZHcFqR3ZagM/dRaxwvV+ZuaCwee+DuE1wZAlggIS8ToKQP6Dfni5iKU05MGwU8jwQVqUD5l+g946fhKSltUrzWCE/HlDMI0jVCzJ/1bMVliMf0X4BJlDTnQaDy8EZd13kQp2J4H1LKkI/Jh5PGGIdlFp60Mkv6rzjK3MoeW+Ybw+4yx53rhr853ZBShk1Brw4ghibjXUE371n1CfOvlrOyi+jEde6/GjN5HLdB9ZMQj+nvgM79m9S5a8637/LHnf2E5fokpIk7g2RYwYzC0bCDh+m/2yq754kf9ZsqoaVNlOKG/N/dmiwbV51L+o9Anf9Bijp3tR/tTDOXrfi+dmTKjVIaHUf63/eOzP+S6xZyWkeG87kcGU4b16j7dWQ0nuLSZnVkkDY7Mll3jGB+Sed3N1WlZ0czrupgY4o7UBF3WLhGcLxLhfG5A8CPQjXZ8Q4LSf9n4MT86cGXnrW62h3DXxCkqyvMv1q7e3YTHR+zuFHgGY3VdtbjdFC+FElykv42Y4eJgwRMvxU6zP9MHWbaXWRpZmpZ54Mg3Qy/q72lbT8sI433KLAD1U7f+oTL7xe006W1W7WbTt35C33Xroq8EjfcB6/Ts81yaWZmttqs1OYa0zPcRwqv/C7Nit6VSnq/M0ZT6qFAp0GuURiGuCWKG4E4XBnkgzL8OGZT9TTyR/oFJT0O1rPUpSWWHG4RAs+u1crVsGVpL8ho7/xu2aa0B09jv8WTONpBxTwY4jKyTYzCkdbfJE1qJgShF7bwNiq88JdBknYbyOXPD3aXJW7nz3BMebFsgYIRJzumsUHJe2fQzVuYgjdt4gkxHorhM8JYrR0oGp1DfdI5pNDxufKFNJP8scMTnTxob+JWpE6EnXhM//8UOphXtzC1r3/DoJueNrGKvhDbSMk/GugTqGxvJP1roF0lXUyA5XTpGfpjyHPchFaJ/LElyL9aE1pc5uGgs7sX7eMPh91lkPRXQj1XJ7Jh/kgM5scmOpgzGTHfFoP5TsCcd+jj3qCbHuq6pv/c5jC/pPP7JXjncqbjfvDbF/kcU2SBZRL6mo3JYsuQ1mp9ta6VzVXPeEkdz2lpWMcyYo0pcT7qdNhRbqQ/7uBVKwf7FRqdvYpMJP0JB1+YXtow6r7kFRni5X+GMqy46hsvIxT6K7mcSeS2m9JJH7ch6JX98RisgH7vpndDgX45U2QzP9+y89q8yZ4YnoUHfsf6j/lZ//3YzNmmtlNaAvtizCOHIfqNfEf1/U/bO7icDjFYj+MuOtVsbhyGNpeb1O6jgIsRsuv7+Im7jjXecey2k7UTjRtPNu48oejvpqC7fBvoN594h7wiX+OUjhczj9Hv++j3/Qo/HFgmGMaVdHFBax/YHq+F55X0D5hf0ml0JvukM6nQcWFdq2BJ+nuV9JNKeimHZi/FBuAlrD7st9aGsM8Q+iux3yK3w5ROxlwbgvj+K8l+H6Z3cfZb05U4PoVukq5oPgJj4fjpxrCThufwJf1ZGg/58Wfn25dSoI8hMvPrM8xXc0RP5I3vkP64wo/wnVfi+pmfrsxVy+W5i0vojdJUqVYvudoyvuO2f5+S/jVKepH1/X5krR7kfB/INQrDEHcvxY1AHPYnPD/txz7Np5I/0i8o6Xm+JG1dalg3rhBL5qfRxkvbXi3b5NemZPcnhyhuCeJ4Ixeu9+BcOgfND5XyRnr7H+n0HkzHvGJ9hK1nbazFdeXyR6PgqitJJ3V1gugcaf0u9RVWr66w7XHQ6krKm7WusD7C1rPmV3FdaWNsfOeqqxMOOlv7pLNVoePqs9P0qRodjeek07q+SvORYu9wfhzzHgs78Zh+C8yb/qJjPhJ5ROxcoK+FsY2W/Dg/7vLFJP3XHfPjJ6jMWE7mEcs8rJQrCjw/Lul/nfxBT+MAdX5caPn1B7PbIt5guQTpbwg76Tho9kbKFNXx3h0dXE7H/KBOhoDPcjqhYPE4/eMKP6I39wfd/GPbiAKv+2L++wkr6cSvGwkL86f5wgmxbiEs19p70qnubycs7QMFwQoTsO4grLhT2lmvNKxPEhbmXyKs0wlYdxIW5uc9bMsJWHcRFuZfJqwzCVh8qiXmP0NYZxOw7iEszM+n7JxLwDpGWNqlLtpcPvZLaU4F9HNBTTnzxW2rdSqgJnfX5vbzCq8FJY7nOLVL3c4rdDSsY4ZYjxpi3WuIdb8h1kOGWI8YYp0yxAoNsZYMsU4bYi0bYp0xxDpriDVkiHWSsIYULM22bWn9i8Kl9Z431+4+fu8djYAC4uWC3nWe+2LoF5T8AeXN0btCDJbgRO/Q1+Q5LynnqJIe8XjPSK5FGE/nYtkxP669D57X9Ctp+9VB3VuhzWdI3oISx+PMLGua/ep4FG4Idfo5JX9AWDnlXRRwLVHSafOsWNYbw+700vZwTgIxeM9ee/4Y9J1P+kwai/EagDbewn5d+JkIeu0Ff4ehjSm1uX1cN4zCMMQZ6vWidsohymckTC+LKLDsXDcdYd1rJ4/wWgDaOfarkvRK7CiPFTAvzolpdVkkmtraEL7jPq2olE2jM9knnUmFjgurqGC56m9SSa/ND/BpzSHEWfcVce1amxdYydq3yG0/peO1b22uhbEC+r2f3g0F7rVvrNPjMXwK3SRdwfwunRzqk86QQifOxkcB/R6e15X0b23ZeL9rr3NV13ePfr8/m0u9xh53aibynVfi+lljb85VSovVZqM0XV1YWCzVXTYj6wlEr1TS+91bPqeusYcg1ygMQ9wpisO+UnjU1thDT/ynkT/SLyjpebyR9SRXCyxZY8e+RNr2atkmvzZlcNfYcW9IlnVbrI+w9aytP3BdaX225k9qdXW/g841fdK5RqGj+ce5mL9Ch98xHY3npHXbj9CYSjstFvMeDzvxmP5/h3XbmmNPNPvaXJ+og1Hgdo+nb6fp3yV9E8ZwvG6rfZt5PIznWWik/c5c0t9OPoaffl5ft3V998rzBVm/e9Xk4NmXUb+ll6DZNf4GB+dgeS/FMsTxfkNcG7s17I7DOU+eu8E1o/soTlt7kLjHIG6Y4vCGCdRRDpptxsPJbsuwxo16s0Rx2hkb2t6oV8Ezxgmv/I71DfMfj8nHdsTzNy9lz226/V2S9s03lol995XuC0JaecKylp2rbK79ULhOx+tsGtajGbHGlDgfdXqvo9yaTdB41crB43mtnb1KkYmkP+XgC9NrB7Ct9nyNJkOr+RqR22soHX9rhjr4aAxWQL9fQ+/i5muSvk//bEHnOe15QZL+e+DHfQ6e+TserVwT9Dv6+3Dr2e8az+yCNq/CsnuYaGMcr2EHQZC6L5UyRXo1lqEvRb/pYaLP34pE7x6ENPz9vqT/efBziwd1zFzgntdmHUp7hoCk/5rD15Y0wzHlOhaD+Yegi1+P0fVAwdTKxXs/mYfjxIOk/6ay7hkEvXaR2/rtYTdv9yq0gph33BfcGxPnopuUN3p+gDC4r2d9fZDSy7p6nExZVyT9dx26ou3pda1nMw+c5kQMD7+v8BD1E5tb8Yt33f1AzFIobxPjpVGuSq6CYQUnLgh+VLw/LOg48tulftoychDzjqtB8uJZnPXGHY0TcWvFG5QCaMR4DVlCmv14g7ZvwPd+PNd5EyhLbV8y7xvQvj3KSmel+wb4dy6Gfk7JH8TkDSjPJT9m40vP2liU5z6yjkW1xsFYcWcELYadeEz/5479BseBDw1T9lhLes0vdh1knDS+5O/TtHGKizbKMs2cvovXUEmPPj/vpUD+woy83hiuLq/HM/Ia1y6lD7topG872Th2y10nGthUmI2AnsfoXdx2Nvl9IobVLZSOp735SDXuN7lPOqnwpwXhAwPzMhQkB75n4H9DlyGmiQaB3kR5+wh2KehyfzZmah5xXe67dtkSYvB2J0n/fzrMTxi4y8Zqv6SkDyENb2nSLgvSPqXAZZRL2GEnTtJ53u5U17Y7YXlHwm5ZnFZkgelZdstKepy25u1OOG3Nlxbh9LDQ1IahuLzCS0NaXWp6zeUdiSlvI+zEd8mndWSxpn+aTLSjmiW99ikLyol1DOV7huIwX9h61vRP0nnWv4amf1he1j/tUxxMz7LTPvvgy8KjUKD0KEftyEWhqdk/qQ88clFb3s7F/A2CXhcdy6ZtLbgp7KYTGtIJIU6WBbk9aa5c9FwNutPjRe/cnrT0ImecatHqb4TS74X29yekX9hP4/Tj/m06bWz7jyq8Mu1ZOK78UOvZ5b7xUd6TwPvfHYzPz8uhvI0J40KI489mlpRySvoosI2T9NcAn39PWyPQluA0ehSGIc7QljSz9mWaXXX1ZUkXlIet50LQq6dx9+ogVgjv4vyg0UD3QfBofUxfgTriS8ixz1wi3h/KyHta3/BRKMff0lH+KMvTRFOrK83ua9cbnEmBteQo71ngWUuPdgLTv0GRPWOOBLouLcdgvhEw+SjtJMxPxmDe4PBVtP4TfUBuI9pnTdinsj+CbeQ8xSHv3G+eA/qc9i6ir32OGyh0Awe/2nZ8F79h65n7hg/ihdSt5zHCM7aLVVddvlopT9q6fNRRfsaSfMNBr75qbeicIq9bt+mYIxkxP6D0r5qv84mwQ/uDMb5BFNg3iALbwEcVvtDncB15zv5BTWmvazaGLDdKWr+LsuB+dwniNNmxTXGNOaUsUSgo6T8edseluesO6aykX/vdmLsBNdzoeT/xIWXT/LHo+RMQj+nvdthxTYYumSeN28PWs3aswzLFhRCHW3MvYYe9mGuhrygf1leXLKKQdbzO+op2c4niXFc+hQqdtPoqefEuS60u+dJmTQfS6swQpUc7qKVnH0jSn03hVyEPrk8t0s4PaH3cuUCnje0WZcIXfEv6J1Pac6kXv+OocllrHyhXbh8uGUYhq48oMnN93q+1j7MUF0Ict50lhYe0bUfyape8Jx35w+O61s8unUEfk229pP+cw9ZrZeunf+V5hhDieIusZjsGTZcHxdaHFKfZek3/cC7gnhS+xrCDf01XQoX/rGsbDwH/l7DDoKfca1H3WF6ue+u1Da5719qGtiU9rU2Ju3c+zqbwvKWk/82MNsWlV5Y2Rbubfe3mGQdbr0KKQ5uSVa9cfSDaoI+kuJLTpUeuta+0Yz+XHg0pfIWAq31GG4Ujrb+lPoNrTcbvNYil6RzRE3ngO6SfD/Q+4IgNP2VXvYbwbgPJZ9kPP1ORyeO2EoVm2Csb5oPb0yPAu8j47WE331HQtnnjOtS/p7kmoRO3B0Jo8HzAX8Lc2X8izKQjM11tH9fXb96q84q4rislTwOWlh7Ljun/xjEG1OxnCO+y+nC8vyPt+vqpGDraXgKtX5b0f59yfCi0/fZ/lfJar9mLzNKs2WMd8DqQpqvYLrgNaD6a1l7xKk2tbaFNQB4DSNeANDxv0oqKtQdyTCr7d/+c0b/bAe+y9svcZkKISzMW1+rBZTO0uunZk9P6plizGUn7fFimbd8CMNPs83HJ1GKfT1qZ3hjqvKaVqaTPO2SK83dpZCrpxx0y1WTkkmnSmj3LFOXNxz8myZS3LWvzmy6ZSvorHDLVjjZwyVTS715DmWKZz1I+tBkhPA8FvfYuH5NvuwPzdAymy/9kjLi6DBU6XJeTjroMlXKdTlmuZaNyLWcsl6S/xlO5Hoop10MZy3U6oVwPUbkk/fVKubQ+LG5cq825RIHn/iV9WWmXl/OcGc+LaX64a/+SS19WMr6p0NyG68gRba+6Nk/He7SOpNQBPJYkCsMQ51sHUJdZB0KI03R/pXPOBSW9jJM1HYi77h7prEQHrt/anS4EjFzM34DwJLj21uLRVFhuHEfgHAWPI5aBrtYWOb20O9xbi+2N959I+neDvvLe2iGlPJEM37tdpx3XVnhOQ9J/fHsH8/2tZ9fV8yu13SjnONv94XXb3WW7RWaa7eY27bLdQwod7Tgt7dgDyXtpX8N4Mv9LSl5Jr/l8mB7HN5j+DodvpM0BoZymYjDvAb2/a3t3+bX9TlG6B7bb0D7hGDtoYwHXJ4RJczvCj2u/BZeb6+oBsgtYxpD4kXzoq2J69lUxLsvYQtvbyzIcjUnPPrikDxU9S7P3QeMvbb+IfjXbdOvPSYWutq4UUpz27cParRFWKpotbpG6FNgWLwW9ssD0K10X0/bDs51GWxwSnaTrsFy6InkjXTnTqgxt7ipuTQBpanswtLVzbith6/dnoa3wvvkQ8qTx2yX95xx2USuDqy0k9a3cFkKIW3bkCwF3TKF1pPW3VGr2FYSe2K2NCi9x/eWXQI5/flDnNdfDb39B6ztzJCe0wYa2oZQjekHQO1bgvknThyMm/HTWZLV5QK3diXzOeuGn3MQ12RDo45os1o3mP2j+L45HvkZ9l9CJW5urQDym/wb4ZV+PwQyC7LZT8ka4f7alG9dlK6LQ77pCCHGu9U3eG4x1wmPxpG+TeJ+jpP8O2Ia/X+u1z3JzzffG8v5X11VhoYKFusDratpcsLZfkeeC/8jhh7r2557KyPuSwju3c247X0vho2pt0mUXkO/9EI/p/63DN1hSeHD5BpZ76TAfHsl5CTvsxEm69f25+rGkQjNpb9x3yHZr3xi51rq1OWXk4wDEY/q/duhfqPCAbSDrfC1/B5h2j/CafwtUKlfWes6M1zRQN3ktRNsXpe1NwW/RPtfSP59ynJ0rtX1aqUPRVw7DEI/p/2tLX/NQDvk73AefzdlauVmtNWvTtXp9arHGx8pHQeosOmYq0od/2N6RGbdtQ7+7JPgjfvDb3/0OQ1mHlDIJfdGlDZA+F/M3CPQxi9DKE5Zx2cqusiH/PFcwTPzIcxzWcEassZi4IzblbtfpkKPcTD8uvdYG5P2oAx/Ti11HHR4lWWz0I4uKq95GgabQX8mx2fL7AKXja85Q3iMxWAH9PkDvhgL92Gy2S2mOE/VkU1IfJyr0V+s40RHiJ67t4nGCd9xVq7dO+WSTx1WH4kQ4LjZXXbtbpHesDhson7iBWhfKfOYUDE0EgqmdcL6B8rHZ1ugGQUdd2XwkYcnzkIOXOIwcYYw7MNabznrTUcJ600nXdKy98crc3Mx8ZaE0NVtfbNanqkneuDX9xYWZhanGwuJMeWqmOlWqrzb9xsLU/OzC/OJ0qV6aL8+vevlna3MXqc9P1aZmSoul2ZksoyHRffSsuK1rXuOogq1dXifpNDqswxsddNhk5oKO1zcauD3EEUr/htZKobaTYxTySDnwwrWNMTwMK2WOwtFQ5+FNwMN/oZkKNN24unHDDjevbJeHg27akv6mHR3Mt7aeXZenFALdzmAc1qXIaHOQrt5FJkGg1+MIpZdZj7h630TllvTvUOp9gtJoMhhT+MN3Lv0fi8HS6iwKx0Kd91uBd575yyv8uWb+Nivp0SYJP5psNlNcnrA1OlhWrGu+sFHSf1gpqzabKLTX4jRllOFI2F1uPMV7SEnP9TGupN8CaURmBUqPdaO10c0Uh3RHiQfNxqNe8sqMNjOANkpzz1EGwueYUl67ulss54ielA/fIf088WqsS+WsOiLyGfcjn5JLB8cV+Qg/W73wU2pfQl5QaAuvrQ8eu+wKph8HGWJ6fJb8+O5RuCArej8B+QS/QHFRkFOac0rckPJuwxphFRQslJvUadSOj5Ms+GYC7a/g8jvmEetTdN5lI1ZKB7HEj9LaU/TvSOt3qa9QrUg5tirlENqoV3ZtZ3o2ra0T+vnAa1suu3QY5SP1prV9yVsIenX4gbCTLkm/kY6GdWFAsZYNsZ4wxHraEMtSXucNsZ40xDpriHXSEMuyjE8ZYlnytWSIZdkeLevxtCGWZRt61hDLsh4tdfV5QyxL/XrGEOvThliWej+oNseyjC8YYt1niPWiIZalvCx9E0v9GlS/0FLvB9WXO2WI9bgh1uXgyw2q3lv6Jut9WjasQfXlBtUWWvpylrbQsh4t5TWo/tf9hliD6n+dMcSybNuWbchSXpb9kGUbGlTZW9qvs4ZYgzo3ZKlflr7voPqYg9h3RM+8ZmXRd0zEYOOza21Yo5NTeNbWlDcAxljQW17LdWXB3+4JX8q9TZEVlkno8xqzxGt/BYvjhFaesIzLVnaVzbUWjevuKIM4rG0ZscaUOB91WnCUG+mPO3jVyjFuKJMRQyzeG6S1f239VtJvV9JrejKh0Ja8Urc7IM6wbiuuukUbIfRX8pWRyO1WSicnCm8IetvGthisgH7fSu+GAA/Datl3/i17a3BP7+3hS3/Xbo/ETDVH9KTMAZXr5bJH4qGwk65fn+FThliWc/SWfvegzmdYltFyrXhQ120GdY7rMUOsy0En1tc01k72lvI6Y4hlWUbL+YxBXZM9a4hlqffnDLEGdb7fUifW/a+Xh4227GsfNcS6HGzhoK6ZhYZYzxliDeq8umWftr4OkQ3rctg/YNmGBnXv2Xrf8fLoO84YYl0O+y3W5xTWTvaWZfy0IdagjocsZX/eEGtQ5wst/Zx1O7F2/sS6nVg72Q+qnRD/y7V3xvM+otTH/Qn91dqbo8lV23ORdY+K6/wuLBPGIQ+uc8ImFDr8W9tHIOdacF1H4Ujrb6mvUJ1mOQlfSNfTXrLUOib080FvvfnQMW1fj7anSGS3Q+G1oMQVKB/W5+rIvLqwUpl7sjNOmWv2MovMo/Bw2EnHcUPKuw0OrFOGWOcNsR43xFo2xDptiHXSEOuCIdZThliWZVwyxLIs4xOGWE8bYj1niGWpX5bt0VK/LG2hJV9PGmJZ6v3loBPnDLEs9etZQyzLMlrK/owhlqXeP2OItW4nXh52wrKMnzbEsvQnBlX2LxhirbehbFiPGmKtt6G1k73l2N1yjMzfuuIcEs9havMt2x10ML+k0+hs65OO6xs5zHek9bfUX6jw93eG2O1vca/oH3uaXwj2Tnu+p2SODc/bx/sZvr2zU0fRP7x/YYjy5qCORyj9wV0dzN9qYfKdLgE8jxFeLrCci0x/s7nQzxOvtvx05kY3ED8sH54bHVJ4LVBcFB4MO+k4bkh558I6b4j1rCHWkiHWU4ZYzxtiLRtiPTOgfJ02xDppiHVqQPm6YIhlqfeWfFnK/nFDLMt6tJT9GUMsyzK+YIh1nyHWi4ZYlvJ60hBrUNu2Zd8h/oSMV9B/lDs6tHvB+A4ovPsMMTAO+XPdvoz5h2PycTnE/+U77I60fpf6C2XB3+QHv33OTNL9d0JfuycuF/NXsDhOaOUJy1p2rrIh/6wHeM8en0ejYW3MiOX5Fut2nbru1UL64w5etXLwXYhaO8spMpH3mxx8YfoJhbbkFRny3XlHWr9L/YWKS4bYFoX+Ss7oEbldSeneEnbkwDq4MQYroN9X0rshwMPgun82p+C76rcQkz8Krnthx5V8Uj68x3EXxG8iGrsUHnc5eMT8kk6jk+uTTk6hw1jaHE0UFsNOPKa/uvWg3ce4W+HP1Rb3KOl3QxrhR5PNnhT5ojCu0BKepB3vhffWthDpCb/4DunniVdffdJe4oflw21jn8JrQYlju7BPobNPoaNh7SYeULdWqf4qK62/3X74cdbfbkWuWeuP59f3eSlHeUH42h/0Bok7ALRZFw5CHLYVDkP0G8t06Z5OumM1ULCEJuqY8Dam8GoopzqXN1D4OgTvPhP28h84ZHEAZDF0qIPL6Zgm6vchisP6uJLiUJ+KFLcf4iYp7oDCT5q2GQW2MS692m1IB2W0h+jsMaSD8t5HdPYZ0sG6k7qaCHrrDtsJt/Eh5R3T2avQkfKgr4/rTx/epdNE3wbzyjmUI0znYAfzYy1MaeOHgC/DNt6UsrEfjuUuAu0DFDcJcazPV0Ec6+BhiMO65aDZDZFFZDcmM9gNtNtFinP17578odT9u9Bfrf7d5RdHwdW/S16t3cra8IQiVyxTHA+aj7hSe+fXx0hft0J/tXzvfSnlqvlB+0jmGCf7FSYUuXLdZvXLdys8aHT29ElH68vERot9+XCrg4hs9PKu7jQyV/E47CM423rW+sSjYXcc+hk3UdwhJS7C/1aLaZFHEcrA8wRFwBhS3rnmCYoxWMOANQZY3MdJ+p+lfm0ScO30fWaW+yChgbQPe6Kdtu0Lfa1PFL7zStxwH7w2F+dK1dLMTL0xM7UwPdXMEb7wyu947uQVSnrt3GSR9SsDL7KutO85CDv4rwC5RmEY4g5T3AjECY+R3v/ewW7+X+GJ/zTyR/oFJf0tUIYsdekTC+2BBdbGFWJtD7rbE9ocvzaoUtFskAStzfM6E7YxGW/kFCzNR5YyRZg/kMFHLkIc8sbl0PoPmbufCHrlehVhHU7AupGwrnLw9YoErFsIS2tX40o+7i/82IDSVNr+Qujng9668uErJsmVfcVXKrwWlDjUC4xDOq9U6GhYVxliiV5o+sv7lScVOpMOOpif7Y8fP6QypdkRCVqdFSnu6pjyc9Dsj5Qpsj93ZrA/KPNXUtxhJa/ntjmz0rbpp07dbVPr/7K0zSjIXSH9tqfLDUtra7mYv0KH3zEd1GkeK+B8Hc5F/iXNRUo+nIvEvG8PO/GY/iYY5/51C1Ozi8KjtMNrIM7Qls1JuV8V9AaJuxZoXwHPHDR7JXxnXYvAdn4txWH9vZrisD2+huLQ7l5Hcdco/KxUv7Cu4saiFnRc/pav9sJ9xysN6WDdSV1NBL11NwnPGCd0+B3TmVToJLX/f9ml04xr/3eEnXhM/4PQ/mUCbkwp41q28Wso7tUQx/r8GohjHbwO4rBuOWh2Q2SRdS0C61bK5HeupDLD9iVQ+EKbcFDh3yULnD85t0IbynWKbVr0YiLolVMRnrm9p+nTi0o5NDoTfdKZUOh4blezWt8hgdscykJrc1nHAdg+sowDUOavoriiktevDNOPA4T+ao3RtT6lCO94HHCNwiv7A1FgH/kahc41Cp3LHUuzsbmYv0KH3zEd1Oli0E0nzg+Y2t3Jg/nSjgMk/bXgB8y2MLW1JuFR2iHaDENbVuO+HoPW12cdBwjfWccB/frz0fP1FIc2+bUUd63Cz0r1C+tqtf1m3+2F/Qlf4yf2TbT+NEdxQoffuXwT7gvj2v+7d+s0044DJP1eaP+30jgAy7iWbZzH3Zo/L3HXQxzr4GshDuuWg2Y3RBZZxwFFiMMyIe/D8A7H5e8IX/o7QukbrXqK6mxxdze9K4FGMeik+wtKp7VHv3M86ferC/180NveffhYml+gjds1uy15C0rcCDyvxC5oNmbQ5uF4TyCO0bHeOCTN0WXZO12EOB5rIz+GclpgOxUofF0H77LunX41yCKLn+LTF4meX0dxr1b4SdPOo8D6runOy81/0NpXv3Sw7qSuJoLeuivCM8YJHX7n8lO4T0Y/Ev2U53brNNFPwby8r0zSj4Kf8mnyUzyNRTK1cdTflfoiEvc6iMO65ZA0vplc4fgGy4S8p/VTJP0XqZ48+RWl7VQuTabr/o5/fwfnctnGZfV3eO50UPwd3nu+Fv4OttV1f6cTt+7v6HQuV38H2wnGCZ0kf0drZ9oaBfo7f5LC38G8cf7O/7Wng/k96kc9rR9+X/o7uCa50nkZthtJcyg5oh3nF70zfOkvz9/8Dczf/NXueL6uBNo/tqc73bo/8/01fyN1uT5/08sPtrd1f6YTt+7P6HQuV38G2wnGCZ0kf0ZrZ0nzN1v36DSzzt/8Ffgz21rP6/M33QFlsZrzN+ynSPorqZ7Wcv7G9W2AJ/8itb/De4IO++HHuSfI9W1Amj1B0TPP36x0vwzq46DteeT5G2yfWG8cksYeWfwdlLPw5nnNfZ59gUDhC32BrP4Oro+vdH+99R56tOG+++3V2l//ct2/MxHY2yOtnfGYIwro79y0R6cZt6+G/R1J/z+Bv3ML9aN+vmXL1sZRf9lP0vQ5656btHZDZJHV30Fflu1GEeK0ORSpB/TT7OqhWhI+SkFvkLgy0L4KnjloMhO+I5ndcGUHl9MxTbQjZYpDnaxQHNqFKsVhfU9RHLblaYpD2zlDcTgemKU41N85ikP9nac41N8foDjU3x+kOPTzX996HjT94bZagTj+FqYKcVm/hUG9+1Sxg8vpmFfUb+E7OlNY5p6ONk7c1Hjg1todt9VrJ2676853Ne65t3H8xDDBcpfKn5a9MoZdxAkc7EZhA8VdRfFyNM+GQA/jSj6hIWpTgvdrMVwR+vmgt3p8DFdKxA/Lh4crZYXXghJXhGeMQzplhY6GJbqibX3nK8aKCp2ig842hedBMyHbKA5NSD/d00q38QlvYwo/hnKqslkMFL6m4F3WYVEFZJFlWIQy524VdYa7VbQt3K1ifXO3WlH4SWNPosD6rumOyy6ulA7KiKe1X2dIB+VdIjolQzpYd1JXE4G93SsqdJKGRV+hYZH0xWmHRZL+t2BY9FVyx4vA11q1cdRfiZuGONbnGYhjHZyFOKxbDprdKLae+xkWsd3Aowk/EXbH4VGPk5QPj6bF4dS3aEkar87go4K1460lDo/3PQT4T7ciWId+G3ToX5Nepj3SSNJrn/e+QimvdrQUT3H6GdYPlv5K3BzEZZ02xSH/nxY7uJxOglbPh4kG2x85qkxrF4cBV+waT9/8W9Cxv4hZAkPaqHesY69W0mvLetoUmOQdtM8ueeoIh9c8HL0e4njqCIfXPOWI/W7Wz7VwGS2tjv1FzNSf0MiiY9cA7k2kY8Lb34CO/SPRfk0Cbdax65T0WF985AHqkeQdU/IZ6tjiuMKrBE1XeFovq65oPjHrLfpVKBMOmo6JnLLo2D+msCXYJ7GOaVsScZmedeyfQMeG9nbTfk0C7aw6Vmw9r+tYd9xq6xjXs6ZjRXjHOlZU+MWtraxjm+DTnF0pdKwI79btWHfc94uO7UqhYyuxY/y5mOY7FeEd64+mb7hkwL4WLkNI3kHaeojy8eFPuXQrrf7gVsc0+pMjOoKL9RMFl38lebWjEIopcV18uPpBTde1rb6aP8/b+zDf1TF04j4d4CMdJH251TbxCj2pDzxGXWiPtf4OQ5zhOsBMxMd1wAfLcCTsLrdrvBSFrG2+2HouBL39Am//xjrgdhf3WcBUzFEcyM+kg/+s+qTxOEjbhzT7knZrAS9XZrV1aW0WblfKYrO0rXdpbZbk1Y5xTDuf4eLDpWOuTyQ0HcP+mbfoYL64LTpos7BsbLMk/btT2iw8hioKwxDn22ahDNlmaW1e25qUts2LzFxHOGXZ5oSYkf79JR35i/O/m4jXAwqvB5SyadfKHIjBSnutjKR/sKUfYuf8XJfWuVaGrxhG2kVPtHNET+SN75C+Nl4TvrXjCX1cK1MkXvkd6/2kkt51rYyfvQn6tTKTINcoDENckeKw/QuP2rUyk574TyN/pF9Q0vNVMC6sKGxYBSy0BxZYG1eIJdfKoP0Um7NaNtOvrct+NeQmipuE9LJWnFOwNP8Lr3jMcn0NyrwIz1wOTebiQ00EvXLlT6uKCVg3EtaVDr4mE7D4+hrMjzaJ83G/5MfWpL++Rujng9668rGvLEmuvK/sKoVXbS8J6gXGIR1t/5qGdaUhVrH1rOkvH1t9SKFzyEEH80s6v/5OpazZEQlanfG+gcMx5eeQtL8iy7HVKHNeSy8qeT23zdTHVnPbLPrhx9k2i/BuJW0zCnyk80rb0+WGpbW1XMxfocPvmA7qdDHopoN7jXAf2a/TuoHkw/kCzBt3bPX/faCD+RstTM0uCo+eP72Z5nUNDBKH8yZZj63GPTNDKzzmhNcDsP543gDbI681od3lOVJf170UY8plQacIaSaJzqQhHZT3au2LlbrS9q+xn6PNQR520Dmk0Elq/3+6V6cZ1/55vlDS/x/Q/v+c5oawjGvZxnkuG9eBihSHc3+sgzj3l3Uvvsgi6z5SrFucc2UeDOVbZfsSKHyhTch6fQ3O05xboQ3lOsU2zXsTNN91pX36AaUcGp2JPulMKHQ8t6vM11jyOODqmPJzSGofd67w+wxel3KN0f3IMP04QOiv1hhd61NcY3TtSkT2B6LAPrK271vbk3u5Y2k2NhfzV+jwO6aDOs1tM84P2LyvkwfzpR0HSPr/AH7A1lYGbX5WePR7ZEz2q7iyjgPwuq2Vfk+2En8+el7J8RzIz0r1C+tqtf1m3+1lta/L1Nb32TfJeuXdAYVOUvt/9T6dZtpxgKT/H6D9X9/K4PnIocxtnMfdmj+v7aFhHdSuuExrN1Z6TCrWLZYJecdjxYqAwcfCS/rXt+opqrMf2NdNbx/QENpRum9SOq09+p3jSf99/cvhqvDoeQSeV2IXNBszaPNwfPypdmVy2jaGc3RZvnvHNsZj7UE4JjYKWb97X79uWy+XBZ219B+09tUvHe3YMW2vIfsp2h7Iqx10tHam+ZHop3x8n04T/RTMy/vXJP23wE+5nfwUT2ORy+q6bfTdsUzIe1o/RdI/QPXkya9Qjz9lma77O/79nUl4ZhuX1d/hudNB8Xf4+NO18Hewra77O524dX9Hp3O5+jvYTjBO6CT5O1o709Yo0N/5Sgp/R9u7yP7Ol8Df+Sr1o57WD78v/R1ck1zpvAzbjaQ5lBzRjvOL+Fh4Sf+bMH/z7X3xfO0D2uX93enW/Znvr/kbqcv1+ZtefrC9rfsznbh1f0anc7n6M9hOME7oJPkzWjtLmr/5W6P5mwvgz/zn9fmbS2FQ5m/YT5H0/22A5m+KQW/5Pe8JSu3v8J6goh9+nHuCivBuJXuCoudJeGZbmmW/DOrjoO155PkbbJ9FeOaQNPbI4u+gnIW3QbrmJwpZ/R1cH1/p/nrrPfRow33328WYclnQKUKal+v+nYnA3h5p7YzHHFFAf+eq/TrNuH017O9I+kfA33llC9Pvt2zZr/Jinxb3pxQpLuuem7R2Q2SR1d9BX5btRtIcitQD+mmG9VAXPq4PeoPE4dk7+I0rB01mwnfW62uKEMdXnKJO8jnGaBdKFIf1fblciTNo+lOkODynbpLi8Jy6rN/CoN5lub4G9Vv4XsH1NUX6PUm/r4pht5/ra/hoh7TX17iOv7ke3q/FcEXo54Pe6vExXLme+GH58HDltQqvBSWOt7O8VqHzWoWOhiW6om195+trsh5Nsk3hedBMCF9fgyakn+5ppdv4hLdBuuYnClmHRXiVT5ZhEcqcu1XUGe5W0bZwt4r1HXclDvKTxp5EgfVd0x2XXVwpHZQRT2tfZ0gH5X090bnekA7WndTVRGBv97R2ljQsepiGRcVWmrTDIkn/CRgWnSJ33M+ndNmv8mL3F69jYn3G2wBZB/FKEaxbDprdEFn0Myxiu4F+EF9fg9fLHKJ8eL0MDqf4ehnB/+Lq1Gu7jzukyERoX+mJdpo27rJ/yLfmh/Vz1GClsbA4U6s1q4vN0mKt2cgFvbbX5YdxG8f0BSW932mNak30Ho8aLAYduUZhGOKupLgRiBMetaMGi574TyN/pF9Q0r8l7KTLUpdaX8lH+qXFkiP98GgD/lyVx2xR8GsH0o97hH6eeDXmpz3u0cYJw4pcxx1y1Y4K4W0pWY8qQyyx+9q4ZzfRyTru2a2UZ9COZOTtL5MQh/rBQeuz8UjGlY57iq3nQTo6LgpZxz3FoCOLLOMelDlPM6M+HaY41Cee6kfbx1PeRYWfNPYkCq5lmuGYclnQQRmx/u42pIPyZp/wkCEd7RhR7VhQHvdk7QMPKHSSxj3f26/TTDvukfTvg3HPn5J/7MdHzX48ZJHicGqf9Rmn9lkHcWof65aDZjdEFv1s52W74fJJUMfXwicR+qvlk+wmflg+Lp9E8mrtFo+SYvuQ1SeRupwIeutoD9HRyrPbQWePUh6//mm5odlMCVofxVtUihCX1SfBeYQsPgnKXHjzbK9KWp/MfE3Cu6w+CdqWlfokkxSH+sR2Rzs+J4u/gvyksSdRcI37VssnYf3dY0gH5c1jzwOGdLDu+Nh6zSau1O65fKw4n2T8gE4zrU8i6W8An6TQeh6j/GvZxlF/NX+F9Rn9FdZB9FewbjlodkNkkdUnwbqdpLTC+4iSdhfFSdqDUF9vbD1PBL3tb0vQHbcL4jbDM9JF3dkVdMJiqPN5VYt+JJO/P6hjbojBFH3U5vWkHH6vJ1osa9cToZ0aCbvLhO1pSEnPc6faXAm2KfalUCfZlxpWsNDHkblBTZ7C41rIE3lMI0/Nb0srT5GRJs+9hLVHwUIZu+SJPmMUhiHOtzyRR5bn3oQysTw1+aOcREbapyP7CUvzwbG989y1YI8q6dkmYfo3gM05fLCbvy2Qn3Vhs4KNNtTVzvJKOcYpDvNe+qRzZzf/0t++Bez3e4h2UaHtag+TSvoipJH6SnOkO+Zby/kH7uvTzj+4tvS7jrrNOjdRbD1nueb3PTG+mtDgtsg6tk/hF31Anmf6AOjYUaKt6Yw2fy/pr1LST0Ia1jEca/DnH5jPUMcq2ly1BE2PihSHesQ6hnrEc1yaHkkcblHNundK5JRFx7ietXnRtDp2JeB+j9b3i624O0DHHlxlHStC3Oro2GDtH5G4aYgrwjMHKx17MEV/lVbHioD7MOmYtMdToGNPE23ts1fUO9axpKtbWcfQJkjeQTv2mNexcHt7keJwezvPUWW9VjitjuFnrGl1jOtZ+9wnrY69AnCvIh0T3p4HHftpov2qBNqsY0nX0Yrc16+g7o5bzSuotXrWbAn2SaxjVyn84mfyrGNfAR37RgodQ9pZdYzXTdZ1bG107BspdEy7VlNbN0Ad+0qMjv0G6NgfpdAxlz+2bsc6cYOsY3/kyY7xca2a7+TSH9c17pqvhWMsyTtIR/+gfHz4Uy7dSqs/eNRQGv3JER3BxfqJgsu/krzaVQQHUuK6+HD1g5qua0dtaf48H6+D+Q7H0Ik7uo+vVJD0fw3zlFfTmjvOJQttv3PJpRltLhllOBJ2l9s1XopC1jbPe1mxX+Dj17AOuN3FHcu3OeYqDOTnkIP/rPqk8ThIx3do9iXtp/2TFJfV1qW1WXhcSBabdZhws9gsyXtpD17MNapJuC4+XDrmOqJQ0zHsn/mIDMw3GUMHbVYRaLPNkvRDLfuQZLOE9lrYLJQh2yytzWtHg6Rt88XWs+sKpSzHjCBmpH9yja/Ug6ypTRzspDlI6+qyLow873WUUVtrwLVlme+eIB4w75iSby33xvF6ThHiXHv5eY0I29c+isP2hTLhoNk1kVMWX57reT/RwLqKAtu4YYXfCPfDrUXVPNGVPEdav0sZQ6Veb5SnyrPzc42pqfr8NB/fFgXRxc0e6E9N12YXa7Pl8vxUuTFVXnX6i9MzC4sXmSg1ypfEsdr0p+sLc6XZSm2+vjhTr04vJtGXKz1Hw0482vQobGz9jvgaUtIL3gilL4G9qlC/MaLQu7Tu7kiXi/l7CUN5Nxx2vxsLe9MPhb3phXY+7OVR4jZDHPY3UdjS+o3yQizhY4TSv6FVdqmTTZBH8hcU+puIfhffyjvsCxhrSHkn6aP6mW3xKHqLZbfek36JJuHjO+ZNdCfS60t7mlvKr+2RyapLcXtaoyDXf0p/OBp4kUlF8DcSf0b47T0ZI0GvnIT2Ji9lazbT1APSzxOvPvQP6Qk/LJ8NJJ8xP/JpRGewiO5h+x1VZMN8bCQe85541MYEwpPEDUOc8BGl2TrZzeMGTzz6baPN9rkD6P/h/uz3kT8ndYNjMtR77Fsx/Yegb/0x6DcEV/KLndoM8RuVePkt9bVBScvfhm8kGWpyxfSik6MxZR2lskr6BRh/XrtDx0T5IV8bYjAbyphWMHFfn6vNS/rNSnpsY8LPRNDbNjdTPuR9LOgO+E6rnxylZd8Sr7zeSGk3xtBheWg8bFJwtG8/xohXpMn6EAUeywwpdLBNYZ8/ptA37B+mtb5SgsSNUnkxDsv+vrCTjoM2jpQyReV9U4bvtrS2ZukbyfsReM90hyjtKKXl8wuQxxEDHgsKnVHC3ejgP0c4w0q+8UBvj9rftPzmFH61vqZfOoj1/rCbDtYz9mlPkv1EOz6k5L037MRj+gvQpz2Tsk9jW4Jl+EDYecc2m/1YbpM8p8t9F6fBfhzTv6D0XWwfECt695kUPoLm97GP8G2Q50+QPDUfYCLolQ3r8BjRQv9Y+heWwReBj586GE9L5DruKGP07ssH9XTIA6ZjDK3vFAytXUu+CYUvbntsO0YdNLT+TKMxQnH91o/Wb6OvofkwWjz250iH321Q0if5H/kYbA13VMHR7PwmisspcWzDsLxow9g30cZkaBu1dhdXdy7fW+M9jV816uBdkx/aIes5ytJcqVxanJ1uNsv1mdrCVNIcpbyXeUUp16W/8G4EyhUFnD/j+TucCxwOu+nLXBnO3yGW8DFC6f81zd/hPJXkLyj0cY6LaWn0ef5Om9ccU9JHdfqHMEdmPvc/PT9Xm18olSvNSqU6N7Pac98zUzPlubna3OLMYnN+anFh1ef+52ea89XqQrk6X2/Ml1e9/I2p6kKz3JyfXag2S9W58qqvPdRKlYtrLgsL0+VGbX6+mUQfx2s5oB+FtPMhkv4vwc96Hc0RbHBgRuFE2I0p6f/aMUegfQ+olVPejyjpeWwahYmgtz+RvDyuwHRe9KlcLjdnphbmZhYrF6e2Fld9La85W5tpzpamK/WpRqVeW236C/WZxdJ8tVyv1WZLszNz/ehzFDQ9kb5Y6n2IeE/C2uDAyjmwRhKwbiQszM/6yOP/KIwFvf6X4fzLVI7oSTkCKne7jw5625WP9YIkuW4g2Wl+fkGJ4zkIzT8dVehoWDlDLP4uMs42aetxLr3hOaMjrd+l/kJqvWmvmwarozdDxE+S3mh9h7Y2KXdSuGyIdhbAamG55rB8z+Gm1QWhnw+86mbZJdchRa48L4p5efwbBa4/zVZp6xzfL1hof7R57aNhd5xmq7TxPM9LaWt7bOMmgvi6Ybur9a3IL8+TXtPaEKftBzDUR/XqTV5L9tS/z2hzexLGlXJzveN8Dtctr9FjnHZuR07hYYh+oywunQU12cHldBI0HclR3KhSDm0uifsAzQdy7R9wzUlq9lvuCMgRZhC455w033QlPjTSu4V4kfKOKukRb4TS/1CrXeEZMowpY8goHA97MZnntG1b0r0ZePgA6BDLgfvIQfOzfZ9V6hpPR2ElfnYUuC9aqW/sC8v3Wij783H7WN59qJOH25Tms/A5g5L+/Yc6mLe2njUbITxuDtx2QZsrYvnH7T9huyDpP+SwC9paJ/J1PNQxPwqYV8es92G5tPqT99oeNdf6nrauljTOv4Qd9mJ6/tZjSvvWA+UzEqaXRRRYdtq6lrYmWaD0Wt+J7Yh9kySf3rXXBc8Pezfojc+5ppEErBsJS9Mbl91DrFsIS9ub4cJKOwfG+yZc8w+e9vCmHnMK/dWaf0iSK/enrrVzzS912TatfWpYw4ZYI4ZYUm9Z5sC4TCNBb7uQPp/7zKehz3ziUDdtrLN3hN1xXBeC8cbWR1RjCv/RvyOt36W+wmxNm8+xw+/ca+nav+6nXU8trrRd+96/rrVrbS4lS7uOwiNhJ10/7ScKTxliXTDEWjbEOmmIdc4Q65Qh1rOGWJbysiyjFV+S34ovS119xhDLsm1b6sSThljr9mvdfvkso6XslwyxLPX+OUMsy7Y9qO3R0kYPal9rWY+nDbEuh37ociijJV+WdnUQ++3o2Wr+xZKvKFjK61OGWOcNsSx9k0Ht09bb49qVcVD77cthnGapE6Eh1qDq/dOGWIM61/G8IZZPG51rvdf22UVB9gnx+sYbaM3Bz36Rqbq2j0x48Lt/bqqeI3pBoK8JCH3XHHw+0P2xIyvkdaHcrDZKCwtTlYX69MzMTFbdkPSDcT7O1ELWs2c2UtwIxAmPUf7fO9jNv5/zj6YW0sgf6Wtt8zYoQ5a63B506xq2R21d8eNhdxzuY5A1S1xXXOl+27jvBpAet2VP+84aadvyoO4Vj+7Ak3M0jzZOvOPehTtuW7yp8cDxN95Zf0ft2Inbane8sV4/1jh+HEvDmsClRWloaTgdp5e4kYRS8K6OrLtNEOtGwnLtNtmYgMU7V7QvqbVdRZgO02gtHeM1fK6PsQSe3x528xx3alj0L5+AdQdhaacGCdbmBKxPEhbm51OStsTQwTR4s+MWhbaGz7IcT+D5zrCbZ+RrnLC2JmDdRViYfythTSRg3U1YmH+C8hVi6GCaCXhfUGhr+CzLbQk83xN284x8bSOs7QlYxwgL828nrB0JWMcJC/PvoHxXxNDBNDvg/RUKbQ2fZbkzgecTxDPyJXnT9KY74b1h75XaMxb6q9WbJsmVvZZdCq8FJY5nTncpdHYpdDSsEUOsjYZYmwyxxgyxNhtibTHEGjfEmjDEKhhibTPEElvIo/YoHGn9LfUVqlPSrtFXYZuIsl6LEYbQzwe9+u3DJmq+BsqHR/g7/PBTd/XXOxT5SF3uVOJYH/HrDUy/A8rI+oh6O0LvfrI18i0omGxztT4H34l8L53IRCNqbAO5mL+Cy+9cK31Sv0kn/33xyu6ySL64k//4axhJv1TsYH6lhal9pSA8GtqAOr8QbKxrOz0ut29zxRvcA5L3HqXMOSX9EP1GvqP+eAh2h3M6pol2hG/EwHazl+Kw7fFtGaj3+ylutXRXs+UrpYMyYjszYUgH5b2D6OwwpIN1J3U1EfTWHWJlsVnaV8U8/oizLX9wpU4zzrbImGeE0t9T7GD+97Tq4Gd8U57h8QEGbv+ov1r7Z33eC3Gsg3ijEI8dMWh2Q2Rx6ev1DHYD65Zv2dHa+FgQ+PRbqmnaAtLXVlZ8+FHa/Jc2G6/ZXMmr2Qdum5q/NqHQ0bBknoBP4Qns5NFcQx+7klY3BtXH1vpcyavZ9KFVkWu5qvVNAfGMc1Bs0+L8Yw6a3WrflnPx3z+s8DR01nvk1VBO01zeQOEL+4zPhL38Bw5ZXAGyyOL7ocx3URzqPtt31Cf2GVEP2We8QuEnTduMAtsvrKu4lXQLOpeDjzkRxNuQXNDbxoeUdy7fj33ZON9vqKjTjPP9+HQJSf+RYgdztPXsd54iWxtH/fXhF6a1GyKLfny/XYCv9ZnyHHdTy2aFHs/duuYCNF+lXK2WLw7xZ8vNerM6PTtfWSjPVGdmmlPN2Zm5qXpzeqpWn22Up2rVynxjttQszzUas9PVxdmZZnSBXlNoiTw3OMqWwWeqLDbL1emLlEoztanp+ky1Uq/MlupT081yea5cmZ+aq1abi1Nz9blKtVmZrSym8Zk8zbulPgFI6K+Wz6TZIZfPdIXCK/chUZBT8nNK3JDyztUfse1cKVYUjobd5XGt23nShepKdcH3ul3SGu5KdIHtU7+6wH25a2zsafyTui3z+Mf32HhA1hiqrnoecvDjaZ28Ivxo62ba3EG03jYaxPt3rJPIN/bf8o7rQaPNe7MwP/ffEwlYNxKW5gu72jxi8d4sTR4jFHdz8aW/kQxfX+xOI/uFfhjSvKH17Jqb9TumTN+mhX4+8NqGyq42pI0TIp3dGLh1B+subr9aXilrGl1GntLosjZmlnSRTrytuLJ0uAN2I6S7xZFuk5KOafHOe8QYobTvbGFEuB+a7KaLsuCTtHBfYp7isF4KFIc88Y5j7QYm7XTXcYpD+fBJ9bh3ZoziUJe2Uhzq4jaKw/rdQnG4X0T2dW0OesepHyu+9DeS453FTh600VFw9UWuvgLtvKTXxvqSd9DWR3iMrK2PauNgbrO4PsL+2H6I62ft5E+LHVxOJ0GrZ60/wzkOsU2anu8AXJ470fTBpT+7lfQ4X8H6gzoieQd1Dd2HjkjcAYhDmXBIWrNPoz8u25BWZySvtta6OSWuS3ddOqbxjW2OdWxC4VuzX3F7a3DOCcsWt2b8ePGlv3g6q/aFEe5Ji8IwxFnuDdNOQUUZjoTd5Xb1AVHI2uZ5/RFtM68/YR3ErfUjJu4jwq99hA/tposo+P0iqzTPfgEG9m2ikHWtRvjOulaDfhj7WujfsF1DH439FKwz9qf49kXtbxD0jjmiwPMhrts+hwzp8Hwz0vF9izDL24KO9t2P59sfMuk/1q3mM3Ndo1/M9YP7olmm/B1MEKRvbyKntH2sdhrq5SRftNUcNPlKunX5duJc8s16u8hK5ctf1h5p/S71FwZKvmllKLLIus6JOiplirvxR/uKWjDEBg0rZYiCrPHwTd7/sfjSX88+j3rjT5rbr7XyDSnluyWmfP9UfOlvlPYvi8n0XLcpa9+18ngC53q4jqR+tdvWtTJI+r8tvvQ3acyA/XcUhsPu8h1pvS/1F9SbE9BfHQm7y62N+TA9jxm0b2qxTfPp0VqbztFvxNJuD2I9G1XSIx7r2T8WX/qLN3kUgvg2LnHanKvL15Q41K0x4Hl88qVnz7cNzGprjRK0udQcxWE74TXUPPGMcagHWfs5kUXWW7T4232M26iUQ7MTfNYBtlvBX4t2i30st1vtG31Mz+02qZ3LPixtPxrrN7aZMYrT1jO4zUThLURPm/fHNrMZaI2GnbTW665REFkPAc/DYYd3oS/6gre0SzrhdcwPryXhVW6hxxvKxoAfKcsGSs/PfKt9cbLDN5YR69F1O/1miJP0Q/BOeJR5pFGI2xxmw9pEWBv7wBK+Ckr6jSvkS8MaJawxBQvf4feA26FNaCflYL8q7TrK9wqoU7Rt6PNgXvZ5JP0PTnYwr2k9a+eqsM3V+mrmJQh0X6DfORjP8yapb/gR+vnAqw9QZp8J5eo6qcvTGGNK+NHOqdHqOVpv3Rr01pm2DwBPQ+Jzbly3bGpr9C7/QOv/rG/ZRNqbg2zjL60dczvH9D80+dLfS7fwUTvWbiDNEX9B4K5DV52jfIVXrV7GKE7zW10+0SYHXy6fSOML/WLek5un364yuPROG6OuoV86rfmlWPYRoBv9c40Po8B1MK6k18aMBUqPMtfaJY/XtDWorO0Sx3K3xvSlWA60s7wmq7VP7KP5fCvh5UjrdyljqM025qdmqpXFanO+Nlea4zmfAGS02QP92cridK06PV9abEzP1mZmk+j//6UABbMaPgUA","debug_symbols":"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","brillig_names":["sync_private_state"]}],"outputs":{"globals":{"notes":[{"fields":[{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000001"},{"kind":"string","value":"IdentityFieldNote"},{"fields":[{"name":"field","value":{"fields":[{"name":"index","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000000"}},{"name":"nullable","value":{"kind":"boolean","value":false}}],"kind":"struct"}},{"name":"owner","value":{"fields":[{"name":"index","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000001"}},{"name":"nullable","value":{"kind":"boolean","value":false}}],"kind":"struct"}},{"name":"randomness","value":{"fields":[{"name":"index","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000002"}},{"name":"nullable","value":{"kind":"boolean","value":false}}],"kind":"struct"}}],"kind":"struct"}],"kind":"tuple"},{"fields":[{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000000"},{"kind":"string","value":"ValueNote"},{"fields":[{"name":"value","value":{"fields":[{"name":"index","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000000"}},{"name":"nullable","value":{"kind":"boolean","value":false}}],"kind":"struct"}},{"name":"owner","value":{"fields":[{"name":"index","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000001"}},{"name":"nullable","value":{"kind":"boolean","value":false}}],"kind":"struct"}},{"name":"randomness","value":{"fields":[{"name":"index","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000002"}},{"name":"nullable","value":{"kind":"boolean","value":false}}],"kind":"struct"}}],"kind":"struct"}],"kind":"tuple"}],"storage":[{"fields":[{"name":"contract_name","value":{"kind":"string","value":"ZeroBot"}},{"name":"fields","value":{"fields":[{"name":"hash","value":{"fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000001"}}],"kind":"struct"}},{"name":"name","value":{"fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000002"}}],"kind":"struct"}},{"name":"last_name","value":{"fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000003"}}],"kind":"struct"}},{"name":"document_type","value":{"fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000004"}}],"kind":"struct"}},{"name":"document_number","value":{"fields":[{"name":"slot","value":{"kind":"integer","sign":false,"value":"0000000000000000000000000000000000000000000000000000000000000005"}}],"kind":"struct"}}],"kind":"struct"}}],"kind":"struct"}]},"structs":{"functions":[{"fields":[{"name":"parameters","type":{"fields":[],"kind":"struct","path":"ZeroBot::constructor_parameters"}}],"kind":"struct","path":"ZeroBot::constructor_abi"},{"fields":[{"name":"parameters","type":{"fields":[],"kind":"struct","path":"ZeroBot::sync_private_state_parameters"}}],"kind":"struct","path":"ZeroBot::sync_private_state_abi"}]}},"file_map":{"101":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/messages/discovery/mod.nr","source":"use protocol_types::{address::AztecAddress, debug_log::debug_log};\n\npub mod nonce_discovery;\npub mod partial_notes;\npub mod pending_tagged_log;\npub mod private_logs;\npub mod private_notes;\n\nuse private_notes::MAX_NOTE_PACKED_LEN;\n\npub struct NoteHashAndNullifier {\n    /// The result of NoteHash::compute_note_hash\n    pub note_hash: Field,\n    /// The result of NoteHash::compute_nullifier_unconstrained (since all of message discovery is unconstrained)\n    pub inner_nullifier: Field,\n}\n\n/// A function which takes a note's packed content, address of the emitting contract, nonce, storage slot and note type\n/// ID and attempts to compute its note hash (not siloed by nonce nor address) and inner nullifier (not siloed by\n/// address).\n///\n/// This function must be user-provided as its implementation requires knowledge of how note type IDs are allocated in a\n/// contract. The `#[aztec]` macro automatically creates such a contract library method called\n/// `_compute_note_hash_and_nullifier`, which looks something like this:\n///\n/// ```\n/// |packed_note, contract_address, nonce, storage_slot, note_type_id| {\n///     if note_type_id == MyNoteType::get_id() {\n///         assert(packed_note.len() == MY_NOTE_TYPE_SERIALIZATION_LENGTH);\n///\n///         let note = MyNoteType::unpack(aztec::utils::array::subarray(packed_note.storage(), 0));\n///\n///         let note_hash = note.compute_note_hash(storage_slot);\n///         let note_hash_for_nullify = aztec::note::utils::compute_note_hash_for_nullify(\n///             RetrievedNote{ note, contract_address, metadata: SettledNoteMetadata::new(nonce).into() },\n///             storage_slot\n///         );\n///\n///         let inner_nullifier = note.compute_nullifier_unconstrained(note_hash_for_nullify);\n///\n///         Option::some(\n///             aztec::messages::discovery::NoteHashAndNullifier {\n///                 note_hash, inner_nullifier\n///             }\n///         )\n///     } else if note_type_id == MyOtherNoteType::get_id() {\n///           ... // Similar to above but calling MyOtherNoteType::unpack_content\n///     } else {\n///         Option::none() // Unknown note type ID\n///     };\n/// }\n/// ```\ntype ComputeNoteHashAndNullifier<Env> = unconstrained fn[Env](/* packed_note */BoundedVec<Field, MAX_NOTE_PACKED_LEN>, /* storage_slot */ Field, /* note_type_id */ Field, /* contract_address */ AztecAddress, /* nonce */ Field) -> Option<NoteHashAndNullifier>;\n\n/// Performs the message discovery process, in which private are downloaded and inspected to find new private notes,\n/// partial notes and events, etc., and pending partial notes are processed to search for their completion logs.\n/// This is the mechanism via which a contract updates its knowledge of its private state.\n///\n/// Receives the address of the contract on which discovery is performed along with its\n/// `compute_note_hash_and_nullifier` function.\npub unconstrained fn discover_new_messages<Env>(\n    contract_address: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n) {\n    debug_log(\"Performing message discovery\");\n\n    private_logs::fetch_and_process_private_tagged_logs(\n        contract_address,\n        compute_note_hash_and_nullifier,\n    );\n\n    partial_notes::fetch_and_process_public_partial_note_completion_logs(\n        contract_address,\n        compute_note_hash_and_nullifier,\n    );\n}\n"},"102":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/messages/discovery/nonce_discovery.nr","source":"use crate::messages::discovery::{ComputeNoteHashAndNullifier, private_notes::MAX_NOTE_PACKED_LEN};\n\nuse dep::protocol_types::{\n    address::AztecAddress,\n    constants::MAX_NOTE_HASHES_PER_TX,\n    debug_log::debug_log_format,\n    hash::{compute_note_hash_nonce, compute_siloed_note_hash, compute_unique_note_hash},\n    traits::ToField,\n};\n\n/// A struct with the discovered information of a complete note, required for delivery to PXE. Note that this is *not*\n/// the complete note information, since it does not include content, storage slot, etc.\npub struct DiscoveredNoteInfo {\n    pub nonce: Field,\n    pub note_hash: Field,\n    pub inner_nullifier: Field,\n}\n\n/// Searches for note nonces that will result in a note that was emitted in a transaction. While rare, it is possible\n/// for multiple notes to have the exact same packed content and storage slot but different nonces, resulting in\n/// different unique note hashes. Because of this this function returns a *vector* of discovered notes, though in most\n/// cases it will contain a single element.\n///\n/// Due to how nonces are computed, this function requires knowledge of the transaction in which the note was created,\n/// more specifically the list of all unique note hashes in it plus the value of its first nullifier.\npub unconstrained fn attempt_note_nonce_discovery<Env>(\n    unique_note_hashes_in_tx: BoundedVec<Field, MAX_NOTE_HASHES_PER_TX>,\n    first_nullifier_in_tx: Field,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n    contract_address: AztecAddress,\n    storage_slot: Field,\n    note_type_id: Field,\n    packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n) -> BoundedVec<DiscoveredNoteInfo, MAX_NOTE_HASHES_PER_TX> {\n    let discovered_notes = &mut BoundedVec::new();\n\n    debug_log_format(\n        \"Attempting nonce discovery on {0} potential notes on contract {1} for storage slot {2}\",\n        [unique_note_hashes_in_tx.len() as Field, contract_address.to_field(), storage_slot],\n    );\n\n    // We need to find nonces (typically just one) that result in a note hash that, once siloed into a unique note hash,\n    // is one of the note hashes created by the transaction.\n    unique_note_hashes_in_tx.for_eachi(|i, expected_unique_note_hash| {\n        // Nonces are computed by hashing the first nullifier in the transaction with the index of the note in the\n        // new note hashes array. We therefore know for each note in every transaction what its nonce is.\n        let candidate_nonce = compute_note_hash_nonce(first_nullifier_in_tx, i);\n\n        // Given nonce, note content and metadata, we can compute the note hash and silo it to check if it matches\n        // the note hash at the array index we're currently processing.\n        // TODO(#11157): handle failed note_hash_and_nullifier computation\n        let hashes = compute_note_hash_and_nullifier(\n            packed_note,\n            storage_slot,\n            note_type_id,\n            contract_address,\n            candidate_nonce,\n        )\n            .expect(f\"Failed to compute a note hash for note type {note_type_id}\");\n\n        let siloed_note_hash = compute_siloed_note_hash(contract_address, hashes.note_hash);\n        let unique_note_hash = compute_unique_note_hash(candidate_nonce, siloed_note_hash);\n\n        if unique_note_hash == expected_unique_note_hash {\n            // Note that while we did check that the note hash is the preimage of the expected unique note hash, we\n            // perform no validations on the nullifier - we fundamentally cannot, since only the application knows\n            // how to compute nullifiers. We simply trust it to have provided the correct one: if it hasn't, then\n            // PXE may fail to realize that a given note has been nullified already, and calls to the application\n            // could result in invalid transactions (with duplicate nullifiers). This is not a concern because an\n            // application already has more direct means of making a call to it fail the transaction.\n            discovered_notes.push(\n                DiscoveredNoteInfo {\n                    nonce: candidate_nonce,\n                    note_hash: hashes.note_hash,\n                    inner_nullifier: hashes.inner_nullifier,\n                },\n            );\n\n            // We don't exit the loop - it is possible (though rare) for the exact same note content to be present\n            // multiple times in the same transaction with different nonces. This typically doesn't happen due to\n            // notes containing random values in order to hide their contents.\n        }\n    });\n\n    debug_log_format(\n        \"Discovered a total of {0} notes\",\n        [discovered_notes.len() as Field],\n    );\n\n    *discovered_notes\n}\n\nmod test {\n    use crate::{\n        messages::discovery::{NoteHashAndNullifier, private_notes::MAX_NOTE_PACKED_LEN},\n        note::{\n            note_interface::{NoteHash, NoteType},\n            note_metadata::SettledNoteMetadata,\n            retrieved_note::RetrievedNote,\n            utils::compute_note_hash_for_nullify,\n        },\n        oracle::random::random,\n        test::mocks::mock_note::MockNote,\n        utils::array,\n    };\n\n    use dep::protocol_types::{\n        address::AztecAddress,\n        hash::{compute_note_hash_nonce, compute_siloed_note_hash, compute_unique_note_hash},\n        traits::{FromField, Packable},\n    };\n\n    use super::attempt_note_nonce_discovery;\n\n    // This implementation could be simpler, but this serves as a nice example of the expected flow in a real\n    // implementation, and as a sanity check that the interface is sufficient.\n    unconstrained fn compute_note_hash_and_nullifier(\n        packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n        storage_slot: Field,\n        note_type_id: Field,\n        contract_address: AztecAddress,\n        nonce: Field,\n    ) -> Option<NoteHashAndNullifier> {\n        if note_type_id == MockNote::get_id() {\n            let note = MockNote::unpack(array::subarray(packed_note.storage(), 0));\n            let note_hash = note.compute_note_hash(storage_slot);\n\n            let note_hash_for_nullify = compute_note_hash_for_nullify(\n                RetrievedNote {\n                    note,\n                    contract_address,\n                    metadata: SettledNoteMetadata::new(nonce).into(),\n                },\n                storage_slot,\n            );\n\n            let inner_nullifier = note.compute_nullifier_unconstrained(note_hash_for_nullify);\n\n            Option::some(NoteHashAndNullifier { note_hash, inner_nullifier })\n        } else {\n            Option::none()\n        }\n    }\n\n    global VALUE: Field = 7;\n    global FIRST_NULLIFIER_IN_TX: Field = 47;\n    global CONTRACT_ADDRESS: AztecAddress = AztecAddress::from_field(13);\n    global STORAGE_SLOT: Field = 99;\n\n    #[test]\n    unconstrained fn no_note_hashes() {\n        let unique_note_hashes_in_tx = BoundedVec::new();\n        let packed_note = BoundedVec::new();\n\n        let discovered_notes = attempt_note_nonce_discovery(\n            unique_note_hashes_in_tx,\n            FIRST_NULLIFIER_IN_TX,\n            compute_note_hash_and_nullifier,\n            CONTRACT_ADDRESS,\n            STORAGE_SLOT,\n            MockNote::get_id(),\n            packed_note,\n        );\n\n        assert_eq(discovered_notes.len(), 0);\n    }\n\n    #[test(should_fail_with = \"Failed to compute a note hash\")]\n    unconstrained fn failed_hash_computation() {\n        let unique_note_hashes_in_tx = BoundedVec::from_array([random()]);\n        let packed_note = BoundedVec::new();\n        let note_type_id = 0; // This note type id is unknown to compute_note_hash_and_nullifier\n\n        let discovered_notes = attempt_note_nonce_discovery(\n            unique_note_hashes_in_tx,\n            FIRST_NULLIFIER_IN_TX,\n            compute_note_hash_and_nullifier,\n            CONTRACT_ADDRESS,\n            STORAGE_SLOT,\n            note_type_id,\n            packed_note,\n        );\n\n        assert_eq(discovered_notes.len(), 0);\n    }\n\n    struct NoteAndData {\n        note: MockNote,\n        nonce: Field,\n        note_hash: Field,\n        unique_note_hash: Field,\n        inner_nullifier: Field,\n    }\n\n    unconstrained fn construct_note(value: Field, note_index_in_tx: u32) -> NoteAndData {\n        let nonce = compute_note_hash_nonce(FIRST_NULLIFIER_IN_TX, note_index_in_tx);\n\n        let retrieved_note = MockNote::new(value)\n            .contract_address(CONTRACT_ADDRESS)\n            .note_metadata(SettledNoteMetadata::new(nonce).into())\n            .build_retrieved_note();\n        let note = retrieved_note.note;\n\n        let note_hash = note.compute_note_hash(STORAGE_SLOT);\n        let unique_note_hash =\n            compute_unique_note_hash(nonce, compute_siloed_note_hash(CONTRACT_ADDRESS, note_hash));\n        let inner_nullifier = note.compute_nullifier_unconstrained(compute_note_hash_for_nullify(\n            retrieved_note,\n            STORAGE_SLOT,\n        ));\n\n        NoteAndData { note, nonce, note_hash, unique_note_hash, inner_nullifier }\n    }\n\n    #[test]\n    unconstrained fn single_note() {\n        let note_index_in_tx = 2;\n        let note_and_data = construct_note(VALUE, note_index_in_tx);\n\n        let mut unique_note_hashes_in_tx = BoundedVec::from_array([\n            random(), random(), random(), random(), random(), random(), random(),\n        ]);\n        unique_note_hashes_in_tx.set(note_index_in_tx, note_and_data.unique_note_hash);\n\n        let discovered_notes = attempt_note_nonce_discovery(\n            unique_note_hashes_in_tx,\n            FIRST_NULLIFIER_IN_TX,\n            compute_note_hash_and_nullifier,\n            CONTRACT_ADDRESS,\n            STORAGE_SLOT,\n            MockNote::get_id(),\n            BoundedVec::from_array(note_and_data.note.pack()),\n        );\n\n        assert_eq(discovered_notes.len(), 1);\n        let discovered_note = discovered_notes.get(0);\n\n        assert_eq(discovered_note.nonce, note_and_data.nonce);\n        assert_eq(discovered_note.note_hash, note_and_data.note_hash);\n        assert_eq(discovered_note.inner_nullifier, note_and_data.inner_nullifier);\n    }\n\n    #[test]\n    unconstrained fn multiple_notes_same_preimage() {\n        let first_note_index_in_tx = 3;\n        let first_note_and_data = construct_note(VALUE, first_note_index_in_tx);\n\n        let second_note_index_in_tx = 5;\n        let second_note_and_data = construct_note(VALUE, second_note_index_in_tx);\n\n        // Both notes have the same preimage (and therefore packed representation), so both should be found in the same\n        // call.\n        assert_eq(first_note_and_data.note, second_note_and_data.note);\n        let packed_note = first_note_and_data.note.pack();\n\n        let mut unique_note_hashes_in_tx = BoundedVec::from_array([\n            random(), random(), random(), random(), random(), random(), random(),\n        ]);\n        unique_note_hashes_in_tx.set(first_note_index_in_tx, first_note_and_data.unique_note_hash);\n        unique_note_hashes_in_tx.set(second_note_index_in_tx, second_note_and_data.unique_note_hash);\n\n        let discovered_notes = attempt_note_nonce_discovery(\n            unique_note_hashes_in_tx,\n            FIRST_NULLIFIER_IN_TX,\n            compute_note_hash_and_nullifier,\n            CONTRACT_ADDRESS,\n            STORAGE_SLOT,\n            MockNote::get_id(),\n            BoundedVec::from_array(packed_note),\n        );\n\n        assert_eq(discovered_notes.len(), 2);\n\n        assert(discovered_notes.any(|discovered_note| {\n            (discovered_note.nonce == first_note_and_data.nonce)\n                & (discovered_note.note_hash == first_note_and_data.note_hash)\n                & (discovered_note.inner_nullifier == first_note_and_data.inner_nullifier)\n        }));\n\n        assert(discovered_notes.any(|discovered_note| {\n            (discovered_note.nonce == second_note_and_data.nonce)\n                & (discovered_note.note_hash == second_note_and_data.note_hash)\n                & (discovered_note.inner_nullifier == second_note_and_data.inner_nullifier)\n        }));\n    }\n}\n"},"103":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/messages/discovery/partial_notes.nr","source":"use crate::{\n    capsules::CapsuleArray,\n    messages::{\n        discovery::{ComputeNoteHashAndNullifier, nonce_discovery::attempt_note_nonce_discovery},\n        encoding::MAX_MESSAGE_CONTENT_LEN,\n    },\n    oracle::message_discovery::{deliver_note, get_log_by_tag},\n    utils::array,\n};\n\nuse dep::protocol_types::{\n    address::AztecAddress,\n    constants::PUBLIC_LOG_SIZE_IN_FIELDS,\n    debug_log::debug_log_format,\n    hash::sha256_to_field,\n    traits::{Deserialize, Serialize, ToField},\n};\n\nglobal PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN: u32 = 2;\n\n/// Partial notes have a maximum packed length of their private fields bound by extra content in their private message\n/// (e.g. the storage slot, note completion log tag, etc.).\npub global MAX_PARTIAL_NOTE_PRIVATE_PACKED_LEN: u32 =\n    MAX_MESSAGE_CONTENT_LEN - PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN;\n\n/// The slot in the PXE capsules where we store a `CapsuleArray` of `DeliveredPendingPartialNote`.\npub global DELIVERED_PENDING_PARTIAL_NOTE_ARRAY_LENGTH_CAPSULES_SLOT: Field = sha256_to_field(\n    \"AZTEC_NR::DELIVERED_PENDING_PARTIAL_NOTE_ARRAY_LENGTH_CAPSULES_SLOT\".as_bytes(),\n);\n\n/// Public logs contain an extra field at the beginning with the address of the contract that emitted them, and partial\n/// notes emit their completion tag in the log, resulting in the first two fields in the public log not being part of\n/// the packed public content.\n// TODO(#10273): improve how contract log siloing is handled\npub global NON_PACKED_CONTENT_FIELDS_IN_PUBLIC_LOG: u32 = 2;\n\n/// The maximum length of the packed representation of public fields in a partial note. This is limited by public log\n/// size and extra fields in the log (e.g. the tag).\npub global MAX_PUBLIC_PARTIAL_NOTE_PACKED_CONTENT_LENGTH: u32 =\n    PUBLIC_LOG_SIZE_IN_FIELDS - NON_PACKED_CONTENT_FIELDS_IN_PUBLIC_LOG;\n\n/// A partial note that was delivered but is still pending completion. Contains the information necessary to find the\n/// log that will complete it and lead to a note being discovered and delivered.\n#[derive(Serialize, Deserialize)]\npub(crate) struct DeliveredPendingPartialNote {\n    pub(crate) note_completion_log_tag: Field,\n    pub(crate) storage_slot: Field,\n    pub(crate) note_type_id: Field,\n    pub(crate) packed_private_note_content: BoundedVec<Field, MAX_PARTIAL_NOTE_PRIVATE_PACKED_LEN>,\n    pub(crate) recipient: AztecAddress,\n}\n\npub unconstrained fn process_partial_note_private_msg(\n    contract_address: AztecAddress,\n    recipient: AztecAddress,\n    msg_metadata: u64,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n) {\n    let (note_type_id, storage_slot, note_completion_log_tag, packed_private_note_content) =\n        decode_partial_note_private_msg(msg_metadata, msg_content);\n\n    // We store the information of the partial note we found in a persistent capsule in PXE, so that we can later search\n    // for the public log that will complete it.\n    let pending = DeliveredPendingPartialNote {\n        note_completion_log_tag,\n        storage_slot,\n        note_type_id,\n        packed_private_note_content,\n        recipient,\n    };\n\n    CapsuleArray::at(\n        contract_address,\n        DELIVERED_PENDING_PARTIAL_NOTE_ARRAY_LENGTH_CAPSULES_SLOT,\n    )\n        .push(pending);\n}\n\n/// Searches for public logs that would result in the completion of pending partial notes, ultimately resulting in the\n/// notes being delivered to PXE if completed.\npub unconstrained fn fetch_and_process_public_partial_note_completion_logs<Env>(\n    contract_address: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n) {\n    let pending_partial_notes = CapsuleArray::at(\n        contract_address,\n        DELIVERED_PENDING_PARTIAL_NOTE_ARRAY_LENGTH_CAPSULES_SLOT,\n    );\n\n    debug_log_format(\n        \"{} pending partial notes\",\n        [pending_partial_notes.len() as Field],\n    );\n\n    pending_partial_notes.for_each(|i, pending_partial_note: DeliveredPendingPartialNote| {\n        let maybe_log = get_log_by_tag(pending_partial_note.note_completion_log_tag);\n        if maybe_log.is_none() {\n            debug_log_format(\n                \"Found no completion logs for partial note with tag {}\",\n                [pending_partial_note.note_completion_log_tag],\n            );\n\n            // Note that we're not removing the pending partial note from the capsule array, so we will continue\n            // searching for this tagged log when performing message discovery in the future until we either find it or\n            // the entry is somehow removed from the array.\n        } else {\n            debug_log_format(\n                \"Completion log found for partial note with tag {}\",\n                [pending_partial_note.note_completion_log_tag],\n            );\n            let log = maybe_log.unwrap();\n\n            // Public logs have an extra field at the beginning with the contract address, which we use to verify\n            // that we're getting the logs from the expected contract.\n            // TODO(#10273): improve how contract log siloing is handled\n            assert_eq(\n                log.log_content.get(0),\n                contract_address.to_field(),\n                \"Got a public log emitted by a different contract\",\n            );\n\n            // Public fields are assumed to all be placed at the end of the packed representation, so we combine the\n            // private and public packed fields (i.e. the contents of the private message and public log sans the extra\n            // fields) to get the complete packed content.\n            let packed_public_note_content: BoundedVec<_, MAX_PUBLIC_PARTIAL_NOTE_PACKED_CONTENT_LENGTH> =\n                array::subbvec(log.log_content, NON_PACKED_CONTENT_FIELDS_IN_PUBLIC_LOG);\n            let complete_packed_note = array::append(\n                pending_partial_note.packed_private_note_content,\n                packed_public_note_content,\n            );\n\n            let discovered_notes = attempt_note_nonce_discovery(\n                log.unique_note_hashes_in_tx,\n                log.first_nullifier_in_tx,\n                compute_note_hash_and_nullifier,\n                contract_address,\n                pending_partial_note.storage_slot,\n                pending_partial_note.note_type_id,\n                complete_packed_note,\n            );\n\n            debug_log_format(\n                \"Discovered {0} notes for partial note with tag {1}\",\n                [discovered_notes.len() as Field, pending_partial_note.note_completion_log_tag],\n            );\n\n            discovered_notes.for_each(|discovered_note| {\n                // TODO:(#10728): decide how to handle notes that fail delivery. This could be due to e.g. a\n                // temporary node connectivity issue - is simply throwing good enough here?\n                assert(\n                    deliver_note(\n                        contract_address,\n                        pending_partial_note.storage_slot,\n                        discovered_note.nonce,\n                        complete_packed_note,\n                        discovered_note.note_hash,\n                        discovered_note.inner_nullifier,\n                        log.tx_hash,\n                        pending_partial_note.recipient,\n                    ),\n                    \"Failed to deliver note\",\n                );\n            });\n\n            // Because there is only a single log for a given tag, once we've processed the tagged log then we\n            // simply delete the pending work entry, regardless of whether it was actually completed or not.\n            // TODO(#11627): only remove the pending entry if we actually process a log that results in the note\n            // being completed.\n            pending_partial_notes.remove(i);\n        }\n    });\n}\n\nfn decode_partial_note_private_msg(\n    msg_metadata: u64,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n) -> (Field, Field, Field, BoundedVec<Field, MAX_PARTIAL_NOTE_PRIVATE_PACKED_LEN>) {\n    let note_type_id = msg_metadata as Field; // TODO: make note type id not be a full field\n\n    assert(\n        msg_content.len() > PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN,\n        f\"Invalid private note message: all partial note private messages must have at least {PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN} fields\",\n    );\n\n    // If PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN is changed, causing the assertion below to fail, then the\n    // destructuring of the partial note private message encoding below must be updated as well.\n    std::static_assert(\n        PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN == 2,\n        \"unexpected value for PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN\",\n    );\n\n    // We currently have two fields that are not the partial note's packed representation, which are the storage slot\n    // and the note completion log tag.\n    let storage_slot = msg_content.get(0);\n    let note_completion_log_tag = msg_content.get(1);\n\n    let packed_private_note_content = array::subbvec(msg_content, 2);\n\n    (note_type_id, storage_slot, note_completion_log_tag, packed_private_note_content)\n}\n"},"105":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/messages/discovery/private_logs.nr","source":"use crate::{\n    capsules::CapsuleArray,\n    messages::{\n        discovery::{\n            ComputeNoteHashAndNullifier,\n            partial_notes::process_partial_note_private_msg,\n            pending_tagged_log::{PENDING_TAGGED_LOG_ARRAY_BASE_SLOT, PendingTaggedLog},\n            private_notes::process_private_note_msg,\n        },\n        encoding::decode_message,\n        encryption::{aes128::AES128, log_encryption::LogEncryption},\n        msg_type::{\n            PARTIAL_NOTE_PRIVATE_MSG_TYPE_ID, PRIVATE_EVENT_MSG_TYPE_ID, PRIVATE_NOTE_MSG_TYPE_ID,\n        },\n    },\n    oracle::{logs::store_private_event_log, message_discovery::fetch_tagged_logs},\n    utils::array,\n};\n\nuse protocol_types::{\n    abis::event_selector::EventSelector,\n    address::AztecAddress,\n    debug_log::{debug_log, debug_log_format},\n    traits::FromField,\n};\n\n/// Searches for private logs that signal new private notes that are then delivered to PXE, or new partial notes that\n/// are stored in the PXE capsules so that `fetch_and_process_public_partial_note_completion_logs` can later search for\n/// public logs that will complete them.\npub unconstrained fn fetch_and_process_private_tagged_logs<Env>(\n    contract_address: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n) {\n    // We will eventually perform log discovery via tagging here, but for now we simply call the `fetchTaggedLogs` oracle.\n    // This makes PXE synchronize tags, download logs and store the pending tagged logs in capsule array which are then\n    // retrieved and processed here.\n    fetch_tagged_logs(PENDING_TAGGED_LOG_ARRAY_BASE_SLOT);\n\n    // Get the logs from the capsule array and process them one by one\n    let logs =\n        CapsuleArray::<PendingTaggedLog>::at(contract_address, PENDING_TAGGED_LOG_ARRAY_BASE_SLOT);\n    logs.for_each(|i, log: PendingTaggedLog| {\n        process_log(contract_address, compute_note_hash_and_nullifier, log);\n        logs.remove(i);\n    });\n}\n\n/// Processes a log's ciphertext by decrypting it and then searching the plaintext for private notes or partial notes.\n///\n/// Private notes result in nonce discovery being performed prior to delivery, which requires knowledge of the\n/// transaction hash in which the notes would've been created (typically the same transaction in which the log was\n/// emitted), along with the list of unique note hashes in said transaction and the `compute_note_hash_and_nullifier`\n/// function.\n///\n/// Partial notes result in a pending partial note entry being stored in a PXE capsule, which will later be retrieved to\n/// search for the note's completion public log.\nunconstrained fn process_log<Env>(\n    contract_address: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n    pending_tagged_log: PendingTaggedLog,\n) {\n    debug_log_format(\n        \"Processing log with tag {0}\",\n        [pending_tagged_log.log.get(0)],\n    );\n\n    // The tag is ignored for now.\n    let ciphertext = array::subbvec(pending_tagged_log.log, 1);\n\n    let log_plaintext = AES128::decrypt_log(ciphertext, pending_tagged_log.recipient);\n\n    // The first thing to do after decrypting the log is to determine what type of private log we're processing. We\n    // have 3 log types: private note logs, partial note logs and event logs.\n\n    let (msg_type_id, msg_metadata, msg_content) = decode_message(log_plaintext);\n\n    if msg_type_id == PRIVATE_NOTE_MSG_TYPE_ID {\n        debug_log(\"Processing private note msg\");\n\n        process_private_note_msg(\n            contract_address,\n            pending_tagged_log.tx_hash,\n            pending_tagged_log.unique_note_hashes_in_tx,\n            pending_tagged_log.first_nullifier_in_tx,\n            pending_tagged_log.recipient,\n            compute_note_hash_and_nullifier,\n            msg_metadata,\n            msg_content,\n        );\n    } else if msg_type_id == PARTIAL_NOTE_PRIVATE_MSG_TYPE_ID {\n        debug_log(\"Processing partial note private msg\");\n\n        process_partial_note_private_msg(\n            contract_address,\n            pending_tagged_log.recipient,\n            msg_metadata,\n            msg_content,\n        );\n    } else if msg_type_id == PRIVATE_EVENT_MSG_TYPE_ID {\n        debug_log(\"Processing private event msg\");\n\n        // In the case of events, the msg metadata is the event selector.\n        let event_selector = EventSelector::from_field(msg_metadata as Field);\n\n        store_private_event_log(\n            contract_address,\n            pending_tagged_log.recipient,\n            event_selector,\n            msg_content,\n            pending_tagged_log.tx_hash,\n            pending_tagged_log.log_index_in_tx,\n            pending_tagged_log.tx_index_in_block,\n        );\n    } else {\n        debug_log_format(\"Unknown msg type id {0}\", [msg_type_id as Field]);\n    }\n}\n"},"106":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/messages/discovery/private_notes.nr","source":"use crate::{\n    messages::{\n        discovery::{ComputeNoteHashAndNullifier, nonce_discovery::attempt_note_nonce_discovery},\n        encoding::MAX_MESSAGE_CONTENT_LEN,\n    },\n    oracle,\n    utils::array,\n};\nuse protocol_types::{\n    address::AztecAddress, constants::MAX_NOTE_HASHES_PER_TX, debug_log::debug_log_format,\n};\n\n/// The number of fields in a private note message content that are not the note's packed representation.\nglobal PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN: u32 = 1;\n\n/// The maximum length of the packed representation of a note's contents. This is limited by private log size,\n/// encryption overhead and extra fields in the message (e.g. message type id, storage slot, etc.).\npub global MAX_NOTE_PACKED_LEN: u32 =\n    MAX_MESSAGE_CONTENT_LEN - PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN;\n\npub unconstrained fn process_private_note_msg<Env>(\n    contract_address: AztecAddress,\n    tx_hash: Field,\n    unique_note_hashes_in_tx: BoundedVec<Field, MAX_NOTE_HASHES_PER_TX>,\n    first_nullifier_in_tx: Field,\n    recipient: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n    msg_metadata: u64,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n) {\n    let (note_type_id, storage_slot, packed_note) =\n        decode_private_note_msg(msg_metadata, msg_content);\n\n    attempt_note_discovery(\n        contract_address,\n        tx_hash,\n        unique_note_hashes_in_tx,\n        first_nullifier_in_tx,\n        recipient,\n        compute_note_hash_and_nullifier,\n        storage_slot,\n        note_type_id,\n        packed_note,\n    );\n}\n\n/// Attempts discovery of a note given information about its contents and the transaction in which it is\n/// suspected the note was created.\npub unconstrained fn attempt_note_discovery<Env>(\n    contract_address: AztecAddress,\n    tx_hash: Field,\n    unique_note_hashes_in_tx: BoundedVec<Field, MAX_NOTE_HASHES_PER_TX>,\n    first_nullifier_in_tx: Field,\n    recipient: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n    storage_slot: Field,\n    note_type_id: Field,\n    packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n) {\n    let discovered_notes = attempt_note_nonce_discovery(\n        unique_note_hashes_in_tx,\n        first_nullifier_in_tx,\n        compute_note_hash_and_nullifier,\n        contract_address,\n        storage_slot,\n        note_type_id,\n        packed_note,\n    );\n\n    debug_log_format(\n        \"Discovered {0} notes from a private message\",\n        [discovered_notes.len() as Field],\n    );\n\n    discovered_notes.for_each(|discovered_note| {\n        // TODO:(#10728): handle notes that fail delivery. This could be due to e.g. a temporary node connectivity\n        // issue, and we should perhaps not have marked the tag index as taken.\n        assert(\n            oracle::message_discovery::deliver_note(\n                contract_address,\n                storage_slot,\n                discovered_note.nonce,\n                packed_note,\n                discovered_note.note_hash,\n                discovered_note.inner_nullifier,\n                tx_hash,\n                recipient,\n            ),\n            \"Failed to deliver note\",\n        );\n    });\n}\n\nfn decode_private_note_msg(\n    msg_metadata: u64,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n) -> (Field, Field, BoundedVec<Field, MAX_NOTE_PACKED_LEN>) {\n    let note_type_id = msg_metadata as Field; // TODO: make note type id not be a full field\n\n    assert(\n        msg_content.len() > PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN,\n        f\"Invalid private note message: all private note messages must have at least {PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN} fields\",\n    );\n\n    // If PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN is changed, causing the assertion below to fail, then the\n    // destructuring of the private note message encoding below must be updated as well.\n    std::static_assert(\n        PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN == 1,\n        \"unexpected value for PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN\",\n    );\n\n    // We currently have a single field that is not the note's packed representation, which is the storage slot.\n    let storage_slot = msg_content.get(0);\n    let packed_note = array::subbvec(msg_content, PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN);\n\n    (note_type_id, storage_slot, packed_note)\n}\n"},"107":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/messages/encoding.nr","source":"// TODO(#12750): don't make these values assume we're using AES.\nuse crate::{\n    messages::encryption::log_encryption::PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS, utils::array,\n};\n\nglobal MAX_MESSAGE_LEN: u32 = PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS;\n\nglobal MESSAGE_EXPANDED_METADATA_LEN: u32 = 1;\n\n// The standard message layout is composed of:\n//  - an initial field called the 'expanded metadata'\n//  - an arbitrary number of fields following that called the 'message content'\n//\n// ```\n// message: [ msg_expanded_metadata, ...msg_content ]\n// ```\n//\n// The expanded metadata itself is interpreted as a u128, of which:\n//  - the upper 64 bits are the message type id\n//  - the lower 64 bits are called the 'message metadata'\n//\n// ```\n// msg_expanded_metadata: [  msg_type_id    |  msg_metadata  ]\n//                        <---  64 bits --->|<--- 64 bits --->\n// ```\n//\n// The meaning of the message metadata and message content depend on the value of the message type id. Note that there\n// is nothing special about the message metadata, it _can_ be considered part of the content. It just has a different\n// name to make it distinct from the message content given that it is not a full field.\n\n/// The maximum length of a message's content, i.e. not including the expanded message metadata.\npub global MAX_MESSAGE_CONTENT_LEN: u32 = MAX_MESSAGE_LEN - MESSAGE_EXPANDED_METADATA_LEN;\n\n/// Encodes a message following aztec-nr's standard message encoding. This message can later be decoded with\n/// `decode_message` to retrieve the original values.\n///\n/// - The `msg_type` is an identifier that groups types of messages that are all processed the same way, e.g. private\n/// notes or events. Possible values are defined in `aztec::messages::msg_type`.\n/// - The `msg_metadata` and `msg_content` are the values stored in the message, whose meaning depends on the\n///  `msg_type`. The only special thing about `msg_metadata` that separates it from `msg_content` is that it is a u64\n/// instead of a full Field (due to details of how messages are encoded), allowing applications that can fit values into\n/// this smaller variable to achieve higher data efficiency.\npub fn encode_message<let N: u32>(\n    msg_type: u64,\n    msg_metadata: u64,\n    msg_content: [Field; N],\n) -> [Field; (N + MESSAGE_EXPANDED_METADATA_LEN)] {\n    std::static_assert(\n        msg_content.len() <= MAX_MESSAGE_CONTENT_LEN,\n        \"Invalid message content: it must have a length of at most MAX_MESSAGE_CONTENT_LEN\",\n    );\n\n    // If MESSAGE_EXPANDED_METADATA_LEN is changed, causing the assertion below to fail, then the destructuring of\n    // the message encoding below must be updated as well.\n    std::static_assert(\n        MESSAGE_EXPANDED_METADATA_LEN == 1,\n        \"unexpected value for MESSAGE_EXPANDED_METADATA_LEN\",\n    );\n    let mut message: [Field; (N + MESSAGE_EXPANDED_METADATA_LEN)] = std::mem::zeroed();\n\n    message[0] = to_expanded_metadata(msg_type, msg_metadata);\n    for i in 0..msg_content.len() {\n        message[MESSAGE_EXPANDED_METADATA_LEN + i] = msg_content[i];\n    }\n\n    message\n}\n\n/// Decodes a standard aztec-nr message, i.e. one created via `encode_message`, returning the original encoded values.\n///\n/// Note that `encode_message` returns a fixed size array while this function takes a `BoundedVec`: this is because\n/// prior to decoding the message type is unknown, and consequentially not known at compile time. If working with\n/// fixed-size messages, consider using `BoundedVec::from_array` to convert them.\npub unconstrained fn decode_message(\n    message: BoundedVec<Field, MAX_MESSAGE_LEN>,\n) -> (u64, u64, BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>) {\n    assert(\n        message.len() >= MESSAGE_EXPANDED_METADATA_LEN,\n        f\"Invalid message: it must have at least {MESSAGE_EXPANDED_METADATA_LEN} fields\",\n    );\n\n    // If MESSAGE_EXPANDED_METADATA_LEN is changed, causing the assertion below to fail, then the destructuring of\n    // the message encoding below must be updated as well.\n    std::static_assert(\n        MESSAGE_EXPANDED_METADATA_LEN == 1,\n        \"unexpected value for MESSAGE_EXPANDED_METADATA_LEN\",\n    );\n\n    let msg_expanded_metadata = message.get(0);\n    let (msg_type_id, msg_metadata) = from_expanded_metadata(msg_expanded_metadata);\n    let msg_content = array::subbvec(message, MESSAGE_EXPANDED_METADATA_LEN);\n\n    (msg_type_id, msg_metadata, msg_content)\n}\n\nglobal U64_SHIFT_MULTIPLIER: Field = 2.pow_32(64);\n\nfn to_expanded_metadata(msg_type: u64, msg_metadata: u64) -> Field {\n    // We use multiplication instead of bit shifting operations to shift the type bits as bit shift operations are\n    // expensive in circuits.\n    let type_field: Field = (msg_type as Field) * U64_SHIFT_MULTIPLIER;\n    let msg_metadata_field = msg_metadata as Field;\n\n    type_field + msg_metadata_field\n}\n\nfn from_expanded_metadata(input: Field) -> (u64, u64) {\n    input.assert_max_bit_size::<128>();\n    let msg_metadata = (input as u64);\n    let msg_type = ((input - (msg_metadata as Field)) / U64_SHIFT_MULTIPLIER) as u64;\n    // Use division instead of bit shift since bit shifts are expensive in circuits\n    (msg_type, msg_metadata)\n}\n\nmod tests {\n    use crate::utils::array::subarray::subarray;\n    use super::{\n        decode_message, encode_message, from_expanded_metadata, MAX_MESSAGE_CONTENT_LEN,\n        to_expanded_metadata,\n    };\n\n    global U64_MAX: u64 = (2.pow_32(64) - 1) as u64;\n    global U128_MAX: Field = (2.pow_32(128) - 1);\n\n    #[test]\n    unconstrained fn encode_decode_empty_message(msg_type: u64, msg_metadata: u64) {\n        let encoded = encode_message(msg_type, msg_metadata, []);\n        let (decoded_msg_type, decoded_msg_metadata, decoded_msg_content) =\n            decode_message(BoundedVec::from_array(encoded));\n\n        assert_eq(decoded_msg_type, msg_type);\n        assert_eq(decoded_msg_metadata, msg_metadata);\n        assert_eq(decoded_msg_content.len(), 0);\n    }\n\n    #[test]\n    unconstrained fn encode_decode_short_message(\n        msg_type: u64,\n        msg_metadata: u64,\n        msg_content: [Field; MAX_MESSAGE_CONTENT_LEN / 2],\n    ) {\n        let encoded = encode_message(msg_type, msg_metadata, msg_content);\n        let (decoded_msg_type, decoded_msg_metadata, decoded_msg_content) =\n            decode_message(BoundedVec::from_array(encoded));\n\n        assert_eq(decoded_msg_type, msg_type);\n        assert_eq(decoded_msg_metadata, msg_metadata);\n        assert_eq(decoded_msg_content.len(), msg_content.len());\n        assert_eq(subarray(decoded_msg_content.storage(), 0), msg_content);\n    }\n\n    #[test]\n    unconstrained fn encode_decode_full_message(\n        msg_type: u64,\n        msg_metadata: u64,\n        msg_content: [Field; MAX_MESSAGE_CONTENT_LEN],\n    ) {\n        let encoded = encode_message(msg_type, msg_metadata, msg_content);\n        let (decoded_msg_type, decoded_msg_metadata, decoded_msg_content) =\n            decode_message(BoundedVec::from_array(encoded));\n\n        assert_eq(decoded_msg_type, msg_type);\n        assert_eq(decoded_msg_metadata, msg_metadata);\n        assert_eq(decoded_msg_content.len(), msg_content.len());\n        assert_eq(subarray(decoded_msg_content.storage(), 0), msg_content);\n    }\n\n    #[test]\n    unconstrained fn to_expanded_metadata_packing() {\n        // Test case 1: All bits set\n        let packed = to_expanded_metadata(U64_MAX, U64_MAX);\n        let (msg_type, msg_metadata) = from_expanded_metadata(packed);\n        assert_eq(msg_type, U64_MAX);\n        assert_eq(msg_metadata, U64_MAX);\n\n        // Test case 2: Only log type bits set\n        let packed = to_expanded_metadata(U64_MAX, 0);\n        let (msg_type, msg_metadata) = from_expanded_metadata(packed);\n        assert_eq(msg_type, U64_MAX);\n        assert_eq(msg_metadata, 0);\n\n        // Test case 3: Only msg_metadata bits set\n        let packed = to_expanded_metadata(0, U64_MAX);\n        let (msg_type, msg_metadata) = from_expanded_metadata(packed);\n        assert_eq(msg_type, 0);\n        assert_eq(msg_metadata, U64_MAX);\n\n        // Test case 4: No bits set\n        let packed = to_expanded_metadata(0, 0);\n        let (msg_type, msg_metadata) = from_expanded_metadata(packed);\n        assert_eq(msg_type, 0);\n        assert_eq(msg_metadata, 0);\n    }\n\n    #[test]\n    unconstrained fn from_expanded_metadata_packing() {\n        // Test case 1: All bits set\n        let input = U128_MAX as Field;\n        let (msg_type, msg_metadata) = from_expanded_metadata(input);\n        assert_eq(msg_type, U64_MAX);\n        assert_eq(msg_metadata, U64_MAX);\n\n        // Test case 2: Only log type bits set\n        let input = (U128_MAX - U64_MAX as Field);\n        let (msg_type, msg_metadata) = from_expanded_metadata(input);\n        assert_eq(msg_type, U64_MAX);\n        assert_eq(msg_metadata, 0);\n\n        // Test case 3: Only msg_metadata bits set\n        let input = U64_MAX as Field;\n        let (msg_type, msg_metadata) = from_expanded_metadata(input);\n        assert_eq(msg_type, 0);\n        assert_eq(msg_metadata, U64_MAX);\n\n        // Test case 4: No bits set\n        let input = 0;\n        let (msg_type, msg_metadata) = from_expanded_metadata(input);\n        assert_eq(msg_type, 0);\n        assert_eq(msg_metadata, 0);\n    }\n\n    #[test]\n    unconstrained fn to_from_expanded_metadata(original_msg_type: u64, original_msg_metadata: u64) {\n        let packed = to_expanded_metadata(original_msg_type, original_msg_metadata);\n        let (unpacked_msg_type, unpacked_msg_metadata) = from_expanded_metadata(packed);\n\n        assert_eq(original_msg_type, unpacked_msg_type);\n        assert_eq(original_msg_metadata, unpacked_msg_metadata);\n    }\n}\n"},"108":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/messages/encryption/aes128.nr","source":"use dep::protocol_types::{\n    constants::{GENERATOR_INDEX__SYMMETRIC_KEY, GENERATOR_INDEX__SYMMETRIC_KEY_2},\n    hash::poseidon2_hash_with_separator,\n    point::Point,\n};\n\nuse crate::{\n    keys::{\n        ecdh_shared_secret::derive_ecdh_shared_secret_using_aztec_address,\n        ephemeral::generate_ephemeral_key_pair,\n    },\n    messages::{\n        encryption::log_encryption::{\n            EPH_PK_SIGN_BYTE_SIZE_IN_BYTES, EPH_PK_X_SIZE_IN_FIELDS,\n            HEADER_CIPHERTEXT_SIZE_IN_BYTES, LogEncryption, PRIVATE_LOG_CIPHERTEXT_LEN,\n            PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS,\n        },\n        logs::arithmetic_generics_utils::{\n            get_arr_of_size__log_bytes__from_PT, get_arr_of_size__log_bytes_padding__from_PT,\n        },\n    },\n    oracle::{aes128_decrypt::aes128_decrypt_oracle, shared_secret::get_shared_secret},\n    prelude::AztecAddress,\n    utils::{\n        array,\n        conversion::{\n            bytes_to_fields::{bytes_from_fields, bytes_to_fields},\n            fields_to_bytes::{fields_from_bytes, fields_to_bytes},\n        },\n        point::{get_sign_of_point, point_from_x_coord_and_sign, point_to_bytes},\n        random::get_random_bytes,\n    },\n};\n\nuse std::aes128::aes128_encrypt;\n\nfn extract_close_to_uniformly_random_256_bits_from_ecdh_shared_secret_using_poseidon2(\n    shared_secret: Point,\n) -> [u8; 32] {\n    let rand1: Field = poseidon2_hash_with_separator(\n        [shared_secret.x, shared_secret.y],\n        GENERATOR_INDEX__SYMMETRIC_KEY,\n    );\n    let rand2: Field = poseidon2_hash_with_separator(\n        [shared_secret.x, shared_secret.y],\n        GENERATOR_INDEX__SYMMETRIC_KEY_2,\n    );\n    let rand1_bytes: [u8; 16] = rand1.to_le_bytes();\n    let rand2_bytes: [u8; 16] = rand2.to_le_bytes();\n    let mut bytes: [u8; 32] = [0; 32];\n    for i in 0..16 {\n        bytes[i] = rand1_bytes[i];\n        bytes[i + 1] = rand2_bytes[i];\n    }\n    bytes\n}\n\n// TODO(#10537): Consider nuking this function.\nfn extract_close_to_uniformly_random_256_bits_from_ecdh_shared_secret_using_sha256(\n    shared_secret: Point,\n) -> [u8; 32] {\n    let shared_secret_bytes: [u8; 32] = point_to_bytes(shared_secret);\n\n    let mut shared_secret_bytes_with_separator: [u8; 33] = std::mem::zeroed();\n    for i in 0..shared_secret_bytes.len() {\n        shared_secret_bytes_with_separator[i] = shared_secret_bytes[i];\n    }\n    shared_secret_bytes_with_separator[32] = GENERATOR_INDEX__SYMMETRIC_KEY;\n\n    sha256::digest(shared_secret_bytes_with_separator)\n}\n\nfn derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret(\n    shared_secret: Point,\n    randomness_extraction_fn: fn(Point) -> [u8; 32],\n) -> ([u8; 16], [u8; 16]) {\n    let random_256_bits = randomness_extraction_fn(shared_secret);\n    let mut sym_key = [0; 16];\n    let mut iv = [0; 16];\n    for i in 0..16 {\n        sym_key[i] = random_256_bits[i];\n        iv[i] = random_256_bits[i + 16];\n    }\n    (sym_key, iv)\n}\n\n// TODO(#10537): Consider nuking this function.\npub fn derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_sha256(\n    shared_secret: Point,\n) -> ([u8; 16], [u8; 16]) {\n    derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret(\n        shared_secret,\n        extract_close_to_uniformly_random_256_bits_from_ecdh_shared_secret_using_sha256,\n    )\n}\n\n// TODO(#10537): This function is currently unused. Consider using it instead of the sha256 one.\npub fn derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_poseidon2(\n    shared_secret: Point,\n) -> ([u8; 16], [u8; 16]) {\n    derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret(\n        shared_secret,\n        extract_close_to_uniformly_random_256_bits_from_ecdh_shared_secret_using_poseidon2,\n    )\n}\n\npub struct AES128 {}\n\nimpl LogEncryption for AES128 {\n    fn encrypt_log<let PLAINTEXT_LEN: u32>(\n        plaintext: [Field; PLAINTEXT_LEN],\n        recipient: AztecAddress,\n    ) -> [Field; PRIVATE_LOG_CIPHERTEXT_LEN] {\n        // AES 128 operates on bytes, not fields, so we need to convert the fields to bytes.\n        // (This process is then reversed when processing the log in `do_process_log`)\n        let plaintext_bytes = fields_to_bytes(plaintext);\n\n        // *****************************************************************************\n        // Compute the shared secret\n        // *****************************************************************************\n\n        let (eph_sk, eph_pk) = generate_ephemeral_key_pair();\n\n        let eph_pk_sign_byte: u8 = get_sign_of_point(eph_pk) as u8;\n\n        // (not to be confused with the tagging shared secret)\n        let ciphertext_shared_secret =\n            derive_ecdh_shared_secret_using_aztec_address(eph_sk, recipient);\n\n        // TODO: also use this shared secret for deriving note randomness.\n\n        // *****************************************************************************\n        // Convert the plaintext into whatever format the encryption function expects\n        // *****************************************************************************\n\n        // Already done for this strategy: AES expects bytes.\n\n        // *****************************************************************************\n        // Encrypt the plaintext\n        // *****************************************************************************\n\n        let (sym_key, iv) = derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_sha256(\n            ciphertext_shared_secret,\n        );\n\n        let ciphertext_bytes = aes128_encrypt(plaintext_bytes, iv, sym_key);\n\n        // |full_pt| = |pt_length| + |pt|\n        // |pt_aes_padding| = 16 - (|full_pt| % 16)\n        // or... since a % b is the same as a - b * (a // b) (integer division), so:\n        // |pt_aes_padding| = 16 - (|full_pt| - 16 * (|full_pt| // 16))\n        // |ct| = |full_pt| + |pt_aes_padding|\n        //      = |full_pt| + 16 - (|full_pt| - 16 * (|full_pt| // 16))\n        //      = 16 + 16 * (|full_pt| // 16)\n        //      = 16 * (1 + |full_pt| // 16)\n        assert(ciphertext_bytes.len() == 16 * (1 + (PLAINTEXT_LEN * 32) / 16));\n\n        // *****************************************************************************\n        // Compute the header ciphertext\n        // *****************************************************************************\n\n        // Header contains only the length of the ciphertext stored in 2 bytes.\n        // TODO: consider nuking the header altogether and just have a fixed-size ciphertext by padding the plaintext.\n        // This would be more costly constraint-wise but cheaper DA-wise.\n        let mut header_plaintext: [u8; 2] = [0 as u8; 2];\n        let ciphertext_bytes_length = ciphertext_bytes.len();\n        header_plaintext[0] = (ciphertext_bytes_length >> 8) as u8;\n        header_plaintext[1] = ciphertext_bytes_length as u8;\n\n        // TODO: this is insecure and wasteful:\n        // \"Insecure\", because the esk shouldn't be used twice (once for the header,\n        // and again for the proper ciphertext) (at least, I never got the\n        // \"go ahead\" that this would be safe, unfortunately).\n        // \"Wasteful\", because the exact same computation is happening further down.\n        // I'm leaving that 2nd computation where it is, because this 1st computation\n        // will be imminently deleted, when the header logic is deleted.\n        let (sym_key, iv) = derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_sha256(\n            ciphertext_shared_secret,\n        );\n\n        // Note: the aes128_encrypt builtin fn automatically appends bytes to the\n        // input, according to pkcs#7; hence why the output `header_ciphertext_bytes` is 16\n        // bytes larger than the input in this case.\n        let header_ciphertext_bytes = aes128_encrypt(header_plaintext, iv, sym_key);\n        // I recall that converting a slice to an array incurs constraints, so I'll check the length this way instead:\n        assert(header_ciphertext_bytes.len() == HEADER_CIPHERTEXT_SIZE_IN_BYTES);\n\n        // *****************************************************************************\n        // Prepend / append more bytes of data to the ciphertext, before converting back\n        // to fields.\n        // *****************************************************************************\n\n        let mut log_bytes_padding_to_mult_31 =\n            get_arr_of_size__log_bytes_padding__from_PT::<PLAINTEXT_LEN * 32>();\n        // Safety: this randomness won't be constrained to be random. It's in the\n        // interest of the executor of this fn to encrypt with random bytes.\n        log_bytes_padding_to_mult_31 = unsafe { get_random_bytes() };\n\n        let mut log_bytes = get_arr_of_size__log_bytes__from_PT::<PLAINTEXT_LEN * 32>();\n\n        assert(\n            log_bytes.len() % 31 == 0,\n            \"Unexpected error: log_bytes.len() should be divisible by 31, by construction.\",\n        );\n\n        log_bytes[0] = eph_pk_sign_byte;\n        let mut offset = 1;\n        for i in 0..header_ciphertext_bytes.len() {\n            log_bytes[offset + i] = header_ciphertext_bytes[i];\n        }\n        offset += header_ciphertext_bytes.len();\n\n        for i in 0..ciphertext_bytes.len() {\n            log_bytes[offset + i] = ciphertext_bytes[i];\n        }\n        offset += ciphertext_bytes.len();\n\n        for i in 0..log_bytes_padding_to_mult_31.len() {\n            log_bytes[offset + i] = log_bytes_padding_to_mult_31[i];\n        }\n\n        assert(\n            offset + log_bytes_padding_to_mult_31.len() == log_bytes.len(),\n            \"Something has gone wrong\",\n        );\n\n        // *****************************************************************************\n        // Convert bytes back to fields\n        // *****************************************************************************\n\n        // TODO(#12749): As Mike pointed out, we need to make logs produced by different encryption schemes\n        // indistinguishable from each other and for this reason the output here and in the last for-loop of this function\n        // should cover a full field.\n        let log_bytes_as_fields = bytes_to_fields(log_bytes);\n\n        // *****************************************************************************\n        // Prepend / append fields, to create the final log\n        // *****************************************************************************\n\n        let mut ciphertext: [Field; PRIVATE_LOG_CIPHERTEXT_LEN] = [0; PRIVATE_LOG_CIPHERTEXT_LEN];\n\n        ciphertext[0] = eph_pk.x;\n\n        let mut offset = 1;\n        for i in 0..log_bytes_as_fields.len() {\n            ciphertext[offset + i] = log_bytes_as_fields[i];\n        }\n        offset += log_bytes_as_fields.len();\n\n        for i in offset..PRIVATE_LOG_CIPHERTEXT_LEN {\n            // We need to get a random value that fits in 31 bytes to not leak information about the size of the log\n            // (all the \"real\" log fields contain at most 31 bytes because of the way we convert the bytes to fields).\n            // TODO(#12749): Long term, this is not a good solution.\n\n            // Safety: we assume that the sender wants for the log to be private - a malicious one could simply reveal its\n            // contents publicly. It is therefore fine to trust the sender to provide random padding.\n            let field_bytes = unsafe { get_random_bytes::<31>() };\n            ciphertext[i] = Field::from_be_bytes::<31>(field_bytes);\n        }\n\n        ciphertext\n    }\n\n    unconstrained fn decrypt_log(\n        ciphertext: BoundedVec<Field, PRIVATE_LOG_CIPHERTEXT_LEN>,\n        recipient: AztecAddress,\n    ) -> BoundedVec<Field, PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS> {\n        let eph_pk_x = ciphertext.get(0);\n\n        let ciphertext_without_eph_pk_x_fields = array::subbvec::<Field, PRIVATE_LOG_CIPHERTEXT_LEN, PRIVATE_LOG_CIPHERTEXT_LEN - EPH_PK_X_SIZE_IN_FIELDS>(\n            ciphertext,\n            EPH_PK_X_SIZE_IN_FIELDS,\n        );\n\n        // Convert the ciphertext represented as fields to a byte representation (its original format)\n        let ciphertext_without_eph_pk_x = bytes_from_fields(ciphertext_without_eph_pk_x_fields);\n\n        // First byte of the ciphertext represents the ephemeral public key sign\n        let eph_pk_sign_bool = ciphertext_without_eph_pk_x.get(0) as bool;\n        // With the sign and the x-coordinate of the ephemeral public key, we can reconstruct the point\n        let eph_pk = point_from_x_coord_and_sign(eph_pk_x, eph_pk_sign_bool);\n\n        // Derive shared secret and symmetric key\n        let ciphertext_shared_secret = get_shared_secret(recipient, eph_pk);\n        let (sym_key, iv) = derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_sha256(\n            ciphertext_shared_secret,\n        );\n\n        // Extract the header ciphertext\n        let header_start = EPH_PK_SIGN_BYTE_SIZE_IN_BYTES; // Skip eph_pk_sign byte\n        let header_ciphertext: [u8; HEADER_CIPHERTEXT_SIZE_IN_BYTES] =\n            array::subarray(ciphertext_without_eph_pk_x.storage(), header_start);\n        // We need to convert the array to a BoundedVec because the oracle expects a BoundedVec as it's designed to work\n        // with logs with unknown length at compile time. This would not be necessary here as the header ciphertext length\n        // is fixed. But we do it anyway to not have to have duplicate oracles.\n        let header_ciphertext_bvec =\n            BoundedVec::<u8, HEADER_CIPHERTEXT_SIZE_IN_BYTES>::from_array(header_ciphertext);\n\n        // Decrypt header\n        let header_plaintext = aes128_decrypt_oracle(header_ciphertext_bvec, iv, sym_key);\n\n        // Extract ciphertext length from header (2 bytes, big-endian)\n        let ciphertext_length =\n            ((header_plaintext.get(0) as u32) << 8) | (header_plaintext.get(1) as u32);\n\n        // Extract and decrypt main ciphertext\n        let ciphertext_start = header_start + HEADER_CIPHERTEXT_SIZE_IN_BYTES;\n        let ciphertext_with_padding: [u8; (PRIVATE_LOG_CIPHERTEXT_LEN - EPH_PK_X_SIZE_IN_FIELDS) * 31 - HEADER_CIPHERTEXT_SIZE_IN_BYTES - EPH_PK_SIGN_BYTE_SIZE_IN_BYTES] =\n            array::subarray(ciphertext_without_eph_pk_x.storage(), ciphertext_start);\n        let ciphertext: BoundedVec<u8, (PRIVATE_LOG_CIPHERTEXT_LEN - EPH_PK_X_SIZE_IN_FIELDS) * 31 - HEADER_CIPHERTEXT_SIZE_IN_BYTES - EPH_PK_SIGN_BYTE_SIZE_IN_BYTES> =\n            BoundedVec::from_parts(ciphertext_with_padding, ciphertext_length);\n\n        // Decrypt main ciphertext and return it\n        let plaintext_bytes = aes128_decrypt_oracle(ciphertext, iv, sym_key);\n\n        // Each field of the original note log was serialized to 32 bytes so we convert the bytes back to fields.\n        fields_from_bytes(plaintext_bytes)\n    }\n}\n\nmod test {\n    use crate::{\n        keys::ecdh_shared_secret::derive_ecdh_shared_secret_using_aztec_address,\n        messages::encryption::log_encryption::{LogEncryption, PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS},\n        test::helpers::test_environment::TestEnvironment,\n    };\n    use super::AES128;\n    use protocol_types::{\n        address::AztecAddress,\n        indexed_tagging_secret::IndexedTaggingSecret,\n        traits::{Deserialize, FromField},\n    };\n    use std::{embedded_curve_ops::EmbeddedCurveScalar, test::OracleMock};\n\n    #[test]\n    unconstrained fn encrypt_decrypt_log() {\n        let mut env = TestEnvironment::new();\n        // Advance 1 block so we can read historic state from private\n        env.advance_block_by(1);\n\n        let plaintext = [1, 2, 3];\n\n        let recipient = AztecAddress::from_field(\n            0x25afb798ea6d0b8c1618e50fdeafa463059415013d3b7c75d46abf5e242be70c,\n        );\n\n        // Mock random values for deterministic test\n        let eph_sk = 0x1358d15019d4639393d62b97e1588c095957ce74a1c32d6ec7d62fe6705d9538;\n        let _ = OracleMock::mock(\"getRandomField\").returns(eph_sk).times(1);\n\n        let randomness = 0x0101010101010101010101010101010101010101010101010101010101010101;\n        let _ = OracleMock::mock(\"getRandomField\").returns(randomness).times(1000000);\n\n        let _ = OracleMock::mock(\"getIndexedTaggingSecretAsSender\").returns(\n            IndexedTaggingSecret::deserialize([69420, 1337]),\n        );\n        let _ = OracleMock::mock(\"incrementAppTaggingSecretIndexAsSender\").returns(());\n\n        // Encrypt the log\n        let encrypted_log = BoundedVec::from_array(AES128::encrypt_log(plaintext, recipient));\n\n        // Mock shared secret for deterministic test\n        let shared_secret = derive_ecdh_shared_secret_using_aztec_address(\n            EmbeddedCurveScalar::from_field(eph_sk),\n            recipient,\n        );\n        let _ = OracleMock::mock(\"getSharedSecret\").returns(shared_secret);\n\n        // Decrypt the log\n        let decrypted = AES128::decrypt_log(encrypted_log, recipient);\n\n        // The decryption function spits out a BoundedVec because it's designed to work with logs with unknown length\n        // at compile time. For this reason we need to convert the original input to a BoundedVec.\n        let plaintext_bvec =\n            BoundedVec::<Field, PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS>::from_array(plaintext);\n\n        // Verify decryption matches original plaintext\n        assert_eq(decrypted, plaintext_bvec, \"Decrypted bytes should match original plaintext\");\n\n        // The following is a workaround of \"struct is never constructed\" Noir compilation error (we only ever use\n        // static methods of the struct).\n        let _ = AES128 {};\n    }\n}\n"},"12":{"path":"std/convert.nr","source":"// docs:start:from-trait\npub trait From<T> {\n    fn from(input: T) -> Self;\n}\n// docs:end:from-trait\n\nimpl<T> From<T> for T {\n    fn from(input: T) -> T {\n        input\n    }\n}\n\n// docs:start:into-trait\npub trait Into<T> {\n    fn into(self) -> T;\n}\n\nimpl<T, U> Into<T> for U\nwhere\n    T: From<U>,\n{\n    fn into(self) -> T {\n        T::from(self)\n    }\n}\n// docs:end:into-trait\n\n// docs:start:from-impls\n// Unsigned integers\n\nimpl From<u8> for u32 {\n    fn from(value: u8) -> u32 {\n        value as u32\n    }\n}\n\nimpl From<u8> for u64 {\n    fn from(value: u8) -> u64 {\n        value as u64\n    }\n}\nimpl From<u32> for u64 {\n    fn from(value: u32) -> u64 {\n        value as u64\n    }\n}\n\nimpl From<u8> for u128 {\n    fn from(value: u8) -> u128 {\n        value as u128\n    }\n}\nimpl From<u32> for u128 {\n    fn from(value: u32) -> u128 {\n        value as u128\n    }\n}\nimpl From<u64> for u128 {\n    fn from(value: u64) -> u128 {\n        value as u128\n    }\n}\n\nimpl From<u8> for Field {\n    fn from(value: u8) -> Field {\n        value as Field\n    }\n}\nimpl From<u32> for Field {\n    fn from(value: u32) -> Field {\n        value as Field\n    }\n}\nimpl From<u64> for Field {\n    fn from(value: u64) -> Field {\n        value as Field\n    }\n}\n\nimpl From<u128> for Field {\n    fn from(value: u128) -> Field {\n        value as Field\n    }\n}\n\n// Signed integers\n\nimpl From<i8> for i32 {\n    fn from(value: i8) -> i32 {\n        value as i32\n    }\n}\n\nimpl From<i8> for i64 {\n    fn from(value: i8) -> i64 {\n        value as i64\n    }\n}\nimpl From<i32> for i64 {\n    fn from(value: i32) -> i64 {\n        value as i64\n    }\n}\n\n// Booleans\nimpl From<bool> for u8 {\n    fn from(value: bool) -> u8 {\n        value as u8\n    }\n}\nimpl From<bool> for u32 {\n    fn from(value: bool) -> u32 {\n        value as u32\n    }\n}\nimpl From<bool> for u64 {\n    fn from(value: bool) -> u64 {\n        value as u64\n    }\n}\nimpl From<bool> for i8 {\n    fn from(value: bool) -> i8 {\n        value as i8\n    }\n}\nimpl From<bool> for i32 {\n    fn from(value: bool) -> i32 {\n        value as i32\n    }\n}\nimpl From<bool> for i64 {\n    fn from(value: bool) -> i64 {\n        value as i64\n    }\n}\nimpl From<bool> for Field {\n    fn from(value: bool) -> Field {\n        value as Field\n    }\n}\n// docs:end:from-impls\n\n/// A generic interface for casting between primitive types,\n/// equivalent of using the `as` keyword between values.\n///\n/// # Example\n///\n/// ```\n/// let x: Field = 1234567890;\n/// let y: u8 = x as u8;\n/// let z: u8 = x.as_();\n/// assert_eq(y, z);\n/// ```\npub trait AsPrimitive<T> {\n    /// The equivalent of doing `self as T`.\n    fn as_(self) -> T;\n}\n\n#[generate_as_primitive_impls]\ncomptime fn generate_as_primitive_impls(_: FunctionDefinition) -> Quoted {\n    let types = [\n        quote { bool },\n        quote { u8 },\n        quote { u16 },\n        quote { u32 },\n        quote { u64 },\n        quote { u128 },\n        quote { i8 },\n        quote { i16 },\n        quote { i32 },\n        quote { i64 },\n        quote { Field },\n    ];\n\n    let mut impls = &[];\n    for type1 in types {\n        for type2 in types {\n            impls = impls.push_back(\n                quote {\n                impl AsPrimitive<$type1> for $type2 {\n                    fn as_(self) -> $type1 {\n                        self as $type1\n                    }\n                }\n            },\n            );\n        }\n    }\n    impls.join(quote {})\n}\n"},"129":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/note/note_metadata.nr","source":"use protocol_types::traits::Serialize;\n\n// There's temporarily quite a bit of boilerplate here because Noir does not yet support enums. This file will\n// eventually be simplified into something closer to:\n//\n// pub enum NoteMetadata {\n//   PendingSamePhase{ note_hash_counter: u32 },\n//   PendingOtherPhase{ note_hash_counter: u32, nonce: Field },\n//   Settled{ nonce: Field },\n// }\n//\n// For now, we have `NoteMetadata` acting as a sort of tagged union.\n\nstruct NoteStageEnum {\n    /// A note that was created in the transaction that is currently being executed, during the current execution phase,\n    /// i.e. non-revertible or revertible.\n    ///\n    /// These notes are not yet in the note hash tree, though they will be inserted unless nullified in this transaction\n    /// (becoming a transient note).\n    PENDING_SAME_PHASE: u8,\n    /// A note that was created in the transaction that is currently being executed, during the previous execution\n    /// phase. Because there are only two phases and their order is always the same (first non-revertible and then\n    /// revertible) this implies that the note was created in the non-revertible phase, and that the current phase is\n    /// the revertible phase.\n    ///\n    /// These notes are not yet in the note hash tree, though they will be inserted **even if nullified in this\n    /// transaction**. This means that they must be nullified as if they were settled (i.e. using the unique note hash)\n    /// in order to avoid double spends once they become settled.\n    PENDING_PREVIOUS_PHASE: u8,\n    /// A note that was created in a prior transaction and is therefore already in the note hash tree.\n    SETTLED: u8,\n}\n\nglobal NoteStage: NoteStageEnum =\n    NoteStageEnum { PENDING_SAME_PHASE: 1, PENDING_PREVIOUS_PHASE: 2, SETTLED: 3 };\n\n/// The metadata required to both prove a note's existence and destroy it, by computing the correct note hash for kernel\n/// read requests, as well as the correct nullifier to avoid double-spends.\n///\n/// This represents a note in any of the three valid stages (pending same phase, pending previous phase, or settled). In\n/// order to access the underlying fields callers must first find the appropriate stage (e.g. via `is_settled()`) and\n/// then convert this into the appropriate type (e.g. via `to_settled()`).\n#[derive(Eq, Serialize)]\npub struct NoteMetadata {\n    stage: u8,\n    maybe_nonce: Field,\n}\n\nimpl NoteMetadata {\n    /// Constructs a `NoteMetadata` object from optional note hash counter and nonce. Both a zero note hash counter and\n    /// a zero nonce are invalid, so those are used to signal non-existent values.\n    pub fn from_raw_data(nonzero_note_hash_counter: bool, maybe_nonce: Field) -> Self {\n        if nonzero_note_hash_counter {\n            if maybe_nonce == 0 {\n                Self { stage: NoteStage.PENDING_SAME_PHASE, maybe_nonce }\n            } else {\n                Self { stage: NoteStage.PENDING_PREVIOUS_PHASE, maybe_nonce }\n            }\n        } else if maybe_nonce != 0 {\n            Self { stage: NoteStage.SETTLED, maybe_nonce }\n        } else {\n            panic(\n                f\"Note has a zero note hash counter and no nonce - existence cannot be proven\",\n            )\n        }\n    }\n\n    /// Returns true if the note is pending **and** from the same phase, i.e. if it's been created in the current\n    /// transaction during the current execution phase (either non-revertible or revertible).\n    pub fn is_pending_same_phase(self) -> bool {\n        self.stage == NoteStage.PENDING_SAME_PHASE\n    }\n\n    /// Returns true if the note is pending **and** from the previous phase, i.e. if it's been created in the current\n    /// transaction during an execution phase prior to the current one. Because private execution only has two phases\n    /// with strict ordering, this implies that the note was created in the non-revertible phase, and that the current\n    /// phase is the revertible phase.\n    pub fn is_pending_previous_phase(self) -> bool {\n        self.stage == NoteStage.PENDING_PREVIOUS_PHASE\n    }\n\n    /// Returns true if the note is settled, i.e. if it's been created in a prior transaction and is therefore already\n    /// in the note hash tree.\n    pub fn is_settled(self) -> bool {\n        self.stage == NoteStage.SETTLED\n    }\n\n    /// Asserts that the metadata is that of a pending note from the same phase and converts it accordingly.\n    pub fn to_pending_same_phase(self) -> PendingSamePhaseNoteMetadata {\n        assert_eq(self.stage, NoteStage.PENDING_SAME_PHASE);\n        PendingSamePhaseNoteMetadata::new()\n    }\n\n    /// Asserts that the metadata is that of a pending note from a previous phase and converts it accordingly.\n    pub fn to_pending_previous_phase(self) -> PendingPreviousPhaseNoteMetadata {\n        assert_eq(self.stage, NoteStage.PENDING_PREVIOUS_PHASE);\n        PendingPreviousPhaseNoteMetadata::new(self.maybe_nonce)\n    }\n\n    /// Asserts that the metadata is that of a settled note and converts it accordingly.\n    pub fn to_settled(self) -> SettledNoteMetadata {\n        assert_eq(self.stage, NoteStage.SETTLED);\n        SettledNoteMetadata::new(self.maybe_nonce)\n    }\n}\n\nimpl From<PendingSamePhaseNoteMetadata> for NoteMetadata {\n    fn from(_value: PendingSamePhaseNoteMetadata) -> Self {\n        NoteMetadata::from_raw_data(true, std::mem::zeroed())\n    }\n}\n\nimpl From<PendingPreviousPhaseNoteMetadata> for NoteMetadata {\n    fn from(value: PendingPreviousPhaseNoteMetadata) -> Self {\n        NoteMetadata::from_raw_data(true, value.nonce())\n    }\n}\n\nimpl From<SettledNoteMetadata> for NoteMetadata {\n    fn from(value: SettledNoteMetadata) -> Self {\n        NoteMetadata::from_raw_data(false, value.nonce())\n    }\n}\n\n/// The metadata required to both prove a note's existence and destroy it, by computing the correct note hash for kernel\n/// read requests, as well as the correct nullifier to avoid double-spends.\n///\n/// This represents a pending same phase note, i.e. a note that was created in the transaction that is currently being\n/// executed during the current execution phase (either non-revertible or revertible).\npub struct PendingSamePhaseNoteMetadata {\n    // This struct contains no fields since there is no metadata associated with a pending same phase note: it has no\n    // nonce (since it may get squashed by a nullifier emitted in the same phase), and while it does have a note hash\n    // counter we cannot constrain its value (and don't need to - only that it is non-zero).\n}\n\nimpl PendingSamePhaseNoteMetadata {\n    pub fn new() -> Self {\n        Self {}\n    }\n}\n\n/// The metadata required to both prove a note's existence and destroy it, by computing the correct note hash for kernel\n/// read requests, as well as the correct nullifier to avoid double-spends.\n///\n/// This represents a pending previous phase note, i.e. a note that was created in the transaction that is currently\n/// being executed, during the previous execution phase. Because there are only two phases and their order is always the\n/// same (first non-revertible and then revertible) this implies that the note was created in the non-revertible phase,\n/// and that the current phase is the revertible phase.\npub struct PendingPreviousPhaseNoteMetadata {\n    nonce: Field,\n    // This struct does not contain a note hash counter, even though one exists for this note, because we cannot\n    // constrain its value (and don't need to - only that it is non-zero).\n}\n\nimpl PendingPreviousPhaseNoteMetadata {\n    pub fn new(nonce: Field) -> Self {\n        Self { nonce }\n    }\n\n    pub fn nonce(self) -> Field {\n        self.nonce\n    }\n}\n\n/// The metadata required to both prove a note's existence and destroy it, by computing the correct note hash for kernel\n/// read requests, as well as the correct nullifier to avoid double-spends.\n///\n/// This represents a settled note, i.e. a note that was created in a prior transaction and is therefore already in the\n/// note hash tree.\npub struct SettledNoteMetadata {\n    nonce: Field,\n}\n\nimpl SettledNoteMetadata {\n    pub fn new(nonce: Field) -> Self {\n        Self { nonce }\n    }\n\n    pub fn nonce(self) -> Field {\n        self.nonce\n    }\n}\n"},"132":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/note/utils.nr","source":"use crate::{\n    context::PrivateContext,\n    note::{note_interface::NoteHash, retrieved_note::RetrievedNote},\n};\n\nuse dep::protocol_types::hash::{\n    compute_siloed_note_hash, compute_siloed_nullifier, compute_unique_note_hash,\n};\n\n/// Returns the note hash that must be used to issue a private kernel read request for a note.\npub fn compute_note_hash_for_read_request<Note>(\n    retrieved_note: RetrievedNote<Note>,\n    storage_slot: Field,\n) -> Field\nwhere\n    Note: NoteHash,\n{\n    let note_hash = retrieved_note.note.compute_note_hash(storage_slot);\n\n    if retrieved_note.metadata.is_settled() {\n        // Settled notes are read by siloing with contract address and nonce (resulting in the final unique note hash,\n        // which is already in the note hash tree).\n        let siloed_note_hash = compute_siloed_note_hash(retrieved_note.contract_address, note_hash);\n        compute_unique_note_hash(\n            retrieved_note.metadata.to_settled().nonce(),\n            siloed_note_hash,\n        )\n    } else {\n        // Pending notes (both same phase and previous phase ones)  re read by their non-siloed hash (not even by\n        // contract address), which is what is stored in the new note hashes array (at the position hinted by note hash\n        // counter).\n        note_hash\n    }\n}\n\n/// Returns the note hash that must be used to compute a note's nullifier when calling `NoteHash::compute_nullifier` or\n/// `NoteHash::compute_nullifier_unconstrained`.\npub fn compute_note_hash_for_nullify<Note>(\n    retrieved_note: RetrievedNote<Note>,\n    storage_slot: Field,\n) -> Field\nwhere\n    Note: NoteHash,\n{\n    compute_note_hash_for_nullify_from_read_request(\n        retrieved_note,\n        compute_note_hash_for_read_request(retrieved_note, storage_slot),\n    )\n}\n\n/// Same as `compute_note_hash_for_nullify`, except it takes the note hash used in a read request (i.e. what\n/// `compute_note_hash_for_read_request` would return). This is useful in scenarios where that hash has already been\n/// computed to reduce constraints by reusing this value.\npub fn compute_note_hash_for_nullify_from_read_request<Note>(\n    retrieved_note: RetrievedNote<Note>,\n    note_hash_for_read_request: Field,\n) -> Field {\n    // There is just one instance in which the note hash for nullification does not match the note hash used for a read\n    // request, which is when dealing with pending previous phase notes. These had their existence proven using their\n    // non-siloed note hash along with the note hash counter (like all pending notes), but since they will be\n    // unconditionally inserted in the note hash tree (since they cannot be squashed) they must be nullified using the\n    // *unique* note hash.\n    // If we didn't, it'd be possible to emit a second different nullifier for the same note in a follow up transaction,\n    // once the note is settled, resulting in a double spend.\n\n    if retrieved_note.metadata.is_pending_previous_phase() {\n        let siloed_note_hash =\n            compute_siloed_note_hash(retrieved_note.contract_address, note_hash_for_read_request);\n        let nonce = retrieved_note.metadata.to_pending_previous_phase().nonce();\n\n        compute_unique_note_hash(nonce, siloed_note_hash)\n    } else {\n        note_hash_for_read_request\n    }\n}\n\n/// Computes a note's siloed nullifier, i.e. the one that will be inserted into the nullifier tree.\npub fn compute_siloed_note_nullifier<Note>(\n    retrieved_note: RetrievedNote<Note>,\n    storage_slot: Field,\n    context: &mut PrivateContext,\n) -> Field\nwhere\n    Note: NoteHash,\n{\n    let note_hash_for_nullify = compute_note_hash_for_nullify(retrieved_note, storage_slot);\n    let inner_nullifier = retrieved_note.note.compute_nullifier(context, note_hash_for_nullify);\n\n    compute_siloed_nullifier(retrieved_note.contract_address, inner_nullifier)\n}\n"},"136":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/oracle/capsules.nr","source":"use protocol_types::{address::AztecAddress, traits::{Deserialize, Serialize}};\n\n/// Stores arbitrary information in a per-contract non-volatile database, which can later be retrieved with `load`. If\n/// data was already stored at this slot, it is overwritten.\npub unconstrained fn store<T, let N: u32>(contract_address: AztecAddress, slot: Field, value: T)\nwhere\n    T: Serialize<N>,\n{\n    let serialized = value.serialize();\n    store_oracle(contract_address, slot, serialized);\n}\n\n/// Returns data previously stored via `storeCapsule` in the per-contract non-volatile database. Returns Option::none() if\n/// nothing was stored at the given slot.\npub unconstrained fn load<T, let N: u32>(contract_address: AztecAddress, slot: Field) -> Option<T>\nwhere\n    T: Deserialize<N>,\n{\n    let serialized_option = load_oracle::<N>(contract_address, slot, N);\n    serialized_option.map(|arr| Deserialize::deserialize(arr))\n}\n\n/// Deletes data in the per-contract non-volatile database. Does nothing if no data was present.\npub unconstrained fn delete(contract_address: AztecAddress, slot: Field) {\n    delete_oracle(contract_address, slot);\n}\n\n/// Copies a number of contiguous entries in the per-contract non-volatile database. This allows for efficient data\n/// structures by avoiding repeated calls to `loadCapsule` and `storeCapsule`.\n/// Supports overlapping source and destination regions (which will result in the overlapped source values being\n/// overwritten). All copied slots must exist in the database (i.e. have been stored and not deleted)\npub unconstrained fn copy(\n    contract_address: AztecAddress,\n    src_slot: Field,\n    dst_slot: Field,\n    num_entries: u32,\n) {\n    copy_oracle(contract_address, src_slot, dst_slot, num_entries);\n}\n\n#[oracle(storeCapsule)]\nunconstrained fn store_oracle<let N: u32>(\n    contract_address: AztecAddress,\n    slot: Field,\n    values: [Field; N],\n) {}\n\n/// We need to pass in `array_len` (the value of N) as a parameter to tell the oracle how many fields the response must\n/// have.\n///\n/// Note that the oracle returns an Option<[Field; N]> because we cannot return an Option<T> directly. That would\n/// require for the oracle resolver to know the shape of T (e.g. if T were a struct of 3 u32 values then the expected\n/// response shape would be 3 single items, whereas it were a struct containing `u32, [Field;10], u32` then the expected\n/// shape would be single, array, single.). Instead, we return the serialization and deserialize in Noir.\n#[oracle(loadCapsule)]\nunconstrained fn load_oracle<let N: u32>(\n    contract_address: AztecAddress,\n    slot: Field,\n    array_len: u32,\n) -> Option<[Field; N]> {}\n\n#[oracle(deleteCapsule)]\nunconstrained fn delete_oracle(contract_address: AztecAddress, slot: Field) {}\n\n#[oracle(copyCapsule)]\nunconstrained fn copy_oracle(\n    contract_address: AztecAddress,\n    src_slot: Field,\n    dst_slot: Field,\n    num_entries: u32,\n) {}\n\nmod test {\n    // These tests are sort of redundant since we already test the oracle implementation directly in TypeScript, but\n    // they are cheap regardless and help ensure both that the TXE implementation works accordingly and that the Noir\n    // oracles are hooked up correctly.\n\n    use crate::{\n        oracle::capsules::{copy, delete, load, store},\n        test::{helpers::test_environment::TestEnvironment, mocks::mock_struct::MockStruct},\n    };\n    use protocol_types::{address::AztecAddress, traits::{FromField, ToField}};\n\n    unconstrained fn setup() -> AztecAddress {\n        let env = TestEnvironment::new();\n        env.contract_address()\n    }\n\n    global SLOT: Field = 1;\n\n    #[test]\n    unconstrained fn stores_and_loads() {\n        let contract_address = setup();\n\n        let value = MockStruct::new(5, 6);\n        store(contract_address, SLOT, value);\n\n        assert_eq(load(contract_address, SLOT).unwrap(), value);\n    }\n\n    #[test]\n    unconstrained fn store_overwrites() {\n        let contract_address = setup();\n\n        let value = MockStruct::new(5, 6);\n        store(contract_address, SLOT, value);\n\n        let new_value = MockStruct::new(7, 8);\n        store(contract_address, SLOT, new_value);\n\n        assert_eq(load(contract_address, SLOT).unwrap(), new_value);\n    }\n\n    #[test]\n    unconstrained fn loads_empty_slot() {\n        let contract_address = setup();\n\n        let loaded_value: Option<MockStruct> = load(contract_address, SLOT);\n        assert_eq(loaded_value, Option::none());\n    }\n\n    #[test]\n    unconstrained fn deletes_stored_value() {\n        let contract_address = setup();\n\n        let value = MockStruct::new(5, 6);\n        store(contract_address, SLOT, value);\n        delete(contract_address, SLOT);\n\n        let loaded_value: Option<MockStruct> = load(contract_address, SLOT);\n        assert_eq(loaded_value, Option::none());\n    }\n\n    #[test]\n    unconstrained fn deletes_empty_slot() {\n        let contract_address = setup();\n\n        delete(contract_address, SLOT);\n        let loaded_value: Option<MockStruct> = load(contract_address, SLOT);\n        assert_eq(loaded_value, Option::none());\n    }\n\n    #[test]\n    unconstrained fn copies_non_overlapping_values() {\n        let contract_address = setup();\n\n        let src = 5;\n\n        let values = [MockStruct::new(5, 6), MockStruct::new(7, 8), MockStruct::new(9, 10)];\n        store(contract_address, src, values[0]);\n        store(contract_address, src + 1, values[1]);\n        store(contract_address, src + 2, values[2]);\n\n        let dst = 10;\n        copy(contract_address, src, dst, 3);\n\n        assert_eq(load(contract_address, dst).unwrap(), values[0]);\n        assert_eq(load(contract_address, dst + 1).unwrap(), values[1]);\n        assert_eq(load(contract_address, dst + 2).unwrap(), values[2]);\n    }\n\n    #[test]\n    unconstrained fn copies_overlapping_values_with_src_ahead() {\n        let contract_address = setup();\n\n        let src = 1;\n\n        let values = [MockStruct::new(5, 6), MockStruct::new(7, 8), MockStruct::new(9, 10)];\n        store(contract_address, src, values[0]);\n        store(contract_address, src + 1, values[1]);\n        store(contract_address, src + 2, values[2]);\n\n        let dst = 2;\n        copy(contract_address, src, dst, 3);\n\n        assert_eq(load(contract_address, dst).unwrap(), values[0]);\n        assert_eq(load(contract_address, dst + 1).unwrap(), values[1]);\n        assert_eq(load(contract_address, dst + 2).unwrap(), values[2]);\n\n        // src[1] and src[2] should have been overwritten since they are also dst[0] and dst[1]\n        assert_eq(load(contract_address, src).unwrap(), values[0]); // src[0] (unchanged)\n        assert_eq(load(contract_address, src + 1).unwrap(), values[0]); // dst[0]\n        assert_eq(load(contract_address, src + 2).unwrap(), values[1]); // dst[1]\n    }\n\n    #[test]\n    unconstrained fn copies_overlapping_values_with_dst_ahead() {\n        let contract_address = setup();\n\n        let src = 2;\n\n        let values = [MockStruct::new(5, 6), MockStruct::new(7, 8), MockStruct::new(9, 10)];\n        store(contract_address, src, values[0]);\n        store(contract_address, src + 1, values[1]);\n        store(contract_address, src + 2, values[2]);\n\n        let dst = 1;\n        copy(contract_address, src, dst, 3);\n\n        assert_eq(load(contract_address, dst).unwrap(), values[0]);\n        assert_eq(load(contract_address, dst + 1).unwrap(), values[1]);\n        assert_eq(load(contract_address, dst + 2).unwrap(), values[2]);\n\n        // src[0] and src[1] should have been overwritten since they are also dst[1] and dst[2]\n        assert_eq(load(contract_address, src).unwrap(), values[1]); // dst[1]\n        assert_eq(load(contract_address, src + 1).unwrap(), values[2]); // dst[2]\n        assert_eq(load(contract_address, src + 2).unwrap(), values[2]); // src[2] (unchanged)\n    }\n\n    #[test(should_fail_with = \"copy empty slot\")]\n    unconstrained fn cannot_copy_empty_values() {\n        let contract_address = setup();\n\n        copy(contract_address, SLOT, SLOT, 1);\n    }\n\n    #[test(should_fail_with = \"not allowed to access\")]\n    unconstrained fn cannot_store_other_contract() {\n        let contract_address = setup();\n        let other_contract_address = AztecAddress::from_field(contract_address.to_field() + 1);\n\n        let value = MockStruct::new(5, 6);\n        store(other_contract_address, SLOT, value);\n    }\n\n    #[test(should_fail_with = \"not allowed to access\")]\n    unconstrained fn cannot_load_other_contract() {\n        let contract_address = setup();\n        let other_contract_address = AztecAddress::from_field(contract_address.to_field() + 1);\n\n        let _: Option<MockStruct> = load(other_contract_address, SLOT);\n    }\n\n    #[test(should_fail_with = \"not allowed to access\")]\n    unconstrained fn cannot_delete_other_contract() {\n        let contract_address = setup();\n        let other_contract_address = AztecAddress::from_field(contract_address.to_field() + 1);\n\n        delete(other_contract_address, SLOT);\n    }\n\n    #[test(should_fail_with = \"not allowed to access\")]\n    unconstrained fn cannot_copy_other_contract() {\n        let contract_address = setup();\n        let other_contract_address = AztecAddress::from_field(contract_address.to_field() + 1);\n\n        copy(other_contract_address, SLOT, SLOT, 0);\n    }\n}\n"},"138":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/oracle/execution.nr","source":"use dep::protocol_types::address::AztecAddress;\n\n#[oracle(getContractAddress)]\nunconstrained fn get_contract_address_oracle() -> AztecAddress {}\n\n#[oracle(getBlockNumber)]\nunconstrained fn get_block_number_oracle() -> u32 {}\n\n#[oracle(getChainId)]\nunconstrained fn get_chain_id_oracle() -> Field {}\n\n#[oracle(getVersion)]\nunconstrained fn get_version_oracle() -> Field {}\n\npub unconstrained fn get_contract_address() -> AztecAddress {\n    get_contract_address_oracle()\n}\n\npub unconstrained fn get_block_number() -> u32 {\n    get_block_number_oracle()\n}\n\npub unconstrained fn get_chain_id() -> Field {\n    get_chain_id_oracle()\n}\n\npub unconstrained fn get_version() -> Field {\n    get_version_oracle()\n}\n"},"140":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/oracle/get_contract_instance.nr","source":"use protocol_types::{\n    address::AztecAddress, contract_class_id::ContractClassId, contract_instance::ContractInstance,\n    traits::FromField,\n};\n\n// NOTE: this is for use in private only\n#[oracle(getContractInstance)]\nunconstrained fn get_contract_instance_oracle(_address: AztecAddress) -> ContractInstance {}\n\n// NOTE: this is for use in private only\nunconstrained fn get_contract_instance_internal(address: AztecAddress) -> ContractInstance {\n    get_contract_instance_oracle(address)\n}\n\n// NOTE: this is for use in private only\npub fn get_contract_instance(address: AztecAddress) -> ContractInstance {\n    // Safety: The to_address function combines all values in the instance object to produce an address,\n    // so by checking that we get the expected address we validate the entire struct.\n    let instance = unsafe { get_contract_instance_internal(address) };\n    assert_eq(instance.to_address(), address);\n\n    instance\n}\n\nstruct GetContractInstanceResult {\n    exists: bool,\n    member: Field,\n}\n\n// These oracles each return a ContractInstance member\n// plus a boolean indicating whether the instance was found.\n#[oracle(avmOpcodeGetContractInstanceDeployer)]\nunconstrained fn get_contract_instance_deployer_oracle_avm(\n    _address: AztecAddress,\n) -> [GetContractInstanceResult; 1] {}\n#[oracle(avmOpcodeGetContractInstanceClassId)]\nunconstrained fn get_contract_instance_class_id_oracle_avm(\n    _address: AztecAddress,\n) -> [GetContractInstanceResult; 1] {}\n#[oracle(avmOpcodeGetContractInstanceInitializationHash)]\nunconstrained fn get_contract_instance_initialization_hash_oracle_avm(\n    _address: AztecAddress,\n) -> [GetContractInstanceResult; 1] {}\n\nunconstrained fn get_contract_instance_deployer_internal_avm(\n    address: AztecAddress,\n) -> [GetContractInstanceResult; 1] {\n    get_contract_instance_deployer_oracle_avm(address)\n}\nunconstrained fn get_contract_instance_class_id_internal_avm(\n    address: AztecAddress,\n) -> [GetContractInstanceResult; 1] {\n    get_contract_instance_class_id_oracle_avm(address)\n}\nunconstrained fn get_contract_instance_initialization_hash_internal_avm(\n    address: AztecAddress,\n) -> [GetContractInstanceResult; 1] {\n    get_contract_instance_initialization_hash_oracle_avm(address)\n}\n\npub fn get_contract_instance_deployer_avm(address: AztecAddress) -> Option<AztecAddress> {\n    // Safety: AVM opcodes are constrained by the AVM itself\n    let GetContractInstanceResult { exists, member } =\n        unsafe { get_contract_instance_deployer_internal_avm(address)[0] };\n    if exists {\n        Option::some(AztecAddress::from_field(member))\n    } else {\n        Option::none()\n    }\n}\npub fn get_contract_instance_class_id_avm(address: AztecAddress) -> Option<ContractClassId> {\n    // Safety: AVM opcodes are constrained by the AVM itself\n    let GetContractInstanceResult { exists, member } =\n        unsafe { get_contract_instance_class_id_internal_avm(address)[0] };\n    if exists {\n        Option::some(ContractClassId::from_field(member))\n    } else {\n        Option::none()\n    }\n}\npub fn get_contract_instance_initialization_hash_avm(address: AztecAddress) -> Option<Field> {\n    // Safety: AVM opcodes are constrained by the AVM itself\n    let GetContractInstanceResult { exists, member } =\n        unsafe { get_contract_instance_initialization_hash_internal_avm(address)[0] };\n    if exists {\n        Option::some(member)\n    } else {\n        Option::none()\n    }\n}\n"},"145":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/oracle/key_validation_request.nr","source":"use protocol_types::abis::validation_requests::KeyValidationRequest;\n\n#[oracle(getKeyValidationRequest)]\nunconstrained fn get_key_validation_request_oracle(\n    _pk_m_hash: Field,\n    _key_index: Field,\n) -> KeyValidationRequest {}\n\npub unconstrained fn get_key_validation_request(\n    pk_m_hash: Field,\n    key_index: Field,\n) -> KeyValidationRequest {\n    get_key_validation_request_oracle(pk_m_hash, key_index)\n}\n"},"146":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/oracle/keys.nr","source":"use dep::protocol_types::{\n    address::{AztecAddress, PartialAddress},\n    point::Point,\n    public_keys::{IvpkM, NpkM, OvpkM, PublicKeys, TpkM},\n};\n\n#[oracle(getPublicKeysAndPartialAddress)]\nunconstrained fn get_public_keys_and_partial_address_oracle(_address: AztecAddress) -> [Field; 13] {}\n\npub unconstrained fn get_public_keys_and_partial_address(\n    address: AztecAddress,\n) -> (PublicKeys, PartialAddress) {\n    let result = get_public_keys_and_partial_address_oracle(address);\n\n    let keys = PublicKeys {\n        npk_m: NpkM { inner: Point { x: result[0], y: result[1], is_infinite: result[2] as bool } },\n        ivpk_m: IvpkM {\n            inner: Point { x: result[3], y: result[4], is_infinite: result[5] as bool },\n        },\n        ovpk_m: OvpkM {\n            inner: Point { x: result[6], y: result[7], is_infinite: result[8] as bool },\n        },\n        tpk_m: TpkM {\n            inner: Point { x: result[9], y: result[10], is_infinite: result[11] as bool },\n        },\n    };\n\n    let partial_address = PartialAddress::from_field(result[12]);\n\n    (keys, partial_address)\n}\n"},"147":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/oracle/logs.nr","source":"use crate::messages::encoding::MAX_MESSAGE_CONTENT_LEN;\nuse protocol_types::{abis::event_selector::EventSelector, address::AztecAddress};\n\n/// The below only exists to broadcast the raw log, so we can provide it to the base rollup later to be constrained.\npub unconstrained fn notify_created_contract_class_log<let N: u32>(\n    contract_address: AztecAddress,\n    message: [Field; N],\n    length: u32,\n    counter: u32,\n) {\n    notify_created_contract_class_log_private_oracle(contract_address, message, length, counter)\n}\n\n#[oracle(notifyCreatedContractClassLog)]\nunconstrained fn notify_created_contract_class_log_private_oracle<let N: u32>(\n    contract_address: AztecAddress,\n    message: [Field; N],\n    length: u32,\n    counter: u32,\n) {}\n\npub unconstrained fn store_private_event_log(\n    contract_address: AztecAddress,\n    recipient: AztecAddress,\n    event_selector: EventSelector,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n    tx_hash: Field,\n    log_index_in_tx: Field,\n    tx_index_in_block: Field,\n) {\n    store_private_event_log_oracle(\n        contract_address,\n        recipient,\n        event_selector,\n        msg_content,\n        tx_hash,\n        log_index_in_tx,\n        tx_index_in_block,\n    )\n}\n\n#[oracle(storePrivateEventLog)]\nunconstrained fn store_private_event_log_oracle(\n    contract_address: AztecAddress,\n    recipient: AztecAddress,\n    event_selector: EventSelector,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n    tx_hash: Field,\n    log_index_in_tx: Field,\n    tx_index_in_block: Field,\n) {}\n"},"148":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/oracle/message_discovery.nr","source":"use crate::messages::discovery::private_notes::MAX_NOTE_PACKED_LEN;\nuse dep::protocol_types::{\n    address::AztecAddress,\n    constants::{MAX_NOTE_HASHES_PER_TX, PUBLIC_LOG_SIZE_IN_FIELDS},\n};\n\n/// Finds new private logs that may have been sent to all registered accounts in PXE in the current contract and makes\n/// them available for later processing in Noir by storing them in a capsule array.\npub unconstrained fn fetch_tagged_logs(pending_tagged_log_array_base_slot: Field) {\n    fetch_tagged_logs_oracle(pending_tagged_log_array_base_slot);\n}\n\n#[oracle(fetchTaggedLogs)]\nunconstrained fn fetch_tagged_logs_oracle(pending_tagged_log_array_base_slot: Field) {}\n\n/// Informs PXE of a note's existence so that it can later be retrieved by the `getNotes` oracle. The note will be\n/// scoped to `contract_address`, meaning other contracts will not be able to access it unless authorized.\n///\n/// The packed note is what `getNotes` will later return. PXE indexes notes by `storage_slot`, so this value\n/// is typically used to filter notes that correspond to different state variables. `note_hash` and `nullifier` are\n/// the inner hashes, i.e. the raw hashes returned by `NoteHash::compute_note_hash` and\n/// `NoteHash::compute_nullifier`. PXE will verify that the siloed unique note hash was inserted into the tree\n/// at `tx_hash`, and will store the nullifier to later check for nullification.\n///\n/// `recipient` is the account to which the note was sent to. Other accounts will not be able to access this note (e.g.\n/// other accounts will not be able to see one another's token balance notes, even in the same PXE) unless authorized.\n///\n/// Returns true if the note was successfully delivered and added to PXE's database.\npub unconstrained fn deliver_note(\n    contract_address: AztecAddress,\n    storage_slot: Field,\n    nonce: Field,\n    packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n    note_hash: Field,\n    nullifier: Field,\n    tx_hash: Field,\n    recipient: AztecAddress,\n) -> bool {\n    deliver_note_oracle(\n        contract_address,\n        storage_slot,\n        nonce,\n        packed_note,\n        note_hash,\n        nullifier,\n        tx_hash,\n        recipient,\n    )\n}\n\n/// The contents of a public log, plus contextual information about the transaction in which the log was emitted. This\n/// is the data required in order to discover notes that are being delivered in a log.\n// TODO(#11639): this could also be used to fetch private logs, but the `BoundedVec` maximum length is that of a public\n// log.\npub struct LogWithTxData {\n    // The log fields length is PUBLIC_LOG_SIZE_IN_FIELDS. + 1 because the contract address is prepended to the content.\n    pub log_content: BoundedVec<Field, PUBLIC_LOG_SIZE_IN_FIELDS + 1>,\n    pub tx_hash: Field,\n    /// The array of new note hashes created by `tx_hash`\n    pub unique_note_hashes_in_tx: BoundedVec<Field, MAX_NOTE_HASHES_PER_TX>,\n    /// The first nullifier created by `tx_hash`\n    pub first_nullifier_in_tx: Field,\n}\n\n/// Fetches a log from the node that has the corresponding `tag`. The log can be either a public or a private log, and\n/// the tag is the first field in the log's content. Returns `Option::none` if no such log exists. Throws if more than\n/// one log with that tag exists.\n/// Public logs have an extra field included at the beginning with the address of the contract that emitted them.\n// TODO(#11627): handle multiple logs with the same tag.\n// TODO(#10273): improve contract siloing of logs, don't introduce an extra field.\npub unconstrained fn get_log_by_tag(tag: Field) -> Option<LogWithTxData> {\n    get_log_by_tag_oracle(tag)\n}\n\n#[oracle(deliverNote)]\nunconstrained fn deliver_note_oracle(\n    contract_address: AztecAddress,\n    storage_slot: Field,\n    nonce: Field,\n    packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n    note_hash: Field,\n    nullifier: Field,\n    tx_hash: Field,\n    recipient: AztecAddress,\n) -> bool {}\n\n#[oracle(getLogByTag)]\nunconstrained fn get_log_by_tag_oracle(tag: Field) -> Option<LogWithTxData> {}\n"},"152":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/oracle/shared_secret.nr","source":"use protocol_types::{address::aztec_address::AztecAddress, point::Point};\n\n// TODO(#12656): return an app-siloed secret + document this\n#[oracle(getSharedSecret)]\nunconstrained fn get_shared_secret_oracle(address: AztecAddress, ephPk: Point) -> Point {}\n\n/// Returns an app-siloed shared secret between `address` and someone who knows the secret key behind an\n/// ephemeral public key `ephPk`. The app-siloing means that contracts cannot retrieve secrets that belong to\n/// other contracts, and therefore cannot e.g. decrypt their messages. This is an important security consideration\n/// given that both the `address` and `ephPk` are public information.\n///\n/// The shared secret `S` is computed as:\n/// `let S =  (ivsk + h) * ephPk`\n/// where `ivsk + h` is the 'preaddress' i.e. the preimage of the address, also called the address secret.\n/// TODO(#12656): app-silo this secret\npub unconstrained fn get_shared_secret(address: AztecAddress, ephPk: Point) -> Point {\n    get_shared_secret_oracle(address, ephPk)\n}\n"},"16":{"path":"std/embedded_curve_ops.nr","source":"use crate::cmp::Eq;\nuse crate::hash::Hash;\nuse crate::ops::arith::{Add, Neg, Sub};\n\n/// A point on the embedded elliptic curve\n/// By definition, the base field of the embedded curve is the scalar field of the proof system curve, i.e the Noir Field.\n/// x and y denotes the Weierstrass coordinates of the point, if is_infinite is false.\npub struct EmbeddedCurvePoint {\n    pub x: Field,\n    pub y: Field,\n    pub is_infinite: bool,\n}\n\nimpl EmbeddedCurvePoint {\n    /// Elliptic curve point doubling operation\n    /// returns the doubled point of a point P, i.e P+P\n    pub fn double(self) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, self)\n    }\n\n    /// Returns the null element of the curve; 'the point at infinity'\n    pub fn point_at_infinity() -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    }\n\n    /// Returns the curve's generator point.\n    pub fn generator() -> EmbeddedCurvePoint {\n        // Generator point for the grumpkin curve (y^2 = x^3 - 17)\n        EmbeddedCurvePoint {\n            x: 1,\n            y: 17631683881184975370165255887551781615748388533673675138860, // sqrt(-16)\n            is_infinite: false,\n        }\n    }\n}\n\nimpl Add for EmbeddedCurvePoint {\n    /// Adds two points P+Q, using the curve addition formula, and also handles point at infinity\n    fn add(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, other)\n    }\n}\n\nimpl Sub for EmbeddedCurvePoint {\n    /// Points subtraction operation, using addition and negation\n    fn sub(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        self + other.neg()\n    }\n}\n\nimpl Neg for EmbeddedCurvePoint {\n    /// Negates a point P, i.e returns -P, by negating the y coordinate.\n    /// If the point is at infinity, then the result is also at infinity.\n    fn neg(self) -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: self.x, y: -self.y, is_infinite: self.is_infinite }\n    }\n}\n\nimpl Eq for EmbeddedCurvePoint {\n    /// Checks whether two points are equal\n    fn eq(self: Self, b: EmbeddedCurvePoint) -> bool {\n        (self.is_infinite & b.is_infinite)\n            | ((self.is_infinite == b.is_infinite) & (self.x == b.x) & (self.y == b.y))\n    }\n}\n\nimpl Hash for EmbeddedCurvePoint {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        if self.is_infinite {\n            self.is_infinite.hash(state);\n        } else {\n            self.x.hash(state);\n            self.y.hash(state);\n        }\n    }\n}\n\n/// Scalar for the embedded curve represented as low and high limbs\n/// By definition, the scalar field of the embedded curve is base field of the proving system curve.\n/// It may not fit into a Field element, so it is represented with two Field elements; its low and high limbs.\npub struct EmbeddedCurveScalar {\n    pub lo: Field,\n    pub hi: Field,\n}\n\nimpl EmbeddedCurveScalar {\n    pub fn new(lo: Field, hi: Field) -> Self {\n        EmbeddedCurveScalar { lo, hi }\n    }\n\n    #[field(bn254)]\n    pub fn from_field(scalar: Field) -> EmbeddedCurveScalar {\n        let (a, b) = crate::field::bn254::decompose(scalar);\n        EmbeddedCurveScalar { lo: a, hi: b }\n    }\n\n    //Bytes to scalar: take the first (after the specified offset) 16 bytes of the input as the lo value, and the next 16 bytes as the hi value\n    #[field(bn254)]\n    pub(crate) fn from_bytes(bytes: [u8; 64], offset: u32) -> EmbeddedCurveScalar {\n        let mut v = 1;\n        let mut lo = 0 as Field;\n        let mut hi = 0 as Field;\n        for i in 0..16 {\n            lo = lo + (bytes[offset + 31 - i] as Field) * v;\n            hi = hi + (bytes[offset + 15 - i] as Field) * v;\n            v = v * 256;\n        }\n        let sig_s = crate::embedded_curve_ops::EmbeddedCurveScalar { lo, hi };\n        sig_s\n    }\n}\n\nimpl Eq for EmbeddedCurveScalar {\n    fn eq(self, other: Self) -> bool {\n        (other.hi == self.hi) & (other.lo == self.lo)\n    }\n}\n\nimpl Hash for EmbeddedCurveScalar {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        self.hi.hash(state);\n        self.lo.hash(state);\n    }\n}\n\n// Computes a multi scalar multiplication over the embedded curve.\n// For bn254, We have Grumpkin and Baby JubJub.\n// For bls12-381, we have JubJub and Bandersnatch.\n//\n// The embedded curve being used is decided by the\n// underlying proof system.\n// docs:start:multi_scalar_mul\npub fn multi_scalar_mul<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n) -> EmbeddedCurvePoint\n// docs:end:multi_scalar_mul\n{\n    multi_scalar_mul_array_return(points, scalars)[0]\n}\n\n#[foreign(multi_scalar_mul)]\npub(crate) fn multi_scalar_mul_array_return<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n) -> [EmbeddedCurvePoint; 1] {}\n\n// docs:start:fixed_base_scalar_mul\npub fn fixed_base_scalar_mul(scalar: EmbeddedCurveScalar) -> EmbeddedCurvePoint\n// docs:end:fixed_base_scalar_mul\n{\n    multi_scalar_mul([EmbeddedCurvePoint::generator()], [scalar])\n}\n\n/// This function only assumes that the points are on the curve\n/// It handles corner cases around the infinity point causing some overhead compared to embedded_curve_add_not_nul and embedded_curve_add_unsafe\n// docs:start:embedded_curve_add\npub fn embedded_curve_add(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    // docs:end:embedded_curve_add\n    if crate::runtime::is_unconstrained() {\n        // `embedded_curve_add_unsafe` requires the inputs not to be the infinity point, so we check it here.\n        // This is because `embedded_curve_add_unsafe` uses the `embedded_curve_add` opcode.\n        // For efficiency, the backend does not check the inputs for the infinity point, but it assumes that they are not the infinity point\n        // so that it can apply the ec addition formula directly.\n        if point1.is_infinite {\n            point2\n        } else if point2.is_infinite {\n            point1\n        } else {\n            embedded_curve_add_unsafe(point1, point2)\n        }\n    } else {\n        // In a constrained context, we also need to check the inputs are not the infinity point because we also use `embedded_curve_add_unsafe`\n        // However we also need to identify the case where the two inputs are the same, because then\n        // the addition formula does not work and we need to use the doubling formula instead.\n        // In unconstrained context, we can check directly if the input values are the same when solving the opcode, so it is not an issue.\n\n        // x_coordinates_match is true if both abscissae are the same\n        let x_coordinates_match = point1.x == point2.x;\n        // y_coordinates_match is true if both ordinates are the same\n        let y_coordinates_match = point1.y == point2.y;\n        // double_predicate is true if both abscissae and ordinates are the same\n        let double_predicate = (x_coordinates_match & y_coordinates_match);\n        // If the abscissae are the same, but not the ordinates, then one point is the opposite of the other\n        let infinity_predicate = (x_coordinates_match & !y_coordinates_match);\n        let point1_1 = EmbeddedCurvePoint {\n            x: point1.x + (x_coordinates_match as Field),\n            y: point1.y,\n            is_infinite: false,\n        };\n        let point2_1 = EmbeddedCurvePoint { x: point2.x, y: point2.y, is_infinite: false };\n        // point1_1 is guaranteed to have a different abscissa than point2:\n        // - if x_coordinates_match is 0, that means point1.x != point2.x, and point1_1.x = point1.x + 0\n        // - if x_coordinates_match is 1, that means point1.x = point2.x, but point1_1.x = point1.x + 1 in this case\n        // Because the abscissa is different, the addition formula is guaranteed to succeed, so we can safely use `embedded_curve_add_unsafe`\n        // Note that this computation may be garbage: if x_coordinates_match is 1, or if one of the input is the point at infinity.\n        let mut result = embedded_curve_add_unsafe(point1_1, point2_1);\n\n        // `embedded_curve_add_unsafe` is doing a doubling if the input is the same variable, because in this case it is guaranteed (at 'compile time') that the input is the same.\n        let double = embedded_curve_add_unsafe(point1, point1);\n        // `embedded_curve_add_unsafe` would not perform doubling, even if the inputs point1 and point2 are the same, because it cannot know this without adding some logic (and some constraints)\n        // However we did this logic when we computed `double_predicate`, so we set the result to 2*point1 if point1 and point2 are the same\n        result = if double_predicate { double } else { result };\n\n        // Same logic as above for unconstrained context, we set the proper result when one of the inputs is the infinity point\n        if point1.is_infinite {\n            result = point2;\n        }\n        if point2.is_infinite {\n            result = point1;\n        }\n\n        // Finally, we set the is_infinity flag of the result:\n        // Opposite points should sum into the infinity point, however, if one of them is point at infinity, their coordinates are not meaningful\n        // so we should not use the fact that the inputs are opposite in this case:\n        let mut result_is_infinity =\n            infinity_predicate & (!point1.is_infinite & !point2.is_infinite);\n        // However, if both of them are at infinity, then the result is also at infinity\n        result.is_infinite = result_is_infinity | (point1.is_infinite & point2.is_infinite);\n        result\n    }\n}\n\n#[foreign(embedded_curve_add)]\nfn embedded_curve_add_array_return(\n    _point1: EmbeddedCurvePoint,\n    _point2: EmbeddedCurvePoint,\n) -> [EmbeddedCurvePoint; 1] {}\n\n/// This function assumes that:\n/// The points are on the curve, and\n/// The points don't share an x-coordinate, and\n/// Neither point is the infinity point.\n/// If it is used with correct input, the function ensures the correct non-zero result is returned.\n/// Except for points on the curve, the other assumptions are checked by the function. It will cause assertion failure if they are not respected.\npub fn embedded_curve_add_not_nul(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    assert(point1.x != point2.x);\n    assert(!point1.is_infinite);\n    assert(!point2.is_infinite);\n    embedded_curve_add_unsafe(point1, point2)\n}\n\n/// Unsafe ec addition\n/// If the inputs are the same, it will perform a doubling, but only if point1 and point2 are the same variable.\n/// If they have the same value but are different variables, the result will be incorrect because in this case\n/// it assumes (but does not check) that the points' x-coordinates are not equal.\n/// It also assumes neither point is the infinity point.\npub fn embedded_curve_add_unsafe(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    embedded_curve_add_array_return(point1, point2)[0]\n}\n"},"17":{"path":"std/field/bn254.nr","source":"use crate::field::field_less_than;\nuse crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\nglobal PLO: Field = 53438638232309528389504892708671455233;\nglobal PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(x: Field) -> (Field, Field) {\n    // Here's we're taking advantage of truncating 128 bit limbs from the input field\n    // and then subtracting them from the input such the field division is equivalent to integer division.\n    let low = (x as u128) as Field;\n    let high = (x - low) / TWO_POW_128;\n\n    (low, high)\n}\n\npub(crate) unconstrained fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nunconstrained fn lte_hint(x: Field, y: Field) -> bool {\n    if x == y {\n        true\n    } else {\n        field_less_than(x, y)\n    }\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    // Safety: borrow is enforced to be boolean due to its type.\n    // if borrow is 0, it asserts that (alo > blo && ahi >= bhi)\n    // if borrow is 1, it asserts that (alo <= blo && ahi > bhi)\n    unsafe {\n        let borrow = lte_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size::<128>();\n        rhi.assert_max_bit_size::<128>();\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        // Safety: decomposition is properly checked below\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size::<128>();\n            xhi.assert_max_bit_size::<128>();\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(\n            // Safety: already unconstrained\n            unsafe { field_less_than(b, a) },\n        );\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unsafe in unconstrained\n        unsafe {\n            field_less_than(b, a)\n        }\n    } else if a == b {\n        false\n    } else {\n        // Safety: Take a hint of the comparison and verify it\n        unsafe {\n            if field_less_than(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{assert_gt, decompose, gt, lte_hint, PHI, PLO, TWO_POW_128};\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_decompose_unconstrained() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_lte_hint() {\n        assert(lte_hint(0, 1));\n        assert(lte_hint(0, 0x100));\n        assert(lte_hint(0x100, TWO_POW_128 - 1));\n        assert(!lte_hint(0 - 1, 0));\n\n        assert(lte_hint(0, 0));\n        assert(lte_hint(0x100, 0x100));\n        assert(lte_hint(0 - 1, 0 - 1));\n    }\n\n    #[test]\n    fn check_assert_gt() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    unconstrained fn check_assert_gt_unconstrained() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    unconstrained fn check_gt_unconstrained() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n}\n"},"179":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/utils/array/append.nr","source":"/// Appends two `BoundedVec`s together, returning one that contains all of the elements of the first one followed by all\n/// of the elements of the second one. The resulting `BoundedVec` can have any arbitrary maximum length, but it must be\n/// large enough to fit all of the elements of both the first and second vectors.\npub fn append<T, let A_LEN: u32, let B_LEN: u32, let DST_LEN: u32>(\n    a: BoundedVec<T, A_LEN>,\n    b: BoundedVec<T, B_LEN>,\n) -> BoundedVec<T, DST_LEN> {\n    let mut dst = BoundedVec::new();\n\n    dst.extend_from_bounded_vec(a);\n    dst.extend_from_bounded_vec(b);\n\n    dst\n}\n\nmod test {\n    use super::append;\n\n    #[test]\n    unconstrained fn append_empty_vecs() {\n        let a: BoundedVec<_, 3> = BoundedVec::new();\n        let b: BoundedVec<_, 14> = BoundedVec::new();\n\n        let result: BoundedVec<Field, 5> = append(a, b);\n\n        assert_eq(result.len(), 0);\n        assert_eq(result.storage(), std::mem::zeroed());\n    }\n\n    #[test]\n    unconstrained fn append_non_empty_vecs() {\n        let a: BoundedVec<_, 3> = BoundedVec::from_array([1, 2, 3]);\n        let b: BoundedVec<_, 14> = BoundedVec::from_array([4, 5, 6]);\n\n        let result: BoundedVec<Field, 8> = append(a, b);\n\n        assert_eq(result.len(), 6);\n        assert_eq(result.storage(), [1, 2, 3, 4, 5, 6, std::mem::zeroed(), std::mem::zeroed()]);\n    }\n\n    #[test(should_fail_with = \"out of bounds\")]\n    unconstrained fn append_non_empty_vecs_insufficient_max_len() {\n        let a: BoundedVec<_, 3> = BoundedVec::from_array([1, 2, 3]);\n        let b: BoundedVec<_, 14> = BoundedVec::from_array([4, 5, 6]);\n\n        let _: BoundedVec<Field, 5> = append(a, b);\n    }\n}\n"},"18":{"path":"std/field/mod.nr","source":"pub mod bn254;\nuse crate::{runtime::is_unconstrained, static_assert};\nuse bn254::lt as bn254_lt;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size<let BIT_SIZE: u32>(self) {\n        // docs:end:assert_max_bit_size\n        static_assert(\n            BIT_SIZE < modulus_num_bits() as u32,\n            \"BIT_SIZE must be less than modulus_num_bits\",\n        );\n        self.__assert_max_bit_size(BIT_SIZE);\n    }\n\n    #[builtin(apply_range_constraint)]\n    fn __assert_max_bit_size(self, bit_size: u32) {}\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_le_bits)]\n    fn _to_le_bits<let N: u32>(self: Self) -> [u1; N] {}\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_be_bits)]\n    fn _to_be_bits<let N: u32>(self: Self) -> [u1; N] {}\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_le_bits\n        let bits = self._to_le_bits();\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[N - 1 - i] != p[N - 1 - i]) {\n                        assert(p[N - 1 - i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_be_bits\n        let bits = self._to_be_bits();\n\n        if !is_unconstrained() {\n            // Ensure that the decomposition does not overflow the modulus\n            let p = modulus_be_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[i] != p[i]) {\n                        assert(p[i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    // docs:start:to_le_radix\n    pub fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        self.__to_le_radix(radix)\n    }\n    // docs:end:to_le_radix\n\n    // docs:start:to_be_radix\n    pub fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            crate::assert_constant(radix);\n        }\n        self.__to_be_radix(radix)\n    }\n    // docs:end:to_be_radix\n\n    // `_radix` must be less than 256\n    #[builtin(to_le_radix)]\n    fn __to_le_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    // `_radix` must be less than 256\n    #[builtin(to_be_radix)]\n    fn __to_be_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32 - i] as Field) * (r * self) + (1 - b[32 - i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N - 1 - i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n/// An unconstrained only built in to efficiently compare fields.\n#[builtin(field_less_than)]\nunconstrained fn __field_less_than(x: Field, y: Field) -> bool {}\n\npub(crate) unconstrained fn field_less_than(x: Field, y: Field) -> bool {\n    __field_less_than(x, y)\n}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unconstrained context\n        unsafe {\n            field_less_than(x, y)\n        }\n    } else {\n        let x_bytes: [u8; 32] = x.to_le_bytes();\n        let y_bytes: [u8; 32] = y.to_le_bytes();\n        let mut x_is_lt = false;\n        let mut done = false;\n        for i in 0..32 {\n            if (!done) {\n                let x_byte = x_bytes[32 - 1 - i] as u8;\n                let y_byte = y_bytes[32 - 1 - i] as u8;\n                let bytes_match = x_byte == y_byte;\n                if !bytes_match {\n                    x_is_lt = x_byte < y_byte;\n                    done = true;\n                }\n            }\n        }\n        x_is_lt\n    }\n}\n\nmod tests {\n    use crate::{panic::panic, runtime};\n    use super::field_less_than;\n\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_be_bytes();\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_le_bytes();\n        assert_eq(bytes, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        // 259, in base 256, big endian, is [1, 3].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 1, 3]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        // 259, in base 256, little endian, is [3, 1].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bytes, [3, 1, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_radix_example\n\n    #[test(should_fail_with = \"radix must be greater than 1\")]\n    fn test_to_le_radix_1() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(1);\n        } else {\n            panic(f\"radix must be greater than 1\");\n        }\n    }\n\n    // TODO: Update this test to account for the Brillig restriction that the radix must be greater than 2\n    //#[test]\n    //fn test_to_le_radix_brillig_1() {\n    //    // this test should only fail in constrained mode\n    //    if runtime::is_unconstrained() {\n    //        let field = 1;\n    //        let out: [u8; 8] = field.to_le_radix(1);\n    //        crate::println(out);\n    //        let expected = [0; 8];\n    //        assert(out == expected, \"unexpected result\");\n    //    }\n    //}\n\n    #[test(should_fail_with = \"radix must be a power of 2\")]\n    fn test_to_le_radix_3() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(3);\n        } else {\n            panic(f\"radix must be a power of 2\");\n        }\n    }\n\n    #[test]\n    fn test_to_le_radix_brillig_3() {\n        // this test should only fail in constrained mode\n        if runtime::is_unconstrained() {\n            let field = 1;\n            let out: [u8; 8] = field.to_le_radix(3);\n            let mut expected = [0; 8];\n            expected[0] = 1;\n            assert(out == expected, \"unexpected result\");\n        }\n    }\n\n    #[test(should_fail_with = \"radix must be less than or equal to 256\")]\n    fn test_to_le_radix_512() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(512);\n        } else {\n            panic(f\"radix must be less than or equal to 256\")\n        }\n    }\n\n    // TODO: Update this test to account for the Brillig restriction that the radix must be less than 512\n    //#[test]\n    //fn test_to_le_radix_brillig_512() {\n    //    // this test should only fail in constrained mode\n    //    if runtime::is_unconstrained() {\n    //        let field = 1;\n    //        let out: [u8; 8] = field.to_le_radix(512);\n    //        let mut expected = [0; 8];\n    //        expected[0] = 1;\n    //        assert(out == expected, \"unexpected result\");\n    //    }\n    //}\n\n    #[test]\n    unconstrained fn test_field_less_than() {\n        assert(field_less_than(0, 1));\n        assert(field_less_than(0, 0x100));\n        assert(field_less_than(0x100, 0 - 1));\n        assert(!field_less_than(0 - 1, 0));\n    }\n}\n"},"182":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/utils/array/subarray.nr","source":"/// Returns `DST_LEN` elements from a source array, starting at `offset`. `DST_LEN` must not be larger than the number\n/// of elements past `offset`.\n///\n/// Examples:\n/// ```\n/// let foo: [Field; 2] = subarray([1, 2, 3, 4, 5], 2);\n/// assert_eq(foo, [3, 4]);\n///\n/// let bar: [Field; 5] = subarray([1, 2, 3, 4, 5], 2); // fails - we can't return 5 elements since only 3 remain\n/// ```\npub fn subarray<T, let SRC_LEN: u32, let DST_LEN: u32>(\n    src: [T; SRC_LEN],\n    offset: u32,\n) -> [T; DST_LEN] {\n    assert(offset + DST_LEN <= SRC_LEN, \"DST_LEN too large for offset\");\n\n    let mut dst: [T; DST_LEN] = std::mem::zeroed();\n    for i in 0..DST_LEN {\n        dst[i] = src[i + offset];\n    }\n\n    dst\n}\n\nmod test {\n    use super::subarray;\n\n    #[test]\n    unconstrained fn subarray_into_empty() {\n        // In all of these cases we're setting DST_LEN to be 0, so we always get back an emtpy array.\n        assert_eq(subarray::<Field, _, _>([], 0), []);\n        assert_eq(subarray([1, 2, 3, 4, 5], 0), []);\n        assert_eq(subarray([1, 2, 3, 4, 5], 2), []);\n    }\n\n    #[test]\n    unconstrained fn subarray_complete() {\n        assert_eq(subarray::<Field, _, _>([], 0), []);\n        assert_eq(subarray([1, 2, 3, 4, 5], 0), [1, 2, 3, 4, 5]);\n    }\n\n    #[test]\n    unconstrained fn subarray_different_end_sizes() {\n        // We implicitly select how many values to read in the size of the return array\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [2, 3, 4, 5]);\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [2, 3, 4]);\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [2, 3]);\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [2]);\n    }\n\n    #[test(should_fail_with = \"DST_LEN too large for offset\")]\n    unconstrained fn subarray_offset_too_large() {\n        // With an offset of 1 we can only request up to 4 elements\n        let _: [_; 5] = subarray([1, 2, 3, 4, 5], 1);\n    }\n\n    #[test(should_fail)]\n    unconstrained fn subarray_bad_return_value() {\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [3, 3, 4, 5]);\n    }\n}\n"},"183":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/utils/array/subbvec.nr","source":"use crate::utils::array;\n\n/// Returns `DST_MAX_LEN` elements from a source BoundedVec, starting at `offset`. `offset` must not be larger than the\n/// original length, and `DST_LEN` must not be larger than the total number of elements past `offset` (including the\n/// zeroed elements past `len()`).\n///\n/// Only elements at the beginning of the vector can be removed: it is not possible to also remove elements at the end\n/// of the vector by passing a value for `DST_LEN` that is smaller than `len() - offset`.\n///\n/// Examples:\n/// ```\n/// let foo = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n/// assert_eq(subbvec(foo, 2), BoundedVec::<_, 8>::from_array([3, 4, 5]));\n///\n/// let bar: BoundedVec<_, 1> = subbvec(foo, 2); // fails - we can't return just 1 element since 3 remain\n/// let baz: BoundedVec<_, 10> = subbvec(foo, 3); // fails - we can't return 10 elements since only 7 remain\n/// ```\npub fn subbvec<T, let SRC_MAX_LEN: u32, let DST_MAX_LEN: u32>(\n    bvec: BoundedVec<T, SRC_MAX_LEN>,\n    offset: u32,\n) -> BoundedVec<T, DST_MAX_LEN> {\n    // from_parts_unchecked does not verify that the elements past len are zeroed, but that is not an issue in our case\n    // because we're constructing the new storage array as a subarray of the original one (which should have zeroed\n    // storage past len), guaranteeing correctness. This is because `subarray` does not allow extending arrays past\n    // their original length.\n    BoundedVec::from_parts_unchecked(array::subarray(bvec.storage(), offset), bvec.len() - offset)\n}\n\nmod test {\n    use super::subbvec;\n\n    #[test]\n    unconstrained fn subbvec_empty() {\n        let bvec = BoundedVec::<Field, 0>::from_array([]);\n        assert_eq(subbvec(bvec, 0), bvec);\n    }\n\n    #[test]\n    unconstrained fn subbvec_complete() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n        assert_eq(subbvec(bvec, 0), bvec);\n\n        let smaller_capacity = BoundedVec::<_, 5>::from_array([1, 2, 3, 4, 5]);\n        assert_eq(subbvec(bvec, 0), smaller_capacity);\n    }\n\n    #[test]\n    unconstrained fn subbvec_partial() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n\n        assert_eq(subbvec(bvec, 2), BoundedVec::<_, 8>::from_array([3, 4, 5]));\n        assert_eq(subbvec(bvec, 2), BoundedVec::<_, 3>::from_array([3, 4, 5]));\n    }\n\n    #[test]\n    unconstrained fn subbvec_into_empty() {\n        let bvec: BoundedVec<_, 10> = BoundedVec::from_array([1, 2, 3, 4, 5]);\n        assert_eq(subbvec(bvec, 5), BoundedVec::<_, 5>::from_array([]));\n    }\n\n    #[test(should_fail)]\n    unconstrained fn subbvec_offset_past_len() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n        let _: BoundedVec<_, 1> = subbvec(bvec, 6);\n    }\n\n    #[test(should_fail)]\n    unconstrained fn subbvec_insufficient_dst_len() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n\n        // We're not providing enough space to hold all of the items inside the original BoundedVec. subbvec can cause\n        // for the capacity to reduce, but not the length (other than by len - offset).\n        let _: BoundedVec<_, 1> = subbvec(bvec, 2);\n    }\n\n    #[test(should_fail_with = \"DST_LEN too large for offset\")]\n    unconstrained fn subbvec_dst_len_causes_enlarge() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n\n        // subbvec does not supprt capacity increases\n        let _: BoundedVec<_, 11> = subbvec(bvec, 0);\n    }\n\n    #[test(should_fail_with = \"DST_LEN too large for offset\")]\n    unconstrained fn subbvec_dst_len_too_large_for_offset() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n\n        // This effectively requests a capacity increase, since there'd be just one element plus the 5 empty slots,\n        // which is less than 7.\n        let _: BoundedVec<_, 7> = subbvec(bvec, 4);\n    }\n}\n"},"185":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/utils/conversion/bytes_to_fields.nr","source":"use std::static_assert;\n\n// These functions are used to facilitate the conversion of log ciphertext between byte and field representations.\n//\n// `bytes_to_fields` uses fixed-size arrays since encryption contexts have compile-time size information.\n// `bytes_from_fields` uses BoundedVec for flexibility in unconstrained contexts where sizes are dynamic.\n//\n// Together they provide bidirectional conversion between bytes and fields when processing encrypted logs.\n\n/// Converts the input bytes into an array of fields. A Field is ~254 bits meaning that each field can store 31 whole\n/// bytes. Use `bytes_from_fields` to obtain the original bytes array.\n///\n/// The input bytes are chunked into chunks of 31 bytes. Each 31-byte chunk is viewed as big-endian, and is converted\n/// into a Field.\n/// For example, [1, 10, 3, ..., 0] (31 bytes) is encoded as [1 * 256^30 + 10 * 256^29 + 3 * 256^28 + ... + 0]\n/// Note: N must be a multiple of 31 bytes\npub fn bytes_to_fields<let N: u32>(bytes: [u8; N]) -> [Field; N / 31] {\n    // Assert that N is a multiple of 31\n    static_assert(N % 31 == 0, \"N must be a multiple of 31\");\n\n    let mut fields = [0; N / 31];\n\n    // Since N is a multiple of 31, we can simply process all chunks fully\n    for i in 0..N / 31 {\n        let mut field = 0;\n        for j in 0..31 {\n            // Shift the existing value left by 8 bits and add the new byte\n            field = field * 256 + bytes[i * 31 + j] as Field;\n        }\n        fields[i] = field;\n    }\n\n    fields\n}\n\n/// Converts an input BoundedVec of fields into a BoundedVec of bytes in big-endian order. Arbitrary Field arrays\n/// are not allowed: this is assumed to be an array obtained via `bytes_to_fields`, i.e. one that actually represents\n/// bytes. To convert a Field array into bytes, use `fields_to_bytes`.\n///\n/// Each input field must contain at most 31 bytes (this is constrained to be so).\n/// Each field is converted into 31 big-endian bytes, and the resulting 31-byte chunks are concatenated\n/// back together in the order of the original fields.\npub fn bytes_from_fields<let N: u32>(fields: BoundedVec<Field, N>) -> BoundedVec<u8, N * 31> {\n    let mut bytes = BoundedVec::new();\n\n    for i in 0..fields.len() {\n        let field = fields.get(i);\n\n        // We expect that the field contains at most 31 bytes of information.\n        field.assert_max_bit_size::<248>();\n\n        // Now we can safely convert the field to 31 bytes.\n        let field_as_bytes: [u8; 31] = field.to_be_bytes();\n\n        for j in 0..31 {\n            bytes.push(field_as_bytes[j]);\n        }\n    }\n\n    bytes\n}\n\nmod tests {\n    use crate::utils::array::subarray;\n    use super::{bytes_from_fields, bytes_to_fields};\n\n    #[test]\n    unconstrained fn random_bytes_to_fields_and_back(input: [u8; 93]) {\n        let fields = bytes_to_fields(input);\n\n        // At this point in production, the log flies through the system and we get a BoundedVec on the other end.\n        // So we need to convert the field array to a BoundedVec to be able to feed it to the `bytes_from_fields`\n        // function.\n        let fields_as_bounded_vec = BoundedVec::<_, 6>::from_array(fields);\n\n        let bytes_back = bytes_from_fields(fields_as_bounded_vec);\n\n        // Compare the original input with the round-tripped result\n        assert_eq(bytes_back.len(), input.len());\n        assert_eq(subarray(bytes_back.storage(), 0), input);\n    }\n\n    #[test(should_fail_with = \"N must be a multiple of 31\")]\n    unconstrained fn bytes_to_fields_input_length_not_multiple_of_31() {\n        // Try to convert 32 bytes (not a multiple of 31) to fields\n        let _fields = bytes_to_fields([0; 32]);\n    }\n\n}\n"},"186":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/utils/conversion/fields_to_bytes.nr","source":"// These functions are used to facilitate the conversion of log plaintext represented as fields into bytes and back.\n//\n// `fields_to_bytes` uses fixed-size arrays since encryption contexts have compile-time size information.\n// `fields_from_bytes` uses BoundedVec for flexibility in unconstrained contexts where sizes are dynamic.\n//\n// Together they provide bidirectional conversion between fields and bytes.\n\n/// Converts an input array of fields into a single array of bytes. Use `fields_from_bytes` to obtain the original\n/// field array.\n/// Each field is converted to a 32-byte big-endian array.\n///\n/// For example, if you have a field array [123, 456], it will be converted to a 64-byte array:\n/// [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,  // First field (32 bytes)\n///  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,200]  // Second field (32 bytes)\n///\n/// Since a field is ~254 bits, you'll end up with a subtle 2-bit \"gap\" at the big end, every 32 bytes. Be careful\n/// that such a gap doesn't leak information! This could happen if you for example expected the output to be\n/// indistinguishable from random bytes.\npub fn fields_to_bytes<let N: u32>(fields: [Field; N]) -> [u8; 32 * N] {\n    let mut bytes = [0; 32 * N];\n\n    for i in 0..N {\n        let field_as_bytes: [u8; 32] = fields[i].to_be_bytes();\n\n        for j in 0..32 {\n            bytes[i * 32 + j] = field_as_bytes[j];\n        }\n    }\n\n    bytes\n}\n\n/// Converts an input BoundedVec of bytes into a BoundedVec of fields. Arbitrary byte arrays are not allowed: this\n/// is assumed to be an array obtained via `fields_to_bytes`, i.e. one that actually represents fields. To convert\n/// a byte array into Fields, use `bytes_to_fields`.\n///\n/// The input bytes are chunked into chunks of 32 bytes. Each 32-byte chunk is viewed as big-endian, and is converted\n/// into a Field.\n/// For example, [1, 10, 3, ..., 0] (32 bytes) is encoded as [1 * 256^31 + 10 * 256^30 + 3 * 256^29 + ... + 0]\n/// Note 1: N must be a multiple of 32 bytes\n/// Note 2: The max value check code was taken from std::field::to_be_bytes function.\npub fn fields_from_bytes<let N: u32>(bytes: BoundedVec<u8, N>) -> BoundedVec<Field, N / 32> {\n    // Assert that input length is a multiple of 32\n    assert(bytes.len() % 32 == 0, \"Input length must be a multiple of 32\");\n\n    let mut fields = BoundedVec::new();\n\n    let p = std::field::modulus_be_bytes();\n\n    // Since input length is a multiple of 32, we can simply process all chunks fully\n    for i in 0..bytes.len() / 32 {\n        let mut field = 0;\n\n        // Process each byte in the 32-byte chunk\n        let mut ok = false;\n\n        for j in 0..32 {\n            let next_byte = bytes.get(i * 32 + j);\n            field = field * 256 + next_byte as Field;\n\n            if !ok {\n                if next_byte != p[j] {\n                    assert(next_byte < p[j], \"Value does not fit in field\");\n                    ok = true;\n                }\n            }\n        }\n        assert(ok, \"Value does not fit in field\");\n\n        fields.push(field);\n    }\n\n    fields\n}\n\nmod tests {\n    use crate::utils::array::subarray;\n    use super::{fields_from_bytes, fields_to_bytes};\n\n    #[test]\n    unconstrained fn random_fields_to_bytes_and_back(input: [Field; 3]) {\n        // Convert to bytes\n        let bytes = fields_to_bytes(input);\n\n        // At this point in production, the log flies through the system and we get a BoundedVec on the other end.\n        // So we need to convert the field array to a BoundedVec to be able to feed it to the `fields_from_bytes`\n        // function.\n        // 113 is an arbitrary max length that is larger than the input length of 96.\n        let bytes_as_bounded_vec = BoundedVec::<_, 113>::from_array(bytes);\n\n        // Convert back to fields\n        let fields_back = fields_from_bytes(bytes_as_bounded_vec);\n\n        // Compare the original input with the round-tripped result\n        assert_eq(fields_back.len(), input.len());\n        assert_eq(subarray(fields_back.storage(), 0), input);\n    }\n\n    #[test(should_fail_with = \"Input length must be a multiple of 32\")]\n    unconstrained fn to_fields_assert() {\n        // 143 is an arbitrary max length that is larger than 33\n        let input = BoundedVec::<_, 143>::from_array([\n            1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n            25, 26, 27, 28, 29, 30, 31, 32, 33,\n        ]);\n\n        // This should fail since 33 is not a multiple of 32\n        let _fields = fields_from_bytes(input);\n    }\n\n    #[test]\n    unconstrained fn fields_from_bytes_max_value() {\n        let max_field_as_bytes: [u8; 32] = (-1).to_be_bytes();\n        let input = BoundedVec::<_, 32>::from_array(max_field_as_bytes);\n\n        let fields = fields_from_bytes(input);\n\n        // The result should be a largest value storable in a field (-1 since we are modulo-ing)\n        assert_eq(fields.get(0), -1);\n    }\n\n    // In this test we verify that overflow check works by taking the max allowed value, bumping a random byte\n    // and then feeding it to `fields_from_bytes` as input.\n    #[test(should_fail_with = \"Value does not fit in field\")]\n    unconstrained fn fields_from_bytes_overflow(random_value: u8) {\n        let index_of_byte_to_bump = random_value % 32;\n\n        // Obtain the byte representation of the maximum field value\n        let max_field_value_as_bytes: [u8; 32] = (-1).to_be_bytes();\n\n        let byte_to_bump = max_field_value_as_bytes[index_of_byte_to_bump as u32];\n\n        // Skip test execution if the selected byte is already at maximum value (255).\n        // This is acceptable since we are using fuzz testing to generate many test cases.\n        if byte_to_bump != 255 {\n            let mut input = BoundedVec::<_, 32>::from_array(max_field_value_as_bytes);\n\n            // Increment the selected byte to exceed the field's maximum value\n            input.set(index_of_byte_to_bump as u32, byte_to_bump + 1);\n\n            // Attempt the conversion, which should fail due to the value exceeding the field's capacity\n            let _fields = fields_from_bytes(input);\n        }\n    }\n\n}\n"},"188":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/utils/field.nr","source":"use std::option::Option;\n\nglobal KNOWN_NON_RESIDUE: Field = 5; // This is a non-residue in Noir's native Field.\n\nglobal C1: u32 = 28;\nglobal C3: Field = 40770029410420498293352137776570907027550720424234931066070132305055;\nglobal C5: Field = 19103219067921713944291392827692070036145651957329286315305642004821462161904;\n\n// Power function of two Field arguments of arbitrary size.\n// Adapted from std::field::pow_32.\npub fn pow(x: Field, y: Field) -> Field {\n    let mut r = 1 as Field;\n    let b: [u1; 254] = y.to_le_bits();\n\n    for i in 0..254 {\n        r *= r;\n        r *= (b[254 - 1 - i] as Field) * x + (1 - b[254 - 1 - i] as Field);\n    }\n\n    r\n}\n\n// Boolean indicating whether Field element is a square, i.e. whether there exists a y in Field s.t. x = y*y.\nunconstrained fn is_square(x: Field) -> bool {\n    let v = pow(x, -1 / 2);\n    v * (v - 1) == 0\n}\n\n// Tonelli-Shanks algorithm for computing the square root of a Field element.\n// Requires C1 = max{c: 2^c divides (p-1)}, where p is the order of Field\n// as well as C3 = (C2 - 1)/2, where C2 = (p-1)/(2^c1),\n// and C5 = ZETA^C2, where ZETA is a non-square element of Field.\n// These are pre-computed above as globals.\nunconstrained fn tonelli_shanks_sqrt(x: Field) -> Field {\n    let mut z = pow(x, C3);\n    let mut t = z * z * x;\n    z *= x;\n    let mut b = t;\n    let mut c = C5;\n\n    for i in 0..(C1 - 1) {\n        for _j in 1..(C1 - i - 1) {\n            b *= b;\n        }\n\n        z *= if b == 1 { 1 } else { c };\n\n        c *= c;\n\n        t *= if b == 1 { 1 } else { c };\n\n        b = t;\n    }\n\n    z\n}\n\n// NB: this doesn't return an option, because in the case of there _not_ being a square root, we still want to return a field element that allows us to then assert in the _constrained_ sqrt function that there is no sqrt.\npub unconstrained fn __sqrt(x: Field) -> (bool, Field) {\n    let is_sq = is_square(x);\n    if is_sq {\n        let sqrt = tonelli_shanks_sqrt(x);\n        (true, sqrt)\n    } else {\n        // Demonstrate that x is not a square (a.k.a. a \"quadratic non-residue\").\n        // Facts:\n        // The Legendre symbol (\"LS\") of x, is x^((p-1)/2) (mod p).\n        // - If x is a square, LS(x) = 1\n        // - If x is not a square, LS(x) = -1\n        // - If x = 0, LS(x) = 0.\n        //\n        // Hence:\n        // sq * sq = sq // 1 * 1 = 1\n        // non-sq * non-sq = sq // -1 * -1 = 1\n        // sq * non-sq = non-sq // -1 * 1 = -1\n        //\n        // See: https://en.wikipedia.org/wiki/Legendre_symbol\n        let demo_x_not_square = x * KNOWN_NON_RESIDUE;\n        let not_sqrt = tonelli_shanks_sqrt(demo_x_not_square);\n        (false, not_sqrt)\n    }\n}\n\n// Returns (false, 0) if there is no square root.\n// Returns (true, sqrt) if there is a square root.\npub fn sqrt(x: Field) -> Option<Field> {\n    // Safety: if the hint returns the square root of x, then we simply square it\n    // check the result equals x. If x is not square, we return a value that\n    // enables us to prove that fact (see the `else` clause below).\n    let (is_sq, maybe_sqrt) = unsafe { __sqrt(x) };\n\n    if is_sq {\n        let sqrt = maybe_sqrt;\n        validate_sqrt_hint(x, sqrt);\n        Option::some(sqrt)\n    } else {\n        let not_sqrt_hint = maybe_sqrt;\n        validate_not_sqrt_hint(x, not_sqrt_hint);\n        Option::none()\n    }\n}\n\nfn validate_sqrt_hint(x: Field, hint: Field) {\n    assert(hint * hint == x, f\"The claimed_sqrt {hint} is not the sqrt of x {x}\");\n}\n\nfn validate_not_sqrt_hint(x: Field, hint: Field) {\n    // We need this assertion, because x = 0 would pass the other assertions in this\n    // function, and we don't want people to be able to prove that 0 is not square!\n    assert(x != 0, \"0 has a square root; you cannot claim it is not square\");\n    // Demonstrate that x is not a square (a.k.a. a \"quadratic non-residue\").\n    //\n    // Facts:\n    // The Legendre symbol (\"LS\") of x, is x^((p-1)/2) (mod p).\n    // - If x is a square, LS(x) = 1\n    // - If x is not a square, LS(x) = -1\n    // - If x = 0, LS(x) = 0.\n    //\n    // Hence:\n    // 1. sq * sq = sq // 1 * 1 = 1\n    // 2. non-sq * non-sq = sq // -1 * -1 = 1\n    // 3. sq * non-sq = non-sq // -1 * 1 = -1\n    //\n    // See: https://en.wikipedia.org/wiki/Legendre_symbol\n    //\n    // We want to demonstrate that this below multiplication falls under bullet-point (2):\n    let demo_x_not_square = x * KNOWN_NON_RESIDUE;\n    // I.e. we want to demonstrate that `demo_x_not_square` has Legendre symbol 1\n    // (i.e. that it is a square), so we prove that it is square below.\n    // Why do we want to prove that it has LS 1?\n    // Well, since it was computed with a known-non-residue, its squareness implies we're\n    // in case 2 (something multiplied by a known-non-residue yielding a result which\n    // has a LS of 1), which implies that x must be a non-square. The unconstrained\n    // function gave us the sqrt of demo_x_not_square, so all we need to do is\n    // assert its squareness:\n    assert(\n        hint * hint == demo_x_not_square,\n        f\"The hint {hint} does not demonstrate that {x} is not a square\",\n    );\n}\n\n#[test]\nfn test_sqrt() {\n    let x = 9;\n    let maybe_sqrt = sqrt(x);\n    assert(maybe_sqrt.is_some());\n    let sqrt = maybe_sqrt.unwrap_unchecked();\n    assert((sqrt == 3) | (sqrt == -3));\n}\n\n#[test]\nfn test_non_square() {\n    let x = 5;\n    let maybe_sqrt = sqrt(x);\n    assert(maybe_sqrt.is_none());\n}\n\n#[test]\nunconstrained fn test_known_non_residue_is_actually_a_non_residue_in_the_field() {\n    assert(!is_square(KNOWN_NON_RESIDUE));\n}\n\n#[test]\nfn test_sqrt_0() {\n    let x = 0;\n    let sqrt = sqrt(x).unwrap();\n    assert(sqrt == 0);\n}\n\n#[test]\nfn test_sqrt_1() {\n    let x = 1;\n    let sqrt = sqrt(x).unwrap();\n    assert((sqrt == 1) | (sqrt == -1));\n}\n\n#[test(should_fail_with = \"The claimed_sqrt 0x04 is not the sqrt of x 0x09\")]\nfn test_bad_sqrt_hint_fails() {\n    validate_sqrt_hint(9, 4);\n}\n\n#[test(should_fail_with = \"The hint 0x04 does not demonstrate that 0x0a is not a square\")]\nfn test_bad_not_sqrt_hint_fails() {\n    validate_not_sqrt_hint(10, 4);\n}\n\n#[test(should_fail_with = \"0 has a square root; you cannot claim it is not square\")]\nfn test_0_not_sqrt_hint_fails() {\n    validate_not_sqrt_hint(0, 0);\n}\n\n#[test]\nunconstrained fn test_is_square() {\n    assert(is_square(25));\n}\n\n#[test]\nunconstrained fn test_is_not_square() {\n    assert(!is_square(10));\n}\n"},"190":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/utils/point.nr","source":"use crate::utils::field::sqrt;\nuse dep::protocol_types::point::Point;\n\n// I am storing the modulus minus 1 divided by 2 here because full modulus would throw \"String literal too large\" error\n// Full modulus is 21888242871839275222246405745257275088548364400416034343698204186575808495617\nglobal BN254_FR_MODULUS_DIV_2: Field =\n    10944121435919637611123202872628637544274182200208017171849102093287904247808;\n\n/// Converts a point to a byte array.\n///\n/// We don't serialize the point at infinity flag because this function is used in situations where we do not want\n/// to waste the extra byte (encrypted log).\npub fn point_to_bytes(p: Point) -> [u8; 32] {\n    // Note that there is 1 more free bit in the 32 bytes (254 bits currently occupied by the x coordinate, 1 bit for\n    // the \"sign\") so it's possible to use that last bit as an \"is_infinite\" flag if desired in the future.\n    assert(!p.is_infinite, \"Cannot serialize point at infinity as bytes.\");\n\n    let mut result: [u8; 32] = p.x.to_be_bytes();\n\n    if get_sign_of_point(p) {\n        // y is <= (modulus - 1) / 2 so we set the sign bit to 1\n        // Here we leverage that field fits into 254 bits (log2(Fr.MODULUS) < 254) and given that we serialize Fr to 32\n        // bytes and we use big-endian the 2 most significant bits are never populated. Hence we can use one of\n        // the bits as a sign bit.\n        result[0] += 128;\n    }\n\n    result\n}\n\n/**\n * Returns: true if p.y <= MOD_DIV_2, else false.\n */\npub fn get_sign_of_point(p: Point) -> bool {\n    // We store only a \"sign\" of the y coordinate because the rest can be derived from the x coordinate. To get\n    // the sign we check if the y coordinate is less or equal than the curve's order minus 1 divided by 2.\n    // Ideally we'd do `y <= MOD_DIV_2`, but there's no `lte` function, so instead we do `!(y > MOD_DIV_2)`, which is\n    // equivalent, and then rewrite that as `!(MOD_DIV_2 < y)`, since we also have no `gt` function.\n    !BN254_FR_MODULUS_DIV_2.lt(p.y)\n}\n\npub fn point_from_x_coord(x: Field) -> Point {\n    // y ^ 2 = x ^ 3 - 17\n    let rhs = x * x * x - 17;\n    let y = sqrt(rhs).unwrap();\n    Point { x, y, is_infinite: false }\n}\n\n/// Uses the x coordinate and sign flag (+/-) to reconstruct the point.\n/// The y coordinate can be derived from the x coordinate and the \"sign\" flag by solving the grumpkin curve\n/// equation for y.\n/// @param x - The x coordinate of the point\n/// @param sign - The \"sign\" of the y coordinate - determines whether y <= (Fr.MODULUS - 1) / 2\npub fn point_from_x_coord_and_sign(x: Field, sign: bool) -> Point {\n    // y ^ 2 = x ^ 3 - 17\n    let rhs = x * x * x - 17;\n    let y = sqrt(rhs).unwrap();\n\n    // If y > MOD_DIV_2 and we want positive sign (or vice versa), negate y\n    let y_is_positive = !BN254_FR_MODULUS_DIV_2.lt(y);\n    let final_y = if y_is_positive == sign { y } else { -y };\n\n    Point { x, y: final_y, is_infinite: false }\n}\n\nmod test {\n    use crate::utils::point::{point_from_x_coord_and_sign, point_to_bytes};\n    use dep::protocol_types::point::Point;\n\n    #[test]\n    unconstrained fn test_point_to_bytes_positive_sign() {\n        let p = Point {\n            x: 0x1af41f5de96446dc3776a1eb2d98bb956b7acd9979a67854bec6fa7c2973bd73,\n            y: 0x07fc22c7f2c7057571f137fe46ea9c95114282bc95d37d71ec4bfb88de457d4a,\n            is_infinite: false,\n        };\n\n        let compressed_point = point_to_bytes(p);\n\n        let expected_compressed_point_positive_sign = [\n            154, 244, 31, 93, 233, 100, 70, 220, 55, 118, 161, 235, 45, 152, 187, 149, 107, 122,\n            205, 153, 121, 166, 120, 84, 190, 198, 250, 124, 41, 115, 189, 115,\n        ];\n        assert_eq(expected_compressed_point_positive_sign, compressed_point);\n    }\n\n    #[test]\n    unconstrained fn test_point_to_bytes_negative_sign() {\n        let p = Point {\n            x: 0x247371652e55dd74c9af8dbe9fb44931ba29a9229994384bd7077796c14ee2b5,\n            y: 0x26441aec112e1ae4cee374f42556932001507ad46e255ffb27369c7e3766e5c0,\n            is_infinite: false,\n        };\n\n        let compressed_point = point_to_bytes(p);\n\n        let expected_compressed_point_negative_sign = [\n            36, 115, 113, 101, 46, 85, 221, 116, 201, 175, 141, 190, 159, 180, 73, 49, 186, 41, 169,\n            34, 153, 148, 56, 75, 215, 7, 119, 150, 193, 78, 226, 181,\n        ];\n\n        assert_eq(expected_compressed_point_negative_sign, compressed_point);\n    }\n\n    #[test]\n    unconstrained fn test_point_from_x_coord_and_sign() {\n        // Test positive y coordinate\n        let x = 0x1af41f5de96446dc3776a1eb2d98bb956b7acd9979a67854bec6fa7c2973bd73;\n        let sign = true;\n        let p = point_from_x_coord_and_sign(x, sign);\n\n        assert_eq(p.x, x);\n        assert_eq(p.y, 0x07fc22c7f2c7057571f137fe46ea9c95114282bc95d37d71ec4bfb88de457d4a);\n        assert_eq(p.is_infinite, false);\n\n        // Test negative y coordinate\n        let x2 = 0x247371652e55dd74c9af8dbe9fb44931ba29a9229994384bd7077796c14ee2b5;\n        let sign2 = false;\n        let p2 = point_from_x_coord_and_sign(x2, sign2);\n\n        assert_eq(p2.x, x2);\n        assert_eq(p2.y, 0x26441aec112e1ae4cee374f42556932001507ad46e255ffb27369c7e3766e5c0);\n        assert_eq(p2.is_infinite, false);\n    }\n}\n"},"201":{"path":"/home/lucholeonel/nargo/github.com/noir-lang/poseidon/v0.1.0/src/poseidon2.nr","source":"use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n"},"218":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/abis/event_selector.nr","source":"use crate::traits::{Deserialize, Empty, FromField, Serialize, ToField};\n\npub struct EventSelector {\n    // 1st 4-bytes (big-endian leftmost) of abi-encoding of an event.\n    inner: u32,\n}\n\nimpl Eq for EventSelector {\n    fn eq(self, other: EventSelector) -> bool {\n        other.inner == self.inner\n    }\n}\n\nimpl Serialize<1> for EventSelector {\n    fn serialize(self: Self) -> [Field; 1] {\n        [self.inner as Field]\n    }\n}\n\nimpl Deserialize<1> for EventSelector {\n    fn deserialize(fields: [Field; 1]) -> Self {\n        Self { inner: fields[0] as u32 }\n    }\n}\n\nimpl FromField for EventSelector {\n    fn from_field(field: Field) -> Self {\n        Self { inner: field as u32 }\n    }\n}\n\nimpl ToField for EventSelector {\n    fn to_field(self) -> Field {\n        self.inner as Field\n    }\n}\n\nimpl Empty for EventSelector {\n    fn empty() -> Self {\n        Self { inner: 0 as u32 }\n    }\n}\n\nimpl EventSelector {\n    pub fn from_u32(value: u32) -> Self {\n        Self { inner: value }\n    }\n\n    pub fn from_signature<let N: u32>(signature: str<N>) -> Self {\n        let bytes = signature.as_bytes();\n        let hash = crate::hash::poseidon2_hash_bytes(bytes);\n\n        // `hash` is automatically truncated to fit within 32 bits.\n        EventSelector::from_field(hash)\n    }\n\n    pub fn zero() -> Self {\n        Self { inner: 0 }\n    }\n}\n"},"220":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/abis/function_selector.nr","source":"use crate::traits::{Deserialize, Empty, FromField, Serialize, ToField};\n\npub struct FunctionSelector {\n    // 1st 4-bytes of abi-encoding of function.\n    pub inner: u32,\n}\n\nimpl Eq for FunctionSelector {\n    fn eq(self, function_selector: FunctionSelector) -> bool {\n        function_selector.inner == self.inner\n    }\n}\n\nimpl Serialize<1> for FunctionSelector {\n    fn serialize(self: Self) -> [Field; 1] {\n        [self.inner as Field]\n    }\n}\n\nimpl Deserialize<1> for FunctionSelector {\n    fn deserialize(fields: [Field; 1]) -> Self {\n        Self { inner: fields[0] as u32 }\n    }\n}\n\nimpl FromField for FunctionSelector {\n    fn from_field(field: Field) -> Self {\n        Self { inner: field as u32 }\n    }\n}\n\nimpl ToField for FunctionSelector {\n    fn to_field(self) -> Field {\n        self.inner as Field\n    }\n}\n\nimpl Empty for FunctionSelector {\n    fn empty() -> Self {\n        Self { inner: 0 as u32 }\n    }\n}\n\nimpl FunctionSelector {\n    pub fn from_u32(value: u32) -> Self {\n        Self { inner: value }\n    }\n\n    pub fn from_signature<let N: u32>(signature: str<N>) -> Self {\n        let bytes = signature.as_bytes();\n        let hash = crate::hash::poseidon2_hash_bytes(bytes);\n\n        // `hash` is automatically truncated to fit within 32 bits.\n        FunctionSelector::from_field(hash)\n    }\n\n    pub fn zero() -> Self {\n        Self { inner: 0 }\n    }\n}\n\n#[test]\nfn test_is_valid_selector() {\n    let selector = FunctionSelector::from_signature(\"IS_VALID()\");\n    assert_eq(selector.to_field(), 0x73cdda47);\n}\n\n#[test]\nfn test_long_selector() {\n    let selector =\n        FunctionSelector::from_signature(\"foo_and_bar_and_baz_and_foo_bar_baz_and_bar_foo\");\n    assert_eq(selector.to_field(), 0x7590a997);\n}\n"},"263":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/address/aztec_address.nr","source":"use crate::{\n    address::{\n        partial_address::PartialAddress, salted_initialization_hash::SaltedInitializationHash,\n    },\n    constants::{\n        AZTEC_ADDRESS_LENGTH, GENERATOR_INDEX__CONTRACT_ADDRESS_V1, MAX_FIELD_VALUE,\n        MAX_PROTOCOL_CONTRACTS,\n    },\n    contract_class_id::ContractClassId,\n    hash::poseidon2_hash_with_separator,\n    public_keys::{IvpkM, NpkM, OvpkM, PublicKeys, ToPoint, TpkM},\n    traits::{Deserialize, Empty, FromField, Packable, Serialize, ToField},\n    utils::field::{pow, sqrt},\n};\n\n// We do below because `use crate::point::Point;` does not work\nuse dep::std::embedded_curve_ops::EmbeddedCurvePoint as Point;\n\nuse crate::public_keys::AddressPoint;\nuse std::{\n    embedded_curve_ops::{EmbeddedCurveScalar, fixed_base_scalar_mul as derive_public_key},\n    ops::Add,\n};\n\n// Aztec address\npub struct AztecAddress {\n    pub inner: Field,\n}\n\nimpl Eq for AztecAddress {\n    fn eq(self, other: Self) -> bool {\n        self.to_field() == other.to_field()\n    }\n}\n\nimpl Empty for AztecAddress {\n    fn empty() -> Self {\n        Self { inner: 0 }\n    }\n}\n\nimpl ToField for AztecAddress {\n    fn to_field(self) -> Field {\n        self.inner\n    }\n}\n\nimpl FromField for AztecAddress {\n    fn from_field(value: Field) -> AztecAddress {\n        AztecAddress { inner: value }\n    }\n}\n\nimpl Serialize<AZTEC_ADDRESS_LENGTH> for AztecAddress {\n    fn serialize(self: Self) -> [Field; AZTEC_ADDRESS_LENGTH] {\n        [self.to_field()]\n    }\n}\n\nimpl Deserialize<AZTEC_ADDRESS_LENGTH> for AztecAddress {\n    fn deserialize(fields: [Field; AZTEC_ADDRESS_LENGTH]) -> Self {\n        FromField::from_field(fields[0])\n    }\n}\n\n/// We implement the Packable trait for AztecAddress because it can be stored in contract's storage (and there\n/// the implementation of Packable is required).\nimpl Packable<AZTEC_ADDRESS_LENGTH> for AztecAddress {\n    fn pack(self) -> [Field; AZTEC_ADDRESS_LENGTH] {\n        self.serialize()\n    }\n\n    fn unpack(fields: [Field; AZTEC_ADDRESS_LENGTH]) -> Self {\n        Self::deserialize(fields)\n    }\n}\n\nimpl AztecAddress {\n    pub fn zero() -> Self {\n        Self { inner: 0 }\n    }\n\n    pub fn to_address_point(self) -> AddressPoint {\n        // We compute the address point by taking our address, setting it to x, and then solving for y in the\n        // equation which defines our bn curve:\n        // y^2 = x^3 - 17; x = address\n        let x = self.inner;\n        let y_squared = pow(x, 3) - 17;\n\n        // TODO (#8970): Handle cases where we cannot recover a point from an address\n        let mut y = sqrt(y_squared);\n\n        // If we get a negative y coordinate (any y where y > MAX_FIELD_VALUE / 2), we pin it to the\n        // positive one (any value where y <= MAX_FIELD_VALUE / 2) by subtracting it from the Field modulus\n        // note: The field modulus is MAX_FIELD_VALUE + 1\n        if (!(y.lt(MAX_FIELD_VALUE / 2) | y.eq(MAX_FIELD_VALUE / 2))) {\n            y = (MAX_FIELD_VALUE + 1) - y;\n        }\n\n        AddressPoint { inner: Point { x: self.inner, y, is_infinite: false } }\n    }\n\n    pub fn compute(public_keys: PublicKeys, partial_address: PartialAddress) -> AztecAddress {\n        let public_keys_hash = public_keys.hash();\n\n        let pre_address = poseidon2_hash_with_separator(\n            [public_keys_hash.to_field(), partial_address.to_field()],\n            GENERATOR_INDEX__CONTRACT_ADDRESS_V1,\n        );\n\n        let address_point = derive_public_key(EmbeddedCurveScalar::from_field(pre_address)).add(\n            public_keys.ivpk_m.to_point(),\n        );\n\n        // Note that our address is only the x-coordinate of the full address_point. This is okay because when people want to encrypt something and send it to us\n        // they can recover our full point using the x-coordinate (our address itself). To do this, they recompute the y-coordinate according to the equation y^2 = x^3 - 17.\n        // When they do this, they may get a positive y-coordinate (a value that is less than or equal to MAX_FIELD_VALUE / 2) or\n        // a negative y-coordinate (a value that is more than MAX_FIELD_VALUE), and we cannot dictate which one they get and hence the recovered point may sometimes be different than the one\n        // our secret can decrypt. Regardless though, they should and will always encrypt using point with the positive y-coordinate by convention.\n        // This ensures that everyone encrypts to the same point given an arbitrary x-coordinate (address). This is allowed because even though our original point may not have a positive y-coordinate,\n        // with our original secret, we will be able to derive the secret to the point with the flipped (and now positive) y-coordinate that everyone encrypts to.\n        AztecAddress::from_field(address_point.x)\n    }\n\n    pub fn compute_from_class_id(\n        contract_class_id: ContractClassId,\n        salted_initialization_hash: SaltedInitializationHash,\n        public_keys: PublicKeys,\n    ) -> Self {\n        let partial_address = PartialAddress::compute_from_salted_initialization_hash(\n            contract_class_id,\n            salted_initialization_hash,\n        );\n\n        AztecAddress::compute(public_keys, partial_address)\n    }\n\n    pub fn is_protocol_contract(self) -> bool {\n        self.inner.lt(MAX_PROTOCOL_CONTRACTS as Field)\n    }\n\n    pub fn is_zero(self) -> bool {\n        self.inner == 0\n    }\n\n    pub fn assert_is_zero(self) {\n        assert(self.to_field() == 0);\n    }\n}\n\n#[test]\nfn compute_address_from_partial_and_pub_keys() {\n    let public_keys = PublicKeys {\n        npk_m: NpkM {\n            inner: Point {\n                x: 0x22f7fcddfa3ce3e8f0cc8e82d7b94cdd740afa3e77f8e4a63ea78a239432dcab,\n                y: 0x0471657de2b6216ade6c506d28fbc22ba8b8ed95c871ad9f3e3984e90d9723a7,\n                is_infinite: false,\n            },\n        },\n        ivpk_m: IvpkM {\n            inner: Point {\n                x: 0x111223493147f6785514b1c195bb37a2589f22a6596d30bb2bb145fdc9ca8f1e,\n                y: 0x273bbffd678edce8fe30e0deafc4f66d58357c06fd4a820285294b9746c3be95,\n                is_infinite: false,\n            },\n        },\n        ovpk_m: OvpkM {\n            inner: Point {\n                x: 0x09115c96e962322ffed6522f57194627136b8d03ac7469109707f5e44190c484,\n                y: 0x0c49773308a13d740a7f0d4f0e6163b02c5a408b6f965856b6a491002d073d5b,\n                is_infinite: false,\n            },\n        },\n        tpk_m: TpkM {\n            inner: Point {\n                x: 0x00d3d81beb009873eb7116327cf47c612d5758ef083d4fda78e9b63980b2a762,\n                y: 0x2f567d22d2b02fe1f4ad42db9d58a36afd1983e7e2909d1cab61cafedad6193a,\n                is_infinite: false,\n            },\n        },\n    };\n\n    let partial_address = PartialAddress::from_field(\n        0x0a7c585381b10f4666044266a02405bf6e01fa564c8517d4ad5823493abd31de,\n    );\n\n    let address = AztecAddress::compute(public_keys, partial_address);\n\n    // The following value was generated by `derivation.test.ts`.\n    // --> Run the test with AZTEC_GENERATE_TEST_DATA=1 flag to update test data.\n    let expected_computed_address_from_partial_and_pubkeys =\n        0x24e4646f58b9fbe7d38e317db8d5636c423fbbdfbe119fc190fe9c64747e0c62;\n    assert(address.to_field() == expected_computed_address_from_partial_and_pubkeys);\n}\n\n#[test]\nfn compute_preaddress_from_partial_and_pub_keys() {\n    let pre_address = poseidon2_hash_with_separator([1, 2], GENERATOR_INDEX__CONTRACT_ADDRESS_V1);\n    let expected_computed_preaddress_from_partial_and_pubkey =\n        0x23ce9be3fa3c846b0f9245cc796902e731d04f086e8a42473bb29e405fc98075;\n    assert(pre_address == expected_computed_preaddress_from_partial_and_pubkey);\n}\n\n#[test]\nfn from_field_to_field() {\n    let address = AztecAddress { inner: 37 };\n    assert_eq(FromField::from_field(address.to_field()), address);\n}\n\n#[test]\nfn serde() {\n    let address = AztecAddress { inner: 37 };\n    assert_eq(Deserialize::deserialize(address.serialize()), address);\n}\n"},"280":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/debug_log.nr","source":"/// Utility function to console.log data in the acir simulator.\n/// Example:\n///   debug_log(\"blah blah this is a debug string\");\npub fn debug_log<let N: u32>(msg: str<N>) {\n    debug_log_format(msg, []);\n}\n\n/// Utility function to console.log data in the acir simulator. This variant receives a format string in which the\n/// `${k}` tokens will be replaced with the k-eth value in the `args` array.\n/// Examples:\n///   debug_log_format(\"get_2(slot:{0}) =>\\n\\t0:{1}\\n\\t1:{2}\", [storage_slot, note0_hash, note1_hash]);\n///   debug_log_format(\"whole array: {}\", [e1, e2, e3, e4]);\npub fn debug_log_format<let M: u32, let N: u32>(msg: str<M>, args: [Field; N]) {\n    // Safety: This oracle call returns nothing: we only call it for its side effects. It is therefore always safe\n    // to call.\n    unsafe { debug_log_oracle_wrapper(msg, args) };\n}\n\npub unconstrained fn debug_log_oracle_wrapper<let M: u32, let N: u32>(\n    msg: str<M>,\n    args: [Field; N],\n) {\n    debug_log_oracle(msg, args.as_slice());\n}\n\n// WARNING: sometimes when using debug logs the ACVM errors with: `thrown: \"solver opcode resolution error: cannot solve opcode: expression has too many unknowns x155\"`\n#[oracle(debugLog)]\nunconstrained fn debug_log_oracle<let M: u32>(_msg: str<M>, args: [Field]) {}\n"},"281":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/hash.nr","source":"use crate::{\n    abis::{\n        contract_class_function_leaf_preimage::ContractClassFunctionLeafPreimage,\n        contract_class_log::ContractClassLog,\n        function_selector::FunctionSelector,\n        note_hash::ScopedNoteHash,\n        nullifier::ScopedNullifier,\n        private_log::{PrivateLog, PrivateLogData},\n        side_effect::{OrderedValue, scoped::Scoped},\n    },\n    address::{AztecAddress, EthAddress},\n    constants::{\n        CONTRACT_CLASS_LOG_SIZE_IN_FIELDS, FUNCTION_TREE_HEIGHT, GENERATOR_INDEX__NOTE_HASH_NONCE,\n        GENERATOR_INDEX__OUTER_NULLIFIER, GENERATOR_INDEX__SILOED_NOTE_HASH,\n        GENERATOR_INDEX__UNIQUE_NOTE_HASH, TWO_POW_64,\n    },\n    merkle_tree::root::root_from_sibling_path,\n    messaging::l2_to_l1_message::{L2ToL1Message, ScopedL2ToL1Message},\n    poseidon2::Poseidon2Sponge,\n    traits::{FromField, Hash, ToField},\n    utils::{arrays::array_concat, field::{field_from_bytes, field_from_bytes_32_trunc}},\n};\n\npub fn sha256_to_field<let N: u32>(bytes_to_hash: [u8; N]) -> Field {\n    let sha256_hashed = sha256::digest(bytes_to_hash);\n    let hash_in_a_field = field_from_bytes_32_trunc(sha256_hashed);\n\n    hash_in_a_field\n}\n\npub fn private_functions_root_from_siblings(\n    selector: FunctionSelector,\n    vk_hash: Field,\n    function_leaf_index: Field,\n    function_leaf_sibling_path: [Field; FUNCTION_TREE_HEIGHT],\n) -> Field {\n    let function_leaf_preimage = ContractClassFunctionLeafPreimage { selector, vk_hash };\n    let function_leaf = function_leaf_preimage.hash();\n    root_from_sibling_path(\n        function_leaf,\n        function_leaf_index,\n        function_leaf_sibling_path,\n    )\n}\n\npub fn compute_note_hash_nonce(first_nullifier_in_tx: Field, note_index_in_tx: u32) -> Field {\n    // Hashing the first nullifier with note index in tx is guaranteed to be unique (because all nullifiers are also\n    // unique).\n    poseidon2_hash_with_separator(\n        [first_nullifier_in_tx, note_index_in_tx as Field],\n        GENERATOR_INDEX__NOTE_HASH_NONCE,\n    )\n}\n\npub fn compute_unique_note_hash(nonce: Field, siloed_note_hash: Field) -> Field {\n    let inputs = [nonce, siloed_note_hash];\n    poseidon2_hash_with_separator(inputs, GENERATOR_INDEX__UNIQUE_NOTE_HASH)\n}\n\npub fn compute_siloed_note_hash(app: AztecAddress, note_hash: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), note_hash],\n        GENERATOR_INDEX__SILOED_NOTE_HASH,\n    )\n}\n\n/// Computes unique note hashes from siloed note hashes\npub fn compute_unique_siloed_note_hash(\n    siloed_note_hash: Field,\n    first_nullifier: Field,\n    note_index_in_tx: u32,\n) -> Field {\n    if siloed_note_hash == 0 {\n        0\n    } else {\n        let nonce = compute_note_hash_nonce(first_nullifier, note_index_in_tx);\n        compute_unique_note_hash(nonce, siloed_note_hash)\n    }\n}\n\n/// Siloing in the context of Aztec refers to the process of hashing a note hash with a contract address (this way\n/// the note hash is scoped to a specific contract). This is used to prevent intermingling of notes between contracts.\npub fn silo_note_hash(note_hash: ScopedNoteHash) -> Field {\n    if note_hash.contract_address.is_zero() {\n        0\n    } else {\n        compute_siloed_note_hash(note_hash.contract_address, note_hash.value())\n    }\n}\n\npub fn compute_siloed_nullifier(app: AztecAddress, nullifier: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), nullifier],\n        GENERATOR_INDEX__OUTER_NULLIFIER,\n    )\n}\n\npub fn silo_nullifier(nullifier: ScopedNullifier) -> Field {\n    if nullifier.contract_address.is_zero() {\n        nullifier.value() // Return value instead of 0 because the first nullifier's contract address is zero.\n    } else {\n        compute_siloed_nullifier(nullifier.contract_address, nullifier.value())\n    }\n}\n\npub fn compute_siloed_private_log_field(contract_address: AztecAddress, field: Field) -> Field {\n    poseidon2_hash([contract_address.to_field(), field])\n}\n\npub fn silo_private_log(private_log: Scoped<PrivateLogData>) -> PrivateLog {\n    if private_log.contract_address.is_zero() {\n        private_log.inner.log\n    } else {\n        let mut fields = private_log.inner.log.fields;\n        fields[0] = compute_siloed_private_log_field(private_log.contract_address, fields[0]);\n        PrivateLog::new(fields, private_log.inner.log.length)\n    }\n}\n\npub fn compute_siloed_contract_class_log_field(\n    contract_address: AztecAddress,\n    first_field: Field,\n) -> Field {\n    poseidon2_hash([contract_address.to_field(), first_field])\n}\n\npub fn silo_contract_class_log(contract_class_log: ContractClassLog) -> ContractClassLog {\n    if contract_class_log.contract_address.is_zero() {\n        contract_class_log\n    } else {\n        let mut log = contract_class_log;\n        log.log.fields[0] = compute_siloed_contract_class_log_field(\n            contract_class_log.contract_address,\n            log.log.fields[0],\n        );\n        log\n    }\n}\n\npub fn compute_contract_class_log_hash(log: [Field; CONTRACT_CLASS_LOG_SIZE_IN_FIELDS]) -> Field {\n    poseidon2_hash(log)\n}\n\npub fn merkle_hash(left: Field, right: Field) -> Field {\n    poseidon2_hash([left, right])\n}\n\npub fn compute_l2_to_l1_hash(\n    contract_address: AztecAddress,\n    recipient: EthAddress,\n    content: Field,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    let mut bytes: [u8; 160] = std::mem::zeroed();\n\n    let inputs =\n        [contract_address.to_field(), rollup_version_id, recipient.to_field(), chain_id, content];\n    for i in 0..5 {\n        // TODO are bytes be in fr.to_buffer() ?\n        let item_bytes: [u8; 32] = inputs[i].to_be_bytes();\n        for j in 0..32 {\n            bytes[32 * i + j] = item_bytes[j];\n        }\n    }\n\n    sha256_to_field(bytes)\n}\n\npub fn silo_l2_to_l1_message(\n    msg: ScopedL2ToL1Message,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    if msg.contract_address.is_zero() {\n        0\n    } else {\n        compute_l2_to_l1_hash(\n            msg.contract_address,\n            msg.message.recipient,\n            msg.message.content,\n            rollup_version_id,\n            chain_id,\n        )\n    }\n}\n\n// Computes sha256 hash of 2 input hashes.\n//\n// NB: This method now takes in two 31 byte fields - it assumes that any input\n// is the result of a sha_to_field hash and => is truncated\n//\n// TODO(Jan and David): This is used for the encrypted_log hashes.\n// Can we check to see if we can just use hash_to_field or pedersen_compress here?\n//\npub fn accumulate_sha256(input: [Field; 2]) -> Field {\n    // This is a note about the cpp code, since it takes an array of Fields\n    // instead of a u128.\n    // 4 Field elements when converted to bytes will usually\n    // occupy 4 * 32 = 128 bytes.\n    // However, this function is making the assumption that each Field\n    // only occupies 128 bits.\n    //\n    // TODO(David): This does not seem to be getting guaranteed anywhere in the code?\n    // Concatentate two fields into 32x2 = 64 bytes\n    // accumulate_sha256 assumes that the inputs are pre-truncated 31 byte numbers\n    let mut hash_input_flattened = [0; 64];\n    for offset in 0..input.len() {\n        let input_as_bytes: [u8; 32] = input[offset].to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n\n    sha256_to_field(hash_input_flattened)\n}\n\npub fn verification_key_hash<let N: u32>(key: [Field; N]) -> Field {\n    crate::hash::poseidon2_hash(key)\n}\n\n#[inline_always]\npub fn pedersen_hash<let N: u32>(inputs: [Field; N], hash_index: u32) -> Field {\n    std::hash::pedersen_hash_with_separator(inputs, hash_index)\n}\n\npub fn poseidon2_hash<let N: u32>(inputs: [Field; N]) -> Field {\n    poseidon::poseidon2::Poseidon2::hash(inputs, N)\n}\n\n#[no_predicates]\npub fn poseidon2_hash_with_separator<let N: u32, T>(inputs: [Field; N], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let inputs_with_separator = array_concat([separator.to_field()], inputs);\n    poseidon2_hash(inputs_with_separator)\n}\n\n// Performs a fixed length hash with a subarray of the given input.\n// Useful for SpongeBlob in which we aborb M things and want to check it vs a hash of M elts of an N-len array.\n// Using stdlib poseidon, this will always absorb an extra 1 as a 'variable' hash, and not match spongeblob.squeeze()\n// or any ts implementation. Also checks that any remaining elts not hashed are empty.\n#[no_predicates]\npub fn poseidon2_hash_subarray<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_chunks(input, in_len, false);\n    sponge.squeeze()\n}\n\n// NB the below is the same as poseidon::poseidon2::Poseidon2::hash(), but replacing a range check with a bit check,\n// and absorbing in chunks of 3 below.\n#[no_predicates]\npub fn poseidon2_cheaper_variable_hash<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_chunks(input, in_len, true);\n    // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n    // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n    // fixed-length and variable-length hashes do not collide)\n    if in_len != N {\n        sponge.absorb(1);\n    }\n    sponge.squeeze()\n}\n\n// The below fn reduces gates of a conditional poseidon2 hash by approx 3x (thank you ~* Giant Brain Dev @IlyasRidhuan *~ for the idea)\n// Why? Because when we call stdlib poseidon, we call absorb for each item. When absorbing is conditional, it seems the compiler does not know\n// what cache_size will be when calling absorb, so it assigns the permutation gates for /each i/ rather than /every 3rd i/, which is actually required.\n// The below code forces the compiler to:\n//  - absorb normally up to 2 times to set cache_size to 1\n//  - absorb in chunks of 3 to ensure perm. only happens every 3rd absorb\n//  - absorb normally up to 2 times to add any remaining values to the hash\n// In fixed len hashes, the compiler is able to tell that it will only need to perform the permutation every 3 absorbs.\n// NB: it also replaces unnecessary range checks (i < thing) with a bit check (&= i != thing), which alone reduces the gates of a var. hash by half.\n\n#[no_predicates]\nfn poseidon2_absorb_chunks<let N: u32>(\n    input: [Field; N],\n    in_len: u32,\n    variable: bool,\n) -> Poseidon2Sponge {\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    // Even though shift is always 1 here, if we input in_len = 0 we get an underflow\n    // since we cannot isolate computation branches. The below is just to avoid that.\n    let shift = if in_len == 0 { 0 } else { 1 };\n    if in_len != 0 {\n        // cache_size = 0, init absorb\n        sponge.cache[0] = input[0];\n        sponge.cache_size = 1;\n        // shift = num elts already added to make cache_size 1 = 1 for a fresh sponge\n        // M = max_chunks = (N - 1 - (N - 1) % 3) / 3: (must be written as a fn of N to compile)\n        // max_remainder = (N - 1) % 3;\n        // max_chunks = (N - 1 - max_remainder) / 3;\n        sponge = poseidon2_absorb_chunks_loop::<N, (N - 1 - (N - 1) % 3) / 3>(\n            sponge,\n            input,\n            in_len,\n            variable,\n            shift,\n        );\n    }\n    sponge\n}\n\n// NB: If it's not required to check that the non-absorbed elts of 'input' are 0s, set skip_0_check=true\n#[no_predicates]\npub fn poseidon2_absorb_chunks_existing_sponge<let N: u32>(\n    in_sponge: Poseidon2Sponge,\n    input: [Field; N],\n    in_len: u32,\n    skip_0_check: bool,\n) -> Poseidon2Sponge {\n    let mut sponge = in_sponge;\n    // 'shift' is to account for already added inputs\n    let mut shift = 0;\n    // 'stop' is to avoid an underflow when inputting in_len = 0\n    let mut stop = false;\n    for i in 0..3 {\n        if shift == in_len {\n            stop = true;\n        }\n        if (sponge.cache_size != 1) & (!stop) {\n            sponge.absorb(input[i]);\n            shift += 1;\n        }\n    }\n    sponge = if stop {\n        sponge\n    } else {\n        // max_chunks = (N - (N % 3)) / 3;\n        poseidon2_absorb_chunks_loop::<N, (N - (N % 3)) / 3>(\n            sponge,\n            input,\n            in_len,\n            skip_0_check,\n            shift,\n        )\n    };\n    sponge\n}\n\n// The below is the loop to absorb elts into a poseidon sponge in chunks of 3\n// shift - the num of elts already absorbed to ensure the sponge's cache_size = 1\n// M - the max number of chunks required to absorb N things (must be comptime to compile)\n// NB: The 0 checks ('Found non-zero field...') are messy, but having a separate loop over N to check\n// for 0s costs 3N gates. Current approach is approx 2N gates.\n#[no_predicates]\nfn poseidon2_absorb_chunks_loop<let N: u32, let M: u32>(\n    in_sponge: Poseidon2Sponge,\n    input: [Field; N],\n    in_len: u32,\n    variable: bool,\n    shift: u32,\n) -> Poseidon2Sponge {\n    assert(in_len <= N, \"Given in_len to absorb is larger than the input array len\");\n    // When we have an existing sponge, we may have a shift of 0, and the final 'k+2' below = N\n    // The below avoids an overflow\n    let skip_last = 3 * M == N;\n    // Writing in_sponge: &mut does not compile\n    let mut sponge = in_sponge;\n    let mut should_add = true;\n    // The num of things left over after absorbing in 3s\n    let remainder = (in_len - shift) % 3;\n    // The num of chunks of 3 to absorb (maximum M)\n    let chunks = (in_len - shift - remainder) / 3;\n    for i in 0..M {\n        // Now we loop through cache size = 1 -> 3\n        should_add &= i != chunks;\n        // This is the index at the start of the chunk (for readability)\n        let k = 3 * i + shift;\n        if should_add {\n            // cache_size = 1, 2 => just assign\n            sponge.cache[1] = input[k];\n            sponge.cache[2] = input[k + 1];\n            // cache_size = 3 => duplex + perm\n            for j in 0..3 {\n                sponge.state[j] += sponge.cache[j];\n            }\n            sponge.state = std::hash::poseidon2_permutation(sponge.state, 4);\n            sponge.cache[0] = input[k + 2];\n            // cache_size is now 1 again, repeat loop\n        } else if (!variable) & (i != chunks) {\n            // if we are hashing a fixed len array which is a subarray, we check the remaining elts are 0\n            // NB: we don't check at i == chunks, because that chunk contains elts to be absorbed or checked below\n            let last_0 = if (i == M - 1) & (skip_last) {\n                0\n            } else {\n                input[k + 2]\n            };\n            let all_0 = (input[k] == 0) & (input[k + 1] == 0) & (last_0 == 0);\n            assert(all_0, \"Found non-zero field after breakpoint\");\n        }\n    }\n    // we have 'remainder' num of items left to absorb\n    should_add = true;\n    // below is to avoid overflows (i.e. if inlen is close to N)\n    let mut should_check = !variable;\n    for i in 0..3 {\n        should_add &= i != remainder;\n        should_check &= in_len - remainder + i != N;\n        if should_add {\n            // we want to absorb the final 'remainder' items\n            sponge.absorb(input[in_len - remainder + i]);\n        } else if should_check {\n            assert(input[in_len - remainder + i] == 0, \"Found non-zero field after breakpoint\");\n        }\n    }\n    sponge\n}\n\npub fn poseidon2_hash_with_separator_slice<T>(inputs: [Field], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let in_len = inputs.len() + 1;\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\n#[no_predicates]\npub fn poseidon2_hash_bytes<let N: u32>(inputs: [u8; N]) -> Field {\n    let mut fields = [0; (N + 30) / 31];\n    let mut field_index = 0;\n    let mut current_field = [0; 31];\n    for i in 0..inputs.len() {\n        let index = i % 31;\n        current_field[index] = inputs[i];\n        if index == 30 {\n            fields[field_index] = field_from_bytes(current_field, false);\n            current_field = [0; 31];\n            field_index += 1;\n        }\n    }\n    if field_index != fields.len() {\n        fields[field_index] = field_from_bytes(current_field, false);\n    }\n    poseidon2_hash(fields)\n}\n\n#[test]\nfn poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let sub_chunk_hash = poseidon2_hash_subarray(input, in_len);\n    let fixed_len_hash = poseidon::poseidon2::Poseidon2::hash(fixed_input, fixed_input.len());\n    assert(sub_chunk_hash == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_matches_variable() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let variable_chunk_hash = poseidon2_cheaper_variable_hash(input, in_len);\n    let variable_len_hash = poseidon::poseidon2::Poseidon2::hash(input, in_len);\n    assert(variable_chunk_hash == variable_len_hash);\n}\n\n#[test]\nfn existing_sponge_poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    // absorb 250 of the 501 things\n    let empty_sponge = Poseidon2Sponge::new((in_len as Field) * TWO_POW_64);\n    let first_sponge = poseidon2_absorb_chunks_existing_sponge(empty_sponge, input, 250, true);\n    // now absorb the final 251 (since they are all 3s, im being lazy and not making a new array)\n    let mut final_sponge = poseidon2_absorb_chunks_existing_sponge(first_sponge, input, 251, true);\n    let fixed_len_hash = Poseidon2Sponge::hash(fixed_input, fixed_input.len());\n    assert(final_sponge.squeeze() == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_empty_inputs() {\n    let in_len = 0;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut constructed_empty_sponge = poseidon2_absorb_chunks(input, in_len, true);\n    let mut first_sponge =\n        poseidon2_absorb_chunks_existing_sponge(constructed_empty_sponge, input, in_len, true);\n    assert(first_sponge.squeeze() == constructed_empty_sponge.squeeze());\n}\n\n#[test]\nfn smoke_sha256_to_field() {\n    let full_buffer = [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n        25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n        71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,\n        94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n    ];\n    let result = sha256_to_field(full_buffer);\n\n    assert(result == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184c7);\n\n    // to show correctness of the current ver (truncate one byte) vs old ver (mod full bytes):\n    let result_bytes = sha256::digest(full_buffer);\n    let truncated_field = crate::utils::field::field_from_bytes_32_trunc(result_bytes);\n    assert(truncated_field == result);\n    let mod_res = result + (result_bytes[31] as Field);\n    assert(mod_res == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184e0);\n}\n\n#[test]\nfn compute_l2_l1_hash() {\n    // All zeroes\n    let hash_result =\n        compute_l2_to_l1_hash(AztecAddress::from_field(0), EthAddress::zero(), 0, 0, 0);\n    assert(hash_result == 0xb393978842a0fa3d3e1470196f098f473f9678e72463cb65ec4ab5581856c2);\n\n    // Non-zero case\n    let hash_result = compute_l2_to_l1_hash(\n        AztecAddress::from_field(1),\n        EthAddress::from_field(3),\n        5,\n        2,\n        4,\n    );\n    assert(hash_result == 0x3f88c1044a05e5340ed20466276500f6d45ca5603913b9091e957161734e16);\n}\n\n#[test]\nfn silo_l2_to_l1_message_matches_typescript() {\n    let version = 4;\n    let chainId = 5;\n\n    let hash = silo_l2_to_l1_message(\n        ScopedL2ToL1Message {\n            message: L2ToL1Message { recipient: EthAddress::from_field(1), content: 2, counter: 0 },\n            contract_address: AztecAddress::from_field(3),\n        },\n        version,\n        chainId,\n    );\n\n    // The following value was generated by `l2_to_l1_message.test.ts`\n    let hash_from_typescript = 0x00c6155d69febb9d5039b374dd4f77bf57b7c881709aa524a18acaa0bd57476a;\n\n    assert_eq(hash, hash_from_typescript);\n}\n"},"295":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/meta/mod.nr","source":"use super::traits::{Deserialize, Packable, Serialize};\n\n/// Returns the typed expression of a trait method implementation.\n///\n/// This helper function is preferred over directly inlining with `$typ::target_method()` in a quote,\n/// as direct inlining would result in missing import warnings in the generated code (specifically,\n/// warnings that the trait implementation is not in scope).\n///\n/// # Note\n/// A copy of this function exists in `aztec-nr/aztec/src/macros/utils.nr`. We maintain separate copies\n/// because importing it there from here would cause the `target_trait` to be interpreted in the context\n/// of this crate, making it impossible to compile code for traits from that crate (e.g. NoteType).\ncomptime fn get_trait_impl_method(\n    typ: Type,\n    target_trait: Quoted,\n    target_method: Quoted,\n) -> TypedExpr {\n    let trait_constraint = target_trait.as_trait_constraint();\n    typ\n        .get_trait_impl(trait_constraint)\n        .expect(f\"Could not find impl for {target_trait} for type {typ}\")\n        .methods()\n        .filter(|m| m.name() == target_method)[0]\n        .as_typed_expr()\n}\n\n/// Generates code that deserializes a struct, primitive type, array or string from a field array.\n///\n/// # Parameters\n/// - `name`: The name of the current field being processed, used to identify fields for replacement.\n/// - `typ`: The type of the struct or field being deserialized (e.g., a custom struct, array, or primitive).\n/// - `field_array_name`: The name of the field array containing serialized field data (e.g., `\"values\"`).\n/// - `num_already_consumed`: The number of fields already processed in previous recursion calls.\n/// - `should_unpack`: A boolean indicating whether the type should be unpacked (see description of `Packable`\n/// and `Serialize` trait for more information about the difference between packing and serialization).\n///\n/// # Returns\n/// A tuple containing:\n/// - `Quoted`: A code that deserializes a given struct, primitive type, array, or string from the field array.\n/// - `u32`: The total number of fields consumed during deserialization (used for recursion).\n///\n/// # Nested Struct Example\n/// Given the following setup:\n/// ```\n/// struct UintNote {\n///     value: u128,\n///     owner: AztecAddress,\n///     randomness: Field,\n/// }\n///\n/// struct AztecAddress {\n///     inner: Field,\n/// }\n/// ```\n///\n/// If `UintNote` is the input type, the function will generate the following deserialization code:\n/// ```\n/// UintNote {\n///     value: fields[0] as u128,\n///     owner: AztecAddress {\n///         inner: fields[1],\n///     },\n///     randomness: fields[2],\n/// }\n/// ```\n/// # Nested Struct Example with Unpacking\n/// - given the same setup as above and given that u128, AztecAddress and Field implement the `Packable` trait\n///   the result we get is:\n/// ```\n/// UintNote {\n///     value: aztec::protocol_types::traits::Packable::unpack([fields[0]]),\n///     owner: aztec::protocol_types::traits::Packable::unpack([fields[1]]),\n///     randomness: aztec::protocol_types::traits::Packable::unpack([fields[2]]),\n/// }\n/// ```\n///\n/// # Panics\n/// - If the deserialization logic encounters a type it does not support.\n/// - If an incorrect number of fields are consumed when deserializing a string.\npub comptime fn generate_deserialize_from_fields(\n    name: Quoted,\n    typ: Type,\n    field_array_name: Quoted,\n    num_already_consumed: u32,\n    should_unpack: bool,\n) -> (Quoted, u32) {\n    let mut result = quote {};\n    // Counter for the number of fields consumed\n    let mut consumed_counter: u32 = 0;\n\n    // If the type implements `Packable`, its length will be assigned to the `maybe_packed_len_typ` variable.\n    let maybe_packed_len_typ = std::meta::typ::fresh_type_variable();\n    let packable_constraint = quote { Packable<$maybe_packed_len_typ> }.as_trait_constraint();\n\n    if (should_unpack & typ.implements(packable_constraint)) {\n        // Unpacking is enabled and the given type implements the `Packable` trait so we call the `unpack()`\n        // method, add the resulting field array to `aux_vars` and each field to `fields`.\n        let packed_len = maybe_packed_len_typ.as_constant().unwrap();\n\n        // We copy the packed fields into a new array and pass that to the unpack function in a quote\n        let mut packed_fields_quotes = &[];\n        for i in 0..packed_len {\n            let index_in_field_array = i + num_already_consumed;\n            packed_fields_quotes =\n                packed_fields_quotes.push_back(quote { $field_array_name[$index_in_field_array] });\n        }\n        let packed_fields = packed_fields_quotes.join(quote {,});\n\n        // Now we call unpack on the type\n        let unpack_method = get_trait_impl_method(typ, quote { Packable<_> }, quote { unpack });\n        result = quote { $unpack_method([ $packed_fields ]) };\n\n        consumed_counter = packed_len;\n    } else if typ.is_field() | typ.as_integer().is_some() | typ.is_bool() {\n        // The field is a primitive so we just reference it in the field array\n        result = quote { $field_array_name[$num_already_consumed] as $typ };\n        consumed_counter = 1;\n    } else if typ.as_data_type().is_some() {\n        // The field is a struct so we iterate over each struct field and recursively call\n        // `generate_deserialize_from_fields`\n        let (nested_def, generics) = typ.as_data_type().unwrap();\n        let nested_name = nested_def.name();\n        let mut deserialized_fields_list = &[];\n\n        // Iterate over each field in the struct\n        for field in nested_def.fields(generics) {\n            let (field_name, field_type) = field;\n            // Recursively call `generate_deserialize_from_fields` for each field in the struct\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                field_name,\n                field_type,\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n            // We increment the consumed counter by the number of fields consumed in the recursion\n            consumed_counter += num_consumed_in_recursion;\n            // We add the deserialized field to the list of deserialized fields.\n            // E.g. `value: u128 { lo: fields[0], hi: fields[1] }`\n            deserialized_fields_list =\n                deserialized_fields_list.push_back(quote { $field_name: $deserialized_field });\n        }\n\n        // We can construct the struct from the deserialized fields\n        let deserialized_fields = deserialized_fields_list.join(quote {,});\n        result = quote {\n                $nested_name {\n                    $deserialized_fields\n                }\n            };\n    } else if typ.as_array().is_some() {\n        // The field is an array so we iterate over each element and recursively call\n        // `generate_deserialize_from_fields`\n        let (element_type, array_len) = typ.as_array().unwrap();\n        let array_len = array_len.as_constant().unwrap();\n        let mut array_fields_list = &[];\n\n        // Iterate over each element in the array\n        for _ in 0..array_len {\n            // Recursively call `generate_deserialize_from_fields` for each element in the array\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                name,\n                element_type,\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n            // We increment the consumed counter by the number of fields consumed in the recursion\n            consumed_counter += num_consumed_in_recursion;\n            // We add the deserialized field to the list of deserialized fields.\n            array_fields_list = array_fields_list.push_back(deserialized_field);\n        }\n\n        // We can construct the array from the deserialized fields\n        let array_fields = array_fields_list.join(quote {,});\n        result = quote { [ $array_fields ] };\n    } else if typ.as_str().is_some() {\n        // The field is a string and we expect each byte of the string to be represented as 1 field in the field\n        // array. So we iterate over the string length and deserialize each character as u8 in the recursive call\n        // to `generate_deserialize_from_fields`.\n        let length_type = typ.as_str().unwrap();\n        let str_len = length_type.as_constant().unwrap();\n        let mut byte_list = &[];\n\n        // Iterate over each character in the string\n        for _ in 0..str_len {\n            // Recursively call `generate_deserialize_from_fields` for each character in the string\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                name,\n                quote {u8}.as_type(),\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n\n            // We should consume just one field in the recursion so we sanity check that\n            assert_eq(\n                num_consumed_in_recursion,\n                1,\n                \"Incorrect number of fields consumed in string deserialization\",\n            );\n\n            // We increment the consumed counter by 1 as we have consumed one field\n            consumed_counter += 1;\n\n            // We add the deserialized field to the list of deserialized fields.\n            // E.g. `fields[6] as u8`\n            byte_list = byte_list.push_back(deserialized_field);\n        }\n\n        // We construct the string from the deserialized fields\n        let bytes = byte_list.join(quote {,});\n        result = quote { [ $bytes ].as_str_unchecked() };\n    } else {\n        panic(\n            f\"Unsupported type for serialization of argument {name} and type {typ}\",\n        )\n    }\n\n    (result, consumed_counter)\n}\n\n/// Generates code that serializes a type into an array of fields. Also generates auxiliary variables if necessary\n/// for serialization. If `should_pack` is true, we check if the type implements the `Packable` trait and pack it\n/// if it does.\n///\n/// # Parameters\n/// - `name`: The base identifier (e.g., `self`, `some_var`).\n/// - `typ`: The type being serialized (e.g., a custom struct, array, or primitive type).\n/// - `should_pack`: A boolean indicating whether the type should be packed.\n///\n/// # Returns\n/// A tuple containing:\n/// - A flattened array of `Quoted` field references representing the serialized fields.\n/// - An array of `Quoted` auxiliary variables needed for serialization, such as byte arrays for strings.\n///\n/// # Examples\n///\n/// ## Struct\n/// Given the following struct:\n/// ```rust\n/// struct MockStruct {\n///     a: Field,\n///     b: Field,\n/// }\n/// ```\n///\n/// Serializing the struct:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_mock_struct }, MockStruct, false)\n/// // Returns:\n/// // ([`my_mock_struct.a`, `my_mock_struct.b`], [])\n/// ```\n///\n/// ## Nested Struct\n/// For a more complex struct:\n/// ```rust\n/// struct NestedStruct {\n///     m1: MockStruct,\n///     m2: MockStruct,\n/// }\n/// ```\n///\n/// Serialization output:\n/// ```rust\n/// generate_serialize_to_fields(quote { self }, NestedStruct, false)\n/// // Returns:\n/// // ([`self.m1.a`, `self.m1.b`, `self.m2.a`, `self.m2.b`], [])\n/// ```\n///\n/// ## Array\n/// For an array type:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_array }, [Field; 3], false)\n/// // Returns:\n/// // ([`my_array[0]`, `my_array[1]`, `my_array[2]`], [])\n/// ```\n///\n/// ## String\n/// For a string field, where each character is serialized as a `Field`:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_string }, StringType, false)\n/// // Returns:\n/// // ([`my_string_as_bytes[0] as Field`, `my_string_as_bytes[1] as Field`, ...],\n/// // [`let my_string_as_bytes = my_string.as_bytes()`])\n/// ```\n///\n/// ## Nested Struct with packing enabled\n/// - u128 has a `Packable` implementation hence it will be packed.\n///\n/// For a more complex struct:\n/// ```rust\n/// struct MyStruct {\n///     value: u128,\n///     value2: Field,\n/// }\n/// ```\n///\n/// # Panics\n/// - If the type is unsupported for serialization.\n/// - If the provided `typ` contains invalid constants or incompatible structures.\npub comptime fn generate_serialize_to_fields(\n    name: Quoted,\n    typ: Type,\n    should_pack: bool,\n) -> ([Quoted], [Quoted]) {\n    let mut fields = &[];\n    let mut aux_vars = &[];\n\n    // If the type implements `Packable`, its length will be assigned to the `maybe_packed_len_typ` variable.\n    let maybe_packed_len_typ = std::meta::typ::fresh_type_variable();\n    let packable_constraint =\n        quote { crate::traits::Packable<$maybe_packed_len_typ> }.as_trait_constraint();\n\n    if (should_pack & typ.implements(packable_constraint)) {\n        // Packing is enabled and the given type implements the `Packable` trait so we call the `pack()`\n        // method, add the resulting field array to `aux_vars` and each field to `fields`.\n        let packed_len = maybe_packed_len_typ.as_constant().unwrap();\n\n        // We collapse the name to a one that gets tokenized as a single token (e.g. \"self.value\" -> \"self_value\").\n        let name_at_one_token = collapse_to_one_token(name);\n        let packed_struct_name = f\"{name_at_one_token}_aux_var\".quoted_contents();\n\n        // We add the individual fields to the fields array\n        let pack_method = get_trait_impl_method(\n            typ,\n            quote { crate::traits::Packable<$packed_len> },\n            quote { pack },\n        );\n        let packed_struct = quote { let $packed_struct_name = $pack_method($name) };\n        for i in 0..packed_len {\n            fields = fields.push_back(quote { $packed_struct_name[$i] });\n        }\n\n        // We add the new auxiliary variable to the aux_vars array\n        aux_vars = aux_vars.push_back(packed_struct);\n    } else if typ.is_field() {\n        // For field we just add the value to fields\n        fields = fields.push_back(name);\n    } else if typ.as_integer().is_some() | typ.is_bool() {\n        // For integer and bool we just cast to Field and add the value to fields\n        fields = fields.push_back(quote { $name as Field });\n    } else if typ.as_data_type().is_some() {\n        // For struct we pref\n        let nested_struct = typ.as_data_type().unwrap();\n        let params = nested_struct.0.fields(nested_struct.1);\n        let struct_flattened = params.map(|(param_name, param_type): (Quoted, Type)| {\n            let maybe_prefixed_name = if name == quote {} {\n                // Triggered when the param name is of a value available in the current scope (e.g. a function\n                // argument) --> then we don't prefix the name with anything.\n                param_name\n            } else {\n                // Triggered when we want to prefix the param name with the `name` from function input. This\n                // can typically be `self` when implementing a method on a struct.\n                quote { $name.$param_name }\n            };\n            generate_serialize_to_fields(quote {$maybe_prefixed_name}, param_type, should_pack)\n        });\n        let struct_flattened_fields = struct_flattened.fold(\n            &[],\n            |acc: [Quoted], (fields, _): (_, [Quoted])| acc.append(fields),\n        );\n        let struct_flattened_aux_vars = struct_flattened.fold(\n            &[],\n            |acc: [Quoted], (_, aux_vars): ([Quoted], _)| acc.append(aux_vars),\n        );\n        fields = fields.append(struct_flattened_fields);\n        aux_vars = aux_vars.append(struct_flattened_aux_vars);\n    } else if typ.as_array().is_some() {\n        // For array we recursively call `generate_serialize_to_fields(...)` for each element\n        let (element_type, array_len) = typ.as_array().unwrap();\n        let array_len = array_len.as_constant().unwrap();\n        for i in 0..array_len {\n            let (element_fields, element_aux_vars) =\n                generate_serialize_to_fields(quote { $name[$i] }, element_type, should_pack);\n            fields = fields.append(element_fields);\n            aux_vars = aux_vars.append(element_aux_vars);\n        }\n    } else if typ.as_str().is_some() {\n        // For string we convert the value to bytes, we store the `as_bytes` in an auxiliary variables and\n        // then we add each byte to fields as a Field\n        let length_type = typ.as_str().unwrap();\n        let str_len = length_type.as_constant().unwrap();\n        let as_member = name.as_expr().unwrap().as_member_access();\n        let var_name = if as_member.is_some() {\n            as_member.unwrap().1\n        } else {\n            name\n        };\n        let as_bytes_name = f\"{var_name}_as_bytes\".quoted_contents();\n        let as_bytes = quote { let $as_bytes_name = $name.as_bytes() };\n        for i in 0..str_len {\n            fields = fields.push_back(quote { $as_bytes_name[$i] as Field });\n        }\n        aux_vars = aux_vars.push_back(as_bytes);\n    } else {\n        panic(\n            f\"Unsupported type for serialization of argument {name} and type {typ}\",\n        )\n    }\n\n    (fields, aux_vars)\n}\n\n/// From a quote that gets tokenized to a multiple tokens we collapse it to a single token by replacing all `.` with `_`.\n/// E.g. \"self.values[0]\" -> \"self_values_0_\"\ncomptime fn collapse_to_one_token(q: Quoted) -> Quoted {\n    let tokens = q.tokens();\n\n    let mut single_token = quote {};\n    for token in tokens {\n        let new_token = if ((token == quote {.}) | (token == quote {[}) | (token == quote {]})) {\n            quote {_}\n        } else {\n            token\n        };\n        single_token = f\"{single_token}{new_token}\".quoted_contents();\n    }\n    single_token\n}\n\npub(crate) comptime fn derive_serialize(s: TypeDefinition) -> Quoted {\n    let typ = s.as_type();\n    let (fields, aux_vars) = generate_serialize_to_fields(quote { self }, typ, false);\n    let aux_vars_for_serialization = if aux_vars.len() > 0 {\n        let joint = aux_vars.join(quote {;});\n        quote { $joint; }\n    } else {\n        quote {}\n    };\n\n    let field_serializations = fields.join(quote {,});\n    let serialized_len = fields.len();\n    quote {\n        impl Serialize<$serialized_len> for $typ {\n            #[inline_always]\n            fn serialize(self) -> [Field; $serialized_len] {\n                $aux_vars_for_serialization\n                [ $field_serializations ]\n            }\n        }\n    }\n}\n\npub(crate) comptime fn derive_deserialize(s: TypeDefinition) -> Quoted {\n    let typ = s.as_type();\n    let (fields, _) = generate_serialize_to_fields(quote { self }, typ, false);\n    let serialized_len = fields.len();\n    let (deserialized, _) =\n        generate_deserialize_from_fields(quote { self }, typ, quote { serialized }, 0, false);\n    quote {\n        impl Deserialize<$serialized_len> for $typ {\n            #[inline_always]\n            fn deserialize(serialized: [Field; $serialized_len]) -> Self {\n                $deserialized\n            }\n        }\n    }\n}\n\n/// Generates `Packable` implementation for a given struct and returns the packed length.\n///\n/// Note: We are having this function separate from `derive_packable` because we use this in the note macros to get\n/// the packed length of a note as well as the `Packable` implementation. We need the length to be able to register\n/// the note in the global `NOTES` map. There the length is used to generate partial note helper functions.\npub comptime fn derive_packable_and_get_packed_len(s: TypeDefinition) -> (Quoted, u32) {\n    let packing_enabled = true;\n\n    let typ = s.as_type();\n    let (fields, aux_vars) = generate_serialize_to_fields(quote { self }, typ, packing_enabled);\n    let aux_vars_for_packing = if aux_vars.len() > 0 {\n        let joint = aux_vars.join(quote {;});\n        quote { $joint; }\n    } else {\n        quote {}\n    };\n\n    let (unpacked, _) =\n        generate_deserialize_from_fields(quote { self }, typ, quote { packed }, 0, packing_enabled);\n\n    let field_packings = fields.join(quote {,});\n    let packed_len = fields.len();\n    let packable_trait: TraitConstraint = quote { Packable<$packed_len> }.as_trait_constraint();\n    (\n        quote {\n        impl $packable_trait for $typ {\n            fn pack(self) -> [Field; $packed_len] {\n                $aux_vars_for_packing\n                [ $field_packings ]\n            }\n\n            fn unpack(packed: [Field; $packed_len]) -> Self {\n                $unpacked\n            }\n        }\n    },\n        packed_len,\n    )\n}\n\npub(crate) comptime fn derive_packable(s: TypeDefinition) -> Quoted {\n    let (packable_impl, _) = derive_packable_and_get_packed_len(s);\n    packable_impl\n}\n\n#[derive(Packable, Serialize, Deserialize, Eq)]\npub struct Smol {\n    a: Field,\n    b: Field,\n}\n\n#[derive(Serialize, Deserialize, Eq)]\npub struct HasArray {\n    a: [Field; 2],\n    b: bool,\n}\n\n#[derive(Serialize, Deserialize, Eq)]\npub struct Fancier {\n    a: Smol,\n    b: [Field; 2],\n    c: [u8; 3],\n    d: str<16>,\n}\n\nfn main() {\n    assert(false);\n}\n\n#[test]\nfn smol_test() {\n    let smol = Smol { a: 1, b: 2 };\n    let serialized = smol.serialize();\n    assert(serialized == [1, 2], serialized);\n    let deserialized = Smol::deserialize(serialized);\n    assert(deserialized == smol);\n\n    // None of the struct members implements the `Packable` trait so the packed and serialized data should be the same\n    let packed = smol.pack();\n    assert_eq(packed, serialized, \"Packed does not match serialized\");\n}\n\n#[test]\nfn has_array_test() {\n    let has_array = HasArray { a: [1, 2], b: true };\n    let serialized = has_array.serialize();\n    assert(serialized == [1, 2, 1], serialized);\n    let deserialized = HasArray::deserialize(serialized);\n    assert(deserialized == has_array);\n}\n\n#[test]\nfn fancier_test() {\n    let fancier =\n        Fancier { a: Smol { a: 1, b: 2 }, b: [0, 1], c: [1, 2, 3], d: \"metaprogramming!\" };\n    let serialized = fancier.serialize();\n    assert(\n        serialized\n            == [\n                1, 2, 0, 1, 1, 2, 3, 0x6d, 0x65, 0x74, 0x61, 0x70, 0x72, 0x6f, 0x67, 0x72, 0x61,\n                0x6d, 0x6d, 0x69, 0x6e, 0x67, 0x21,\n            ],\n        serialized,\n    );\n    let deserialized = Fancier::deserialize(serialized);\n    assert(deserialized == fancier);\n}\n"},"297":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/point.nr","source":"pub use dep::std::embedded_curve_ops::EmbeddedCurvePoint as Point;\nuse crate::{hash::poseidon2_hash, traits::{Deserialize, Empty, Hash, Packable, Serialize}};\n\npub global POINT_LENGTH: u32 = 3;\n\nimpl Serialize<POINT_LENGTH> for Point {\n    fn serialize(self: Self) -> [Field; POINT_LENGTH] {\n        [self.x, self.y, self.is_infinite as Field]\n    }\n}\n\nimpl Hash for Point {\n    fn hash(self) -> Field {\n        poseidon2_hash(self.serialize())\n    }\n}\n\nimpl Empty for Point {\n    /// Note: Does not return a valid point on curve - instead represents an empty/\"unpopulated\" point struct (e.g.\n    /// empty/unpopulated value in an array of points).\n    fn empty() -> Self {\n        Point { x: 0, y: 0, is_infinite: false }\n    }\n}\n\nimpl Deserialize<POINT_LENGTH> for Point {\n    fn deserialize(serialized: [Field; POINT_LENGTH]) -> Point {\n        Point { x: serialized[0], y: serialized[1], is_infinite: serialized[2] as bool }\n    }\n}\n// TODO(#11356): use compact representation here.\nimpl Packable<POINT_LENGTH> for Point {\n    fn pack(self) -> [Field; POINT_LENGTH] {\n        self.serialize()\n    }\n\n    fn unpack(packed: [Field; POINT_LENGTH]) -> Self {\n        Self::deserialize(packed)\n    }\n}\n"},"308":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/public_keys.nr","source":"use crate::{\n    address::public_keys_hash::PublicKeysHash,\n    constants::{\n        DEFAULT_IVPK_M_X, DEFAULT_IVPK_M_Y, DEFAULT_NPK_M_X, DEFAULT_NPK_M_Y, DEFAULT_OVPK_M_X,\n        DEFAULT_OVPK_M_Y, DEFAULT_TPK_M_X, DEFAULT_TPK_M_Y, GENERATOR_INDEX__PUBLIC_KEYS_HASH,\n    },\n    hash::poseidon2_hash_with_separator,\n    point::POINT_LENGTH,\n    traits::{Deserialize, Hash, Serialize},\n};\n\nuse dep::std::embedded_curve_ops::EmbeddedCurvePoint as Point;\nuse std::default::Default;\n\npub global PUBLIC_KEYS_LENGTH: u32 = 12;\n\npub struct PublicKeys {\n    pub npk_m: NpkM,\n    pub ivpk_m: IvpkM,\n    pub ovpk_m: OvpkM,\n    pub tpk_m: TpkM,\n}\n\npub trait ToPoint {\n    fn to_point(self) -> Point;\n}\n\npub struct NpkM {\n    pub inner: Point,\n}\n\nimpl ToPoint for NpkM {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\nimpl Serialize<POINT_LENGTH> for NpkM {\n    fn serialize(self) -> [Field; POINT_LENGTH] {\n        self.inner.serialize()\n    }\n}\n\n// Note: If we store npk_m_hash directly we can remove this trait implementation. See #8091\nimpl Hash for NpkM {\n    fn hash(self) -> Field {\n        self.inner.hash()\n    }\n}\n\npub struct IvpkM {\n    pub inner: Point,\n}\n\nimpl ToPoint for IvpkM {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\nimpl Serialize<POINT_LENGTH> for IvpkM {\n    fn serialize(self) -> [Field; POINT_LENGTH] {\n        self.inner.serialize()\n    }\n}\n\npub struct OvpkM {\n    pub inner: Point,\n}\n\nimpl Hash for OvpkM {\n    fn hash(self) -> Field {\n        self.inner.hash()\n    }\n}\n\nimpl ToPoint for OvpkM {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\nimpl Serialize<POINT_LENGTH> for OvpkM {\n    fn serialize(self) -> [Field; POINT_LENGTH] {\n        self.inner.serialize()\n    }\n}\n\npub struct TpkM {\n    pub inner: Point,\n}\n\nimpl ToPoint for TpkM {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\nimpl Serialize<POINT_LENGTH> for TpkM {\n    fn serialize(self) -> [Field; POINT_LENGTH] {\n        self.inner.serialize()\n    }\n}\n\nimpl Default for PublicKeys {\n    fn default() -> Self {\n        PublicKeys {\n            npk_m: NpkM {\n                inner: Point { x: DEFAULT_NPK_M_X, y: DEFAULT_NPK_M_Y, is_infinite: false },\n            },\n            ivpk_m: IvpkM {\n                inner: Point { x: DEFAULT_IVPK_M_X, y: DEFAULT_IVPK_M_Y, is_infinite: false },\n            },\n            ovpk_m: OvpkM {\n                inner: Point { x: DEFAULT_OVPK_M_X, y: DEFAULT_OVPK_M_Y, is_infinite: false },\n            },\n            tpk_m: TpkM {\n                inner: Point { x: DEFAULT_TPK_M_X, y: DEFAULT_TPK_M_Y, is_infinite: false },\n            },\n        }\n    }\n}\n\nimpl Eq for PublicKeys {\n    fn eq(self, other: PublicKeys) -> bool {\n        (self.npk_m.inner == other.npk_m.inner)\n            & (self.ivpk_m.inner == other.ivpk_m.inner)\n            & (self.ovpk_m.inner == other.ovpk_m.inner)\n            & (self.tpk_m.inner == other.tpk_m.inner)\n    }\n}\n\nimpl PublicKeys {\n    pub fn hash(self) -> PublicKeysHash {\n        PublicKeysHash::from_field(poseidon2_hash_with_separator(\n            self.serialize(),\n            GENERATOR_INDEX__PUBLIC_KEYS_HASH as Field,\n        ))\n    }\n}\n\nimpl Serialize<PUBLIC_KEYS_LENGTH> for PublicKeys {\n    fn serialize(self) -> [Field; PUBLIC_KEYS_LENGTH] {\n        [\n            self.npk_m.inner.x,\n            self.npk_m.inner.y,\n            self.npk_m.inner.is_infinite as Field,\n            self.ivpk_m.inner.x,\n            self.ivpk_m.inner.y,\n            self.ivpk_m.inner.is_infinite as Field,\n            self.ovpk_m.inner.x,\n            self.ovpk_m.inner.y,\n            self.ovpk_m.inner.is_infinite as Field,\n            self.tpk_m.inner.x,\n            self.tpk_m.inner.y,\n            self.tpk_m.inner.is_infinite as Field,\n        ]\n    }\n}\n\nimpl Deserialize<PUBLIC_KEYS_LENGTH> for PublicKeys {\n    fn deserialize(serialized: [Field; PUBLIC_KEYS_LENGTH]) -> PublicKeys {\n        PublicKeys {\n            npk_m: NpkM {\n                inner: Point {\n                    x: serialized[0],\n                    y: serialized[1],\n                    is_infinite: serialized[2] as bool,\n                },\n            },\n            ivpk_m: IvpkM {\n                inner: Point {\n                    x: serialized[3],\n                    y: serialized[4],\n                    is_infinite: serialized[5] as bool,\n                },\n            },\n            ovpk_m: OvpkM {\n                inner: Point {\n                    x: serialized[6],\n                    y: serialized[7],\n                    is_infinite: serialized[8] as bool,\n                },\n            },\n            tpk_m: TpkM {\n                inner: Point {\n                    x: serialized[9],\n                    y: serialized[10],\n                    is_infinite: serialized[11] as bool,\n                },\n            },\n        }\n    }\n}\n\npub struct AddressPoint {\n    pub inner: Point,\n}\n\nimpl ToPoint for AddressPoint {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\n#[test]\nunconstrained fn compute_public_keys_hash() {\n    let keys = PublicKeys {\n        npk_m: NpkM { inner: Point { x: 1, y: 2, is_infinite: false } },\n        ivpk_m: IvpkM { inner: Point { x: 3, y: 4, is_infinite: false } },\n        ovpk_m: OvpkM { inner: Point { x: 5, y: 6, is_infinite: false } },\n        tpk_m: TpkM { inner: Point { x: 7, y: 8, is_infinite: false } },\n    };\n\n    let actual = keys.hash();\n    let expected_public_keys_hash =\n        0x0fecd9a32db731fec1fded1b9ff957a1625c069245a3613a2538bd527068b0ad;\n\n    assert(actual.to_field() == expected_public_keys_hash);\n}\n\n#[test]\nunconstrained fn compute_default_hash() {\n    let keys = PublicKeys::default();\n\n    let actual = keys.hash();\n    let test_data_default_hash = 0x1d3bf1fb93ae0e9cda83b203dd91c3bfb492a9aecf30ec90e1057eced0f0e62d;\n\n    assert(actual.to_field() == test_data_default_hash);\n}\n\n#[test]\nunconstrained fn test_public_keys_serialization() {\n    let keys = PublicKeys {\n        npk_m: NpkM { inner: Point { x: 1, y: 2, is_infinite: false } },\n        ivpk_m: IvpkM { inner: Point { x: 3, y: 4, is_infinite: false } },\n        ovpk_m: OvpkM { inner: Point { x: 5, y: 6, is_infinite: false } },\n        tpk_m: TpkM { inner: Point { x: 7, y: 8, is_infinite: false } },\n    };\n\n    let serialized = keys.serialize();\n    let deserialized = PublicKeys::deserialize(serialized);\n\n    assert_eq(keys.npk_m.inner.x, deserialized.npk_m.inner.x);\n    assert_eq(keys.npk_m.inner.y, deserialized.npk_m.inner.y);\n    assert_eq(keys.ivpk_m.inner.x, deserialized.ivpk_m.inner.x);\n    assert_eq(keys.ivpk_m.inner.y, deserialized.ivpk_m.inner.y);\n    assert_eq(keys.ovpk_m.inner.x, deserialized.ovpk_m.inner.x);\n    assert_eq(keys.ovpk_m.inner.y, deserialized.ovpk_m.inner.y);\n    assert_eq(keys.tpk_m.inner.x, deserialized.tpk_m.inner.x);\n    assert_eq(keys.tpk_m.inner.y, deserialized.tpk_m.inner.y);\n}\n"},"338":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/type_serialization.nr","source":"use crate::traits::{Deserialize, Serialize};\n\nglobal BOOL_SERIALIZED_LEN: u32 = 1;\nglobal U8_SERIALIZED_LEN: u32 = 1;\nglobal U16_SERIALIZED_LEN: u32 = 1;\nglobal U32_SERIALIZED_LEN: u32 = 1;\nglobal U64_SERIALIZED_LEN: u32 = 1;\nglobal U128_SERIALIZED_LEN: u32 = 1;\nglobal FIELD_SERIALIZED_LEN: u32 = 1;\nglobal I8_SERIALIZED_LEN: u32 = 1;\nglobal I16_SERIALIZED_LEN: u32 = 1;\nglobal I32_SERIALIZED_LEN: u32 = 1;\nglobal I64_SERIALIZED_LEN: u32 = 1;\n\nimpl Serialize<BOOL_SERIALIZED_LEN> for bool {\n    fn serialize(self) -> [Field; BOOL_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<BOOL_SERIALIZED_LEN> for bool {\n    fn deserialize(fields: [Field; BOOL_SERIALIZED_LEN]) -> bool {\n        fields[0] as bool\n    }\n}\n\nimpl Serialize<U8_SERIALIZED_LEN> for u8 {\n    fn serialize(self) -> [Field; U8_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U8_SERIALIZED_LEN> for u8 {\n    fn deserialize(fields: [Field; U8_SERIALIZED_LEN]) -> Self {\n        fields[0] as u8\n    }\n}\n\nimpl Serialize<U16_SERIALIZED_LEN> for u16 {\n    fn serialize(self) -> [Field; U16_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U16_SERIALIZED_LEN> for u16 {\n    fn deserialize(fields: [Field; U16_SERIALIZED_LEN]) -> Self {\n        fields[0] as u16\n    }\n}\n\nimpl Serialize<U32_SERIALIZED_LEN> for u32 {\n    fn serialize(self) -> [Field; U32_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U32_SERIALIZED_LEN> for u32 {\n    fn deserialize(fields: [Field; U32_SERIALIZED_LEN]) -> Self {\n        fields[0] as u32\n    }\n}\n\nimpl Serialize<U64_SERIALIZED_LEN> for u64 {\n    fn serialize(self) -> [Field; U64_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U64_SERIALIZED_LEN> for u64 {\n    fn deserialize(fields: [Field; U64_SERIALIZED_LEN]) -> Self {\n        fields[0] as u64\n    }\n}\n\nimpl Serialize<U128_SERIALIZED_LEN> for u128 {\n    fn serialize(self) -> [Field; U128_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U128_SERIALIZED_LEN> for u128 {\n    fn deserialize(fields: [Field; U128_SERIALIZED_LEN]) -> Self {\n        fields[0] as u128\n    }\n}\n\nimpl Serialize<FIELD_SERIALIZED_LEN> for Field {\n    fn serialize(self) -> [Field; FIELD_SERIALIZED_LEN] {\n        [self]\n    }\n}\n\nimpl Deserialize<FIELD_SERIALIZED_LEN> for Field {\n    fn deserialize(fields: [Field; FIELD_SERIALIZED_LEN]) -> Self {\n        fields[0]\n    }\n}\n\nimpl Serialize<I8_SERIALIZED_LEN> for i8 {\n    fn serialize(self) -> [Field; I8_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I8_SERIALIZED_LEN> for i8 {\n    fn deserialize(fields: [Field; I8_SERIALIZED_LEN]) -> Self {\n        fields[0] as i8\n    }\n}\n\nimpl Serialize<I16_SERIALIZED_LEN> for i16 {\n    fn serialize(self) -> [Field; I16_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I16_SERIALIZED_LEN> for i16 {\n    fn deserialize(fields: [Field; I16_SERIALIZED_LEN]) -> Self {\n        fields[0] as i16\n    }\n}\n\nimpl Serialize<I32_SERIALIZED_LEN> for i32 {\n    fn serialize(self) -> [Field; I32_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I32_SERIALIZED_LEN> for i32 {\n    fn deserialize(fields: [Field; I32_SERIALIZED_LEN]) -> Self {\n        fields[0] as i32\n    }\n}\n\nimpl Serialize<I64_SERIALIZED_LEN> for i64 {\n    fn serialize(self) -> [Field; I64_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I64_SERIALIZED_LEN> for i64 {\n    fn deserialize(fields: [Field; I64_SERIALIZED_LEN]) -> Self {\n        fields[0] as i64\n    }\n}\n\nimpl<T, let N: u32, let M: u32> Serialize<N * M> for [T; N]\nwhere\n    T: Serialize<M>,\n{\n    fn serialize(self) -> [Field; N * M] {\n        let mut result: [Field; N * M] = std::mem::zeroed();\n        let mut serialized: [Field; M] = std::mem::zeroed();\n        for i in 0..N {\n            serialized = self[i].serialize();\n            for j in 0..M {\n                result[i * M + j] = serialized[j];\n            }\n        }\n        result\n    }\n}\n\nimpl<T, let N: u32, let M: u32> Deserialize<N * M> for [T; N]\nwhere\n    T: Deserialize<M>,\n{\n    fn deserialize(fields: [Field; N * M]) -> Self {\n        let mut reader = crate::utils::reader::Reader::new(fields);\n        let mut result: [T; N] = std::mem::zeroed();\n        reader.read_struct_array::<T, M, N>(Deserialize::deserialize, result)\n    }\n}\n\n#[test]\nfn test_u16_serialization() {\n    let a: u16 = 10;\n    assert_eq(a, u16::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i8_serialization() {\n    let a: i8 = -10;\n    assert_eq(a, i8::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i16_serialization() {\n    let a: i16 = -10;\n    assert_eq(a, i16::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i32_serialization() {\n    let a: i32 = -10;\n    assert_eq(a, i32::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i64_serialization() {\n    let a: i64 = -10;\n    assert_eq(a, i64::deserialize(a.serialize()));\n}\n"},"354":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/noir-protocol-circuits/crates/types/src/utils/arrays.nr","source":"pub mod assert_array_appended;\npub mod assert_array_prepended;\npub mod assert_combined_array;\npub mod assert_combined_transformed_array;\npub mod assert_exposed_sorted_transformed_value_array;\npub mod assert_sorted_array;\npub mod assert_sorted_transformed_value_array;\npub mod assert_split_sorted_transformed_value_arrays;\npub mod assert_split_transformed_value_arrays;\npub mod get_sorted_result;\npub mod get_sorted_tuple;\npub mod sort_by;\npub mod sort_by_counter;\n\n// Re-exports.\npub use assert_array_appended::{\n    assert_array_appended, assert_array_appended_and_scoped, assert_array_appended_reversed,\n    assert_array_appended_scoped,\n};\npub use assert_array_prepended::assert_array_prepended;\npub use assert_combined_array::{assert_combined_array, combine_arrays};\npub use assert_combined_transformed_array::{\n    assert_combined_transformed_array, combine_and_transform_arrays,\n};\npub use assert_exposed_sorted_transformed_value_array::{\n    assert_exposed_sorted_transformed_value_array,\n    get_order_hints::{get_order_hints_asc, OrderHint},\n};\npub use assert_sorted_array::assert_sorted_array;\npub use assert_sorted_transformed_value_array::{\n    assert_sorted_transformed_value_array, assert_sorted_transformed_value_array_capped_size,\n};\npub use assert_split_sorted_transformed_value_arrays::{\n    assert_split_sorted_transformed_value_arrays_asc,\n    get_split_order_hints::{get_split_order_hints_asc, SplitOrderHints},\n};\npub use assert_split_transformed_value_arrays::assert_split_transformed_value_arrays;\npub use get_sorted_result::{get_sorted_result, SortedResult};\npub use sort_by_counter::sort_by_counter_asc;\n\nuse crate::traits::{Empty, is_empty};\n\npub fn subarray<let SRC_LEN: u32, let DST_LEN: u32>(\n    src: [Field; SRC_LEN],\n    offset: u32,\n) -> [Field; DST_LEN] {\n    assert(offset + DST_LEN <= SRC_LEN, \"offset too large\");\n\n    let mut dst: [Field; DST_LEN] = std::mem::zeroed();\n    for i in 0..DST_LEN {\n        dst[i] = src[i + offset];\n    }\n\n    dst\n}\n\n// Helper function to convert a validated array to BoundedVec.\n// Important: Only use it for validated arrays: validate_array(array) should be true.\npub unconstrained fn array_to_bounded_vec<T, let N: u32>(array: [T; N]) -> BoundedVec<T, N>\nwhere\n    T: Empty + Eq,\n{\n    let len = array_length(array);\n    BoundedVec::from_parts_unchecked(array, len)\n}\n\n// Helper function to find the index of the first element in an array that satisfies a given predicate. If the element\n// is not found, the function returns N as the index.\npub unconstrained fn find_index_hint<T, let N: u32, Env>(\n    array: [T; N],\n    find: fn[Env](T) -> bool,\n) -> u32 {\n    let mut index = N;\n    for i in 0..N {\n        // We check `index == N` to ensure that we only update the index if we haven't found a match yet.\n        if (index == N) & find(array[i]) {\n            index = i;\n        }\n    }\n    index\n}\n\n// Routine which validates that all zero values of an array form a contiguous region at the end, i.e.,\n// of the form: [*,*,*...,0,0,0,0] where any * is non-zero. Note that a full array of non-zero values is\n// valid.\npub fn validate_array<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    let mut seen_empty = false;\n    let mut length = 0;\n    for i in 0..N {\n        if is_empty(array[i]) {\n            seen_empty = true;\n        } else {\n            assert(seen_empty == false, \"invalid array\");\n            length += 1;\n        }\n    }\n    length\n}\n\n// Helper function to count the number of non-empty elements in a validated array.\n// Important: Only use it for validated arrays where validate_array(array) returns true,\n// which ensures that:\n// 1. All elements before the first empty element are non-empty\n// 2. All elements after and including the first empty element are empty\n// 3. The array forms a contiguous sequence of non-empty elements followed by empty elements\npub fn array_length<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    // We get the length by checking the index of the first empty element.\n\n    // Safety: This is safe because we have validated the array (see function doc above) and the emptiness\n    // of the element and non-emptiness of the previous element is checked below.\n    let length = unsafe { find_index_hint(array, |elem: T| is_empty(elem)) };\n    if length != 0 {\n        assert(!is_empty(array[length - 1]));\n    }\n    if length != N {\n        assert(is_empty(array[length]));\n    }\n    length\n}\n\n// Returns the number of consecutive elements at the start of the array for which the predicate returns false.\n// This function ensures that any element after the first matching element (predicate returns true) also matches the predicate.\npub fn array_length_until<T, let N: u32, Env>(array: [T; N], predicate: fn[Env](T) -> bool) -> u32 {\n    let mut length = 0;\n    let mut stop = false;\n    for i in 0..N {\n        if predicate(array[i]) {\n            stop = true;\n        } else {\n            assert(\n                stop == false,\n                \"matching element found after already encountering a non-matching element\",\n            );\n            length += 1;\n        }\n    }\n    length\n}\n\npub fn array_concat<T, let N: u32, let M: u32>(array1: [T; N], array2: [T; M]) -> [T; N + M] {\n    let mut result = [array1[0]; N + M];\n    for i in 1..N {\n        result[i] = array1[i];\n    }\n    for i in 0..M {\n        result[i + N] = array2[i];\n    }\n    result\n}\n\n/// This function assumes that `array1` and `array2` contain no more than N non-empty elements between them,\n/// if this is not the case then elements from the end of `array2` will be dropped.\npub fn array_merge<T, let N: u32>(array1: [T; N], array2: [T; N]) -> [T; N]\nwhere\n    T: Empty + Eq,\n{\n    // Safety: we constrain this array below\n    let result = unsafe { array_merge_helper(array1, array2) };\n    // We assume arrays have been validated. The only use cases so far are with previously validated arrays.\n    let array1_len = array_length(array1);\n    let mut add_from_left = true;\n    for i in 0..N {\n        add_from_left &= i != array1_len;\n        if add_from_left {\n            assert_eq(result[i], array1[i]);\n        } else {\n            assert_eq(result[i], array2[i - array1_len]);\n        }\n    }\n    result\n}\n\nunconstrained fn array_merge_helper<T, let N: u32>(array1: [T; N], array2: [T; N]) -> [T; N]\nwhere\n    T: Empty + Eq,\n{\n    let mut result: [T; N] = [T::empty(); N];\n    let mut i = 0;\n    for elem in array1 {\n        if !is_empty(elem) {\n            result[i] = elem;\n            i += 1;\n        }\n    }\n    for elem in array2 {\n        if !is_empty(elem) {\n            result[i] = elem;\n            i += 1;\n        }\n    }\n    result\n}\n\n// Helper fn to create a subarray from a given array\npub fn array_splice<T, let N: u32, let M: u32>(array: [T; N], offset: u32) -> [T; M]\nwhere\n    T: Empty,\n{\n    assert(M + offset <= N, \"Subarray length larger than array length\");\n    let mut result: [T; M] = [T::empty(); M];\n    for i in 0..M {\n        result[i] = array[offset + i];\n    }\n    result\n}\n\npub fn check_permutation<T, let N: u32>(\n    original_array: [T; N],\n    permuted_array: [T; N],\n    original_indexes: [u32; N],\n)\nwhere\n    T: Eq + Empty,\n{\n    let mut seen_value = [false; N];\n    for i in 0..N {\n        let index = original_indexes[i];\n        let original_value = original_array[index];\n        assert(permuted_array[i].eq(original_value), \"Invalid index\");\n        assert(!seen_value[index], \"Duplicated index\");\n        seen_value[index] = true;\n    }\n}\n\n// Helper function to find the index of the last element in an array, allowing empty elements.\n// e.g. useful for removing trailing 0s from [1, 0, 2, 0, 0, 0] -> [1, 0, 2]\n// Nothing to do with validated arrays. Correctness constrained by padded_array_length.\npub unconstrained fn find_last_value_index<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    let mut index = N;\n    for i in 0..N {\n        let j = N - i - 1;\n        // We check `index == N` to ensure that we only update the index if we haven't found a match yet.\n        if (index == N) & !is_empty(array[j]) {\n            index = j;\n        }\n    }\n    index\n}\n\n// Routine which returns the length of an array right padded by empty elements\n// of the form: [*,*,*...,0,0,0,0] where * is any value (zeroes allowed).\n// See smoke_validate_array_trailing for examples.\n// Nothing to do with validated arrays. Correctness constrained by padded_array_length.\npub unconstrained fn unsafe_padded_array_length<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    let index = find_last_value_index(array);\n    if index == N {\n        0\n    } else {\n        index + 1\n    }\n}\n\n// Routine which validates that zero values of an array form a contiguous region at the end, i.e.,\n// of the form: [*,*,*...,0,0,0,0] where * is any value (zeroes allowed).\npub fn padded_array_length<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    // Safety: this value is constrained in the below loop.\n    let length = unsafe { unsafe_padded_array_length(array) };\n    // Check the elt just before length is non-zero:\n    if length != 0 {\n        assert(!is_empty(array[length - 1]), \"invalid right padded array\");\n    }\n    // Check all beyond length are zero:\n    let mut check_zero = false;\n    for i in 0..N {\n        check_zero |= i == length;\n        if check_zero {\n            assert(is_empty(array[i]), \"invalid right padded array\");\n        }\n    }\n    length\n}\n\n// Helper function to check if an array is padded with a given value from a given index.\n// Different to padded_array_length in that it allows the elements before the given index to be the same as the padded value.\npub fn array_padded_with<T, let N: u32>(array: [T; N], from_index: u32, padded_with: T) -> bool\nwhere\n    T: Eq,\n{\n    let mut is_valid = true;\n    let mut should_check = false;\n    for i in 0..N {\n        should_check |= i == from_index;\n        is_valid &= !should_check | (array[i] == padded_with);\n    }\n    is_valid\n}\n\n#[test]\nfn smoke_validate_array() {\n    let valid_array: [Field; 0] = [];\n    assert(validate_array(valid_array) == 0);\n\n    let valid_array = [0];\n    assert(validate_array(valid_array) == 0);\n\n    let valid_array = [3];\n    assert(validate_array(valid_array) == 1);\n\n    let valid_array = [1, 2, 3];\n    assert(validate_array(valid_array) == 3);\n\n    let valid_array = [1, 2, 3, 0];\n    assert(validate_array(valid_array) == 3);\n\n    let valid_array = [1, 2, 3, 0, 0];\n    assert(validate_array(valid_array) == 3);\n}\n\n#[test]\nfn smoke_validate_array_trailing() {\n    let valid_array: [Field; 0] = [];\n    assert(padded_array_length(valid_array) == 0);\n\n    let valid_array = [0];\n    assert(padded_array_length(valid_array) == 0);\n\n    let valid_array = [3];\n    assert(padded_array_length(valid_array) == 1);\n\n    let valid_array = [1, 0, 3];\n    assert(padded_array_length(valid_array) == 3);\n\n    let valid_array = [1, 0, 3, 0];\n    assert(padded_array_length(valid_array) == 3);\n\n    let valid_array = [1, 2, 3, 0, 0];\n    assert(padded_array_length(valid_array) == 3);\n\n    let valid_array = [0, 0, 3, 0, 0];\n    assert(padded_array_length(valid_array) == 3);\n}\n\n#[test(should_fail_with = \"invalid array\")]\nfn smoke_validate_array_invalid_case0() {\n    let invalid_array = [0, 1];\n    let _ = validate_array(invalid_array);\n}\n\n#[test(should_fail_with = \"invalid array\")]\nfn smoke_validate_array_invalid_case1() {\n    let invalid_array = [1, 0, 0, 1, 0];\n    let _ = validate_array(invalid_array);\n}\n\n#[test(should_fail_with = \"invalid array\")]\nfn smoke_validate_array_invalid_case2() {\n    let invalid_array = [0, 0, 0, 0, 1];\n    let _ = validate_array(invalid_array);\n}\n\n#[test]\nfn test_empty_array_length() {\n    assert_eq(array_length([0]), 0);\n    assert_eq(array_length([0, 0, 0]), 0);\n}\n\n#[test]\nfn test_array_length() {\n    assert_eq(array_length([123]), 1);\n    assert_eq(array_length([123, 0, 0]), 1);\n    assert_eq(array_length([123, 456]), 2);\n    assert_eq(array_length([123, 456, 0]), 2);\n}\n\n#[test]\nfn test_array_length_invalid_arrays() {\n    // Result can be misleading (but correct) for invalid arrays.\n    assert_eq(array_length([0, 0, 123]), 0);\n    assert_eq(array_length([0, 123, 0]), 0);\n    assert_eq(array_length([0, 123, 456]), 0);\n    assert_eq(array_length([123, 0, 456]), 1);\n}\n\n#[test]\nfn test_array_length_until() {\n    let array = [11, 22, 33, 44, 55];\n    assert_eq(array_length_until(array, |x| x == 55), 4);\n    assert_eq(array_length_until(array, |x| x == 56), 5);\n    assert_eq(array_length_until(array, |x| x > 40), 3);\n    assert_eq(array_length_until(array, |x| x > 10), 0);\n}\n\n#[test(should_fail_with = \"matching element found after already encountering a non-matching element\")]\nfn test_array_length_until_non_consecutive_fails() {\n    let array = [1, 1, 0, 1, 0];\n    let _ = array_length_until(array, |x| x == 0);\n}\n\n#[test(should_fail_with = \"matching element found after already encountering a non-matching element\")]\nfn test_array_length_until_first_non_matching_fails() {\n    let array = [1, 0, 0, 0, 0];\n    let _ = array_length_until(array, |x| x == 1);\n}\n\n#[test]\nunconstrained fn find_index_greater_than_min() {\n    let values = [10, 20, 30, 40];\n    let min = 22;\n    let index = find_index_hint(values, |v: Field| min.lt(v));\n    assert_eq(index, 2);\n}\n\n#[test]\nunconstrained fn find_index_not_found() {\n    let values = [10, 20, 30, 40];\n    let min = 100;\n    let index = find_index_hint(values, |v: Field| min.lt(v));\n    assert_eq(index, 4);\n}\n\n#[test]\nfn test_array_concat() {\n    let array0 = [1, 2, 3];\n    let array1 = [4, 5];\n    let concatenated = array_concat(array0, array1);\n    assert_eq(concatenated, [1, 2, 3, 4, 5]);\n}\n\n#[test]\nfn check_permutation_basic_test() {\n    let original_array = [1, 2, 3];\n    let permuted_array = [3, 1, 2];\n    let indexes = [2, 0, 1];\n    check_permutation(original_array, permuted_array, indexes);\n}\n\n#[test(should_fail_with = \"Duplicated index\")]\nfn check_permutation_duplicated_index() {\n    let original_array = [0, 1, 0];\n    let permuted_array = [1, 0, 0];\n    let indexes = [1, 0, 0];\n    check_permutation(original_array, permuted_array, indexes);\n}\n\n#[test(should_fail_with = \"Invalid index\")]\nfn check_permutation_invalid_index() {\n    let original_array = [0, 1, 2];\n    let permuted_array = [1, 0, 0];\n    let indexes = [1, 0, 2];\n    check_permutation(original_array, permuted_array, indexes);\n}\n\n#[test]\nfn test_array_padded_with() {\n    let array = [11, 22, 33, 44, 44];\n    assert_eq(array_padded_with(array, 0, 44), false);\n    assert_eq(array_padded_with(array, 1, 44), false);\n    assert_eq(array_padded_with(array, 2, 44), false);\n    assert_eq(array_padded_with(array, 3, 44), true);\n    assert_eq(array_padded_with(array, 4, 44), true);\n    assert_eq(array_padded_with(array, 4, 33), false);\n    assert_eq(array_padded_with(array, 5, 44), true); // Index out of bounds.\n    assert_eq(array_padded_with(array, 0, 11), false);\n}\n"},"367":{"path":"/home/lucholeonel/nargo/github.com/noir-lang/sha256/v0.1.2/src/sha256.nr","source":"use std::hash::sha256_compression;\nuse std::runtime::is_unconstrained;\n\nuse constants::{\n    BLOCK_BYTE_PTR, BLOCK_SIZE, HASH, INITIAL_STATE, INT_BLOCK, INT_BLOCK_SIZE, INT_SIZE,\n    INT_SIZE_PTR, MSG_BLOCK, MSG_SIZE_PTR, STATE, TWO_POW_16, TWO_POW_24, TWO_POW_32, TWO_POW_8,\n};\n\nmod constants;\nmod tests;\n\n// Implementation of SHA-256 mapping a byte array of variable length to\n// 32 bytes.\n\n// Deprecated in favour of `sha256_var`\n// docs:start:sha256\npub fn sha256<let N: u32>(input: [u8; N]) -> HASH\n// docs:end:sha256\n{\n    digest(input)\n}\n\n// SHA-256 hash function\n#[no_predicates]\npub fn digest<let N: u32>(msg: [u8; N]) -> HASH {\n    sha256_var(msg, N as u64)\n}\n\n// Variable size SHA-256 hash\npub fn sha256_var<let N: u32>(msg: [u8; N], message_size: u64) -> HASH {\n    let message_size = message_size as u32;\n    assert(message_size <= N);\n\n    if std::runtime::is_unconstrained() {\n        // Safety: SHA256 is running as an unconstrained function.\n        unsafe {\n            __sha256_var(msg, message_size)\n        }\n    } else {\n        let mut msg_block: MSG_BLOCK = [0; INT_BLOCK_SIZE];\n        // Intermediate hash, starting with the canonical initial value\n        let mut h: STATE = INITIAL_STATE;\n        // Pointer into msg_block on a 64 byte scale\n        let mut msg_byte_ptr = 0;\n        let num_blocks = N / BLOCK_SIZE;\n        for i in 0..num_blocks {\n            let msg_start = BLOCK_SIZE * i;\n            let (new_msg_block, new_msg_byte_ptr) =\n                unsafe { build_msg_block(msg, message_size, msg_start) };\n\n            if msg_start < message_size {\n                msg_block = new_msg_block;\n            }\n\n            // Verify the block we are compressing was appropriately constructed\n            let new_msg_byte_ptr = verify_msg_block(msg, message_size, msg_block, msg_start);\n            if msg_start < message_size {\n                msg_byte_ptr = new_msg_byte_ptr;\n            }\n\n            // If the block is filled, compress it.\n            // An un-filled block is handled after this loop.\n            if (msg_start < message_size) & (msg_byte_ptr == BLOCK_SIZE) {\n                h = sha256_compression(msg_block, h);\n            }\n        }\n\n        let modulo = N % BLOCK_SIZE;\n        // Handle setup of the final msg block.\n        // This case is only hit if the msg is less than the block size,\n        // or our message cannot be evenly split into blocks.\n        if modulo != 0 {\n            let msg_start = BLOCK_SIZE * num_blocks;\n            let (new_msg_block, new_msg_byte_ptr) =\n                unsafe { build_msg_block(msg, message_size, msg_start) };\n\n            if msg_start < message_size {\n                msg_block = new_msg_block;\n            }\n\n            let new_msg_byte_ptr = verify_msg_block(msg, message_size, msg_block, msg_start);\n            if msg_start < message_size {\n                msg_byte_ptr = new_msg_byte_ptr;\n                verify_msg_block_padding(msg_block, msg_byte_ptr);\n            }\n        }\n\n        // If we had modulo == 0 then it means the last block was full,\n        // and we can reset the pointer to zero to overwrite it.\n        if msg_byte_ptr == BLOCK_SIZE {\n            msg_byte_ptr = 0;\n        }\n\n        // Pad the rest such that we have a [u32; 2] block at the end representing the length\n        // of the message, and a block of 1 0 ... 0 following the message (i.e. [1 << 7, 0, ..., 0]).\n        // Here we rely on the fact that everything beyond the available input is set to 0.\n        let index = msg_byte_ptr / INT_SIZE;\n        msg_block[index] = set_item_byte_then_zeros(msg_block[index], msg_byte_ptr, 1 << 7);\n\n        msg_byte_ptr = msg_byte_ptr + 1;\n        let last_block = msg_block;\n\n        // If we don't have room to write the size, compress the block and reset it.\n        if msg_byte_ptr > MSG_SIZE_PTR {\n            h = sha256_compression(msg_block, h);\n            // `attach_len_to_msg_block` will zero out everything after the `msg_byte_ptr`.\n            msg_byte_ptr = 0;\n        }\n\n        msg_block = unsafe { attach_len_to_msg_block(msg_block, msg_byte_ptr, message_size) };\n\n        verify_msg_len(msg_block, last_block, msg_byte_ptr, message_size);\n\n        hash_final_block(msg_block, h)\n    }\n}\n\n// Variable size SHA-256 hash\nunconstrained fn __sha256_var<let N: u32>(msg: [u8; N], message_size: u32) -> HASH {\n    let num_full_blocks = message_size / BLOCK_SIZE;\n    // Intermediate hash, starting with the canonical initial value\n    let mut h: STATE = INITIAL_STATE;\n    // Pointer into msg_block on a 64 byte scale\n    for i in 0..num_full_blocks {\n        let (msg_block, _) = build_msg_block(msg, message_size, BLOCK_SIZE * i);\n        h = sha256_compression(msg_block, h);\n    }\n\n    // Handle setup of the final msg block.\n    // This case is only hit if the msg is less than the block size,\n    // or our message cannot be evenly split into blocks.\n    let modulo = message_size % BLOCK_SIZE;\n    let (mut msg_block, mut msg_byte_ptr): (INT_BLOCK, u32) = if modulo != 0 {\n        let msg_start = BLOCK_SIZE * num_full_blocks;\n        let (new_msg_block, new_msg_byte_ptr) = build_msg_block(msg, message_size, msg_start);\n\n        (new_msg_block, new_msg_byte_ptr)\n    } else {\n        // If we had modulo == 0 then it means the last block was full,\n        // and we can reset the pointer to zero to overwrite it.\n        ([0; INT_BLOCK_SIZE], 0)\n    };\n\n    // Pad the rest such that we have a [u32; 2] block at the end representing the length\n    // of the message, and a block of 1 0 ... 0 following the message (i.e. [1 << 7, 0, ..., 0]).\n    // Here we rely on the fact that everything beyond the available input is set to 0.\n    let index = msg_byte_ptr / INT_SIZE;\n    msg_block[index] = set_item_byte_then_zeros(msg_block[index], msg_byte_ptr, 1 << 7);\n\n    // If we don't have room to write the size, compress the block and reset it.\n    let (h, mut msg_byte_ptr): (STATE, u32) = if msg_byte_ptr >= MSG_SIZE_PTR {\n        // `attach_len_to_msg_block` will zero out everything after the `msg_byte_ptr`.\n        (sha256_compression(msg_block, h), 0)\n    } else {\n        (h, msg_byte_ptr + 1)\n    };\n    msg_block = attach_len_to_msg_block(msg_block, msg_byte_ptr, message_size);\n\n    hash_final_block(msg_block, h)\n}\n\n// Take `BLOCK_SIZE` number of bytes from `msg` starting at `msg_start`.\n// Returns the block and the length that has been copied rather than padded with zeros.\nunconstrained fn build_msg_block<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    msg_start: u32,\n) -> (MSG_BLOCK, BLOCK_BYTE_PTR) {\n    let mut msg_block: MSG_BLOCK = [0; INT_BLOCK_SIZE];\n\n    // We insert `BLOCK_SIZE` bytes (or up to the end of the message)\n    let block_input = if message_size < msg_start {\n        // This function is sometimes called with `msg_start` past the end of the message.\n        // In this case we return an empty block and zero pointer to signal that the result should be ignored.\n        0\n    } else if message_size < msg_start + BLOCK_SIZE {\n        message_size - msg_start\n    } else {\n        BLOCK_SIZE\n    };\n\n    // Figure out the number of items in the int array that we have to pack.\n    // e.g. if the input is [0,1,2,3,4,5] then we need to pack it as 2 items: [0123, 4500]\n    let mut int_input = block_input / INT_SIZE;\n    if block_input % INT_SIZE != 0 {\n        int_input = int_input + 1;\n    };\n\n    for i in 0..int_input {\n        let mut msg_item: u32 = 0;\n        // Always construct the integer as 4 bytes, even if it means going beyond the input.\n        for j in 0..INT_SIZE {\n            let k = i * INT_SIZE + j;\n            let msg_byte = if k < block_input {\n                msg[msg_start + k]\n            } else {\n                0\n            };\n            msg_item = lshift8(msg_item, 1) + msg_byte as u32;\n        }\n        msg_block[i] = msg_item;\n    }\n\n    // Returning the index as if it was a 64 byte array.\n    // We have to project it down to 16 items and bit shifting to get a byte back if we need it.\n    (msg_block, block_input)\n}\n\n// Verify the block we are compressing was appropriately constructed by `build_msg_block`\n// and matches the input data. Returns the index of the first unset item.\n// If `message_size` is less than `msg_start` then this is called with the old non-empty block;\n// in that case we can skip verification, ie. no need to check that everything is zero.\nfn verify_msg_block<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    msg_block: MSG_BLOCK,\n    msg_start: u32,\n) -> BLOCK_BYTE_PTR {\n    let mut msg_byte_ptr = 0;\n    let mut msg_end = msg_start + BLOCK_SIZE;\n    if msg_end > N {\n        msg_end = N;\n    }\n    // We might have to go beyond the input to pad the fields.\n    if msg_end % INT_SIZE != 0 {\n        msg_end = msg_end + INT_SIZE - msg_end % INT_SIZE;\n    }\n\n    // Reconstructed packed item.\n    let mut msg_item: u32 = 0;\n\n    // Inclusive at the end so that we can compare the last item.\n    let mut i: u32 = 0;\n    for k in msg_start..=msg_end {\n        if k % INT_SIZE == 0 {\n            // If we consumed some input we can compare against the block.\n            if (msg_start < message_size) & (k > msg_start) {\n                assert_eq(msg_block[i], msg_item as u32);\n                i = i + 1;\n                msg_item = 0;\n            }\n        }\n        // Shift the accumulator\n        msg_item = lshift8(msg_item, 1);\n        // If we have input to consume, add it at the rightmost position.\n        if k < message_size & k < msg_end {\n            msg_item = msg_item + msg[k] as u32;\n            msg_byte_ptr = msg_byte_ptr + 1;\n        }\n    }\n\n    msg_byte_ptr\n}\n\n// Verify the block we are compressing was appropriately padded with zeros by `build_msg_block`.\n// This is only relevant for the last, potentially partially filled block.\nfn verify_msg_block_padding(msg_block: MSG_BLOCK, msg_byte_ptr: BLOCK_BYTE_PTR) {\n    // Check all the way to the end of the block.\n    verify_msg_block_zeros(msg_block, msg_byte_ptr, INT_BLOCK_SIZE);\n}\n\n// Verify that a region of ints in the message block are (partially) zeroed,\n// up to an (exclusive) maximum which can either be the end of the block\n// or just where the size is to be written.\nfn verify_msg_block_zeros(\n    msg_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n    max_int_byte_ptr: u32,\n) {\n    // This variable is used to get around the compiler under-constrained check giving a warning.\n    // We want to check against a constant zero, but if it does not come from the circuit inputs\n    // or return values the compiler check will issue a warning.\n    let zero = msg_block[0] - msg_block[0];\n\n    // First integer which is supposed to be (partially) zero.\n    let mut int_byte_ptr = msg_byte_ptr / INT_SIZE;\n\n    // Check partial zeros.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        let zeros = INT_SIZE - modulo;\n        let mask = if zeros == 3 {\n            TWO_POW_24\n        } else if zeros == 2 {\n            TWO_POW_16\n        } else {\n            TWO_POW_8\n        };\n        assert_eq(msg_block[int_byte_ptr] % mask, zero);\n        int_byte_ptr = int_byte_ptr + 1;\n    }\n\n    // Check the rest of the items.\n    for i in 0..max_int_byte_ptr {\n        if i >= int_byte_ptr {\n            assert_eq(msg_block[i], zero);\n        }\n    }\n}\n\n// Verify that up to the byte pointer the two blocks are equal.\n// At the byte pointer the new block can be partially zeroed.\nfn verify_msg_block_equals_last(\n    msg_block: MSG_BLOCK,\n    last_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n) {\n    // msg_byte_ptr is the position at which they are no longer have to be the same.\n    // First integer which is supposed to be (partially) zero contains that pointer.\n    let mut int_byte_ptr = msg_byte_ptr / INT_SIZE;\n\n    // Check partial zeros.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        // Reconstruct the partially zero item from the last block.\n        let last_field = last_block[int_byte_ptr];\n        let mut msg_item: u32 = 0;\n        // Reset to where they are still equal.\n        msg_byte_ptr = msg_byte_ptr - modulo;\n        for i in 0..INT_SIZE {\n            msg_item = lshift8(msg_item, 1);\n            if i < modulo {\n                msg_item = msg_item + get_item_byte(last_field, msg_byte_ptr) as u32;\n                msg_byte_ptr = msg_byte_ptr + 1;\n            }\n        }\n        assert_eq(msg_block[int_byte_ptr], msg_item);\n    }\n\n    for i in 0..INT_SIZE_PTR {\n        if i < int_byte_ptr {\n            assert_eq(msg_block[i], last_block[i]);\n        }\n    }\n}\n\n// Set the rightmost `zeros` number of bytes to 0.\n#[inline_always]\nfn set_item_zeros(item: u32, zeros: u8) -> u32 {\n    lshift8(rshift8(item, zeros), zeros)\n}\n\n// Replace one byte in the item with a value, and set everything after it to zero.\nfn set_item_byte_then_zeros(msg_item: u32, msg_byte_ptr: BLOCK_BYTE_PTR, msg_byte: u8) -> u32 {\n    let zeros = INT_SIZE - msg_byte_ptr % INT_SIZE;\n    let zeroed_item = set_item_zeros(msg_item, zeros as u8);\n    let new_item = byte_into_item(msg_byte, msg_byte_ptr);\n    zeroed_item + new_item\n}\n\n// Get a byte of a message item according to its overall position in the `BLOCK_SIZE` space.\nfn get_item_byte(mut msg_item: u32, msg_byte_ptr: BLOCK_BYTE_PTR) -> u8 {\n    // How many times do we have to shift to the right to get to the position we want?\n    let max_shifts = INT_SIZE - 1;\n    let shifts = max_shifts - msg_byte_ptr % INT_SIZE;\n    msg_item = rshift8(msg_item, shifts as u8);\n    // At this point the byte we want is in the rightmost position.\n    msg_item as u8\n}\n\n// Project a byte into a position in a field based on the overall block pointer.\n// For example putting 1 into pointer 5 would be 100, because overall we would\n// have [____, 0100] with indexes [0123,4567].\n#[inline_always]\nfn byte_into_item(msg_byte: u8, msg_byte_ptr: BLOCK_BYTE_PTR) -> u32 {\n    let mut msg_item = msg_byte as u32;\n    // How many times do we have to shift to the left to get to the position we want?\n    let max_shifts = INT_SIZE - 1;\n    let shifts = max_shifts - msg_byte_ptr % INT_SIZE;\n    lshift8(msg_item, shifts as u8)\n}\n\n// Construct a field out of 4 bytes.\n#[inline_always]\nfn make_item(b0: u8, b1: u8, b2: u8, b3: u8) -> u32 {\n    let mut item = b0 as u32;\n    item = lshift8(item, 1) + b1 as u32;\n    item = lshift8(item, 1) + b2 as u32;\n    item = lshift8(item, 1) + b3 as u32;\n    item\n}\n\n// Shift by 8 bits to the left between 0 and 4 times.\n// Checks `is_unconstrained()` to just use a bitshift if we're running in an unconstrained context,\n// otherwise multiplies by 256.\n#[inline_always]\nfn lshift8(item: u32, shifts: u8) -> u32 {\n    if is_unconstrained() {\n        // Brillig wouldn't shift 0<<4 without overflow.\n        if shifts >= 4 {\n            0\n        } else {\n            item << (8 * shifts)\n        }\n    } else {\n        // We can do a for loop up to INT_SIZE or an if-else.\n        if shifts == 0 {\n            item\n        } else if shifts == 1 {\n            item * TWO_POW_8\n        } else if shifts == 2 {\n            item * TWO_POW_16\n        } else if shifts == 3 {\n            item * TWO_POW_24\n        } else {\n            // Doesn't make sense, but it's most likely called on 0 anyway.\n            0\n        }\n    }\n}\n\n// Shift by 8 bits to the right between 0 and 4 times.\n// Checks `is_unconstrained()` to just use a bitshift if we're running in an unconstrained context,\n// otherwise divides by 256.\nfn rshift8(item: u32, shifts: u8) -> u32 {\n    if is_unconstrained() {\n        item >> (8 * shifts)\n    } else {\n        // Division wouldn't work on `Field`.\n        if shifts == 0 {\n            item\n        } else if shifts == 1 {\n            item / TWO_POW_8\n        } else if shifts == 2 {\n            item / TWO_POW_16\n        } else if shifts == 3 {\n            item / TWO_POW_24\n        } else {\n            0\n        }\n    }\n}\n\n// Zero out all bytes between the end of the message and where the length is appended,\n// then write the length into the last 8 bytes of the block.\nunconstrained fn attach_len_to_msg_block(\n    mut msg_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n    message_size: u32,\n) -> MSG_BLOCK {\n    // We assume that `msg_byte_ptr` is less than 57 because if not then it is reset to zero before calling this function.\n    // In any case, fill blocks up with zeros until the last 64 bits (i.e. until msg_byte_ptr = 56).\n    // There can be one item which has to be partially zeroed.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        // Index of the block in which we find the item we need to partially zero.\n        let i = msg_byte_ptr / INT_SIZE;\n        let zeros = INT_SIZE - modulo;\n        msg_block[i] = set_item_zeros(msg_block[i], zeros as u8);\n        msg_byte_ptr = msg_byte_ptr + zeros;\n    }\n\n    // The rest can be zeroed without bit shifting anything.\n    for i in (msg_byte_ptr / INT_SIZE)..INT_SIZE_PTR {\n        msg_block[i] = 0;\n    }\n\n    // Set the last two 4 byte ints as the first/second half of the 8 bytes of the length.\n    let len = 8 * message_size;\n    let len_bytes: [u8; 8] = (len as Field).to_be_bytes();\n    for i in 0..=1 {\n        let shift = i * 4;\n        msg_block[INT_SIZE_PTR + i] = make_item(\n            len_bytes[shift],\n            len_bytes[shift + 1],\n            len_bytes[shift + 2],\n            len_bytes[shift + 3],\n        );\n    }\n    msg_block\n}\n\n// Verify that the message length was correctly written by `attach_len_to_msg_block`,\n// and that everything between the byte pointer and the size pointer was zeroed,\n// and that everything before the byte pointer was untouched.\nfn verify_msg_len(\n    msg_block: MSG_BLOCK,\n    last_block: MSG_BLOCK,\n    msg_byte_ptr: BLOCK_BYTE_PTR,\n    message_size: u32,\n) {\n    // Check zeros up to the size pointer.\n    verify_msg_block_zeros(msg_block, msg_byte_ptr, INT_SIZE_PTR);\n\n    // Check that up to the pointer we match the last block.\n    verify_msg_block_equals_last(msg_block, last_block, msg_byte_ptr);\n\n    // We verify the message length was inserted correctly by reversing the byte decomposition.\n    let mut reconstructed_len: u64 = 0;\n    for i in INT_SIZE_PTR..INT_BLOCK_SIZE {\n        reconstructed_len = reconstructed_len * TWO_POW_32;\n        reconstructed_len = reconstructed_len + msg_block[i] as u64;\n    }\n    let len = 8 * message_size as u64;\n    assert_eq(reconstructed_len, len);\n}\n\n// Perform the final compression, then transform the `STATE` into `HASH`.\nfn hash_final_block(msg_block: MSG_BLOCK, mut state: STATE) -> HASH {\n    let mut out_h: HASH = [0; 32]; // Digest as sequence of bytes\n    // Hash final padded block\n    state = sha256_compression(msg_block, state);\n\n    // Return final hash as byte array\n    for j in 0..8 {\n        let h_bytes: [u8; 4] = (state[j] as Field).to_be_bytes();\n        for k in 0..4 {\n            out_h[4 * j + k] = h_bytes[k];\n        }\n    }\n\n    out_h\n}\n\nmod equivalence_test {\n\n    #[test]\n    fn test_implementations_agree(msg: [u8; 100], message_size: u64) {\n        let message_size = message_size % 100;\n        let unconstrained_sha = unsafe { super::__sha256_var(msg, message_size as u32) };\n        let sha = super::sha256_var(msg, message_size);\n        assert_eq(sha, unconstrained_sha);\n    }\n}\n"},"42":{"path":"std/option.nr","source":"use crate::cmp::{Eq, Ord, Ordering};\nuse crate::default::Default;\nuse crate::hash::{Hash, Hasher};\n\npub struct Option<T> {\n    _is_some: bool,\n    _value: T,\n}\n\nimpl<T> Option<T> {\n    /// Constructs a None value\n    pub fn none() -> Self {\n        Self { _is_some: false, _value: crate::mem::zeroed() }\n    }\n\n    /// Constructs a Some wrapper around the given value\n    pub fn some(_value: T) -> Self {\n        Self { _is_some: true, _value }\n    }\n\n    /// True if this Option is None\n    pub fn is_none(self) -> bool {\n        !self._is_some\n    }\n\n    /// True if this Option is Some\n    pub fn is_some(self) -> bool {\n        self._is_some\n    }\n\n    /// Asserts `self.is_some()` and returns the wrapped value.\n    pub fn unwrap(self) -> T {\n        assert(self._is_some);\n        self._value\n    }\n\n    /// Returns the inner value without asserting `self.is_some()`\n    /// Note that if `self` is `None`, there is no guarantee what value will be returned,\n    /// only that it will be of type `T`.\n    pub fn unwrap_unchecked(self) -> T {\n        self._value\n    }\n\n    /// Returns the wrapped value if `self.is_some()`. Otherwise, returns the given default value.\n    pub fn unwrap_or(self, default: T) -> T {\n        if self._is_some {\n            self._value\n        } else {\n            default\n        }\n    }\n\n    /// Returns the wrapped value if `self.is_some()`. Otherwise, calls the given function to return\n    /// a default value.\n    pub fn unwrap_or_else<Env>(self, default: fn[Env]() -> T) -> T {\n        if self._is_some {\n            self._value\n        } else {\n            default()\n        }\n    }\n\n    /// Asserts `self.is_some()` with a provided custom message and returns the contained `Some` value\n    pub fn expect<let N: u32, MessageTypes>(self, message: fmtstr<N, MessageTypes>) -> T {\n        assert(self.is_some(), message);\n        self._value\n    }\n\n    /// If self is `Some(x)`, this returns `Some(f(x))`. Otherwise, this returns `None`.\n    pub fn map<U, Env>(self, f: fn[Env](T) -> U) -> Option<U> {\n        if self._is_some {\n            Option::some(f(self._value))\n        } else {\n            Option::none()\n        }\n    }\n\n    /// If self is `Some(x)`, this returns `f(x)`. Otherwise, this returns the given default value.\n    pub fn map_or<U, Env>(self, default: U, f: fn[Env](T) -> U) -> U {\n        if self._is_some {\n            f(self._value)\n        } else {\n            default\n        }\n    }\n\n    /// If self is `Some(x)`, this returns `f(x)`. Otherwise, this returns `default()`.\n    pub fn map_or_else<U, Env1, Env2>(self, default: fn[Env1]() -> U, f: fn[Env2](T) -> U) -> U {\n        if self._is_some {\n            f(self._value)\n        } else {\n            default()\n        }\n    }\n\n    /// Returns None if self is None. Otherwise, this returns `other`.\n    pub fn and(self, other: Self) -> Self {\n        if self.is_none() {\n            Option::none()\n        } else {\n            other\n        }\n    }\n\n    /// If self is None, this returns None. Otherwise, this calls the given function\n    /// with the Some value contained within self, and returns the result of that call.\n    ///\n    /// In some languages this function is called `flat_map` or `bind`.\n    pub fn and_then<U, Env>(self, f: fn[Env](T) -> Option<U>) -> Option<U> {\n        if self._is_some {\n            f(self._value)\n        } else {\n            Option::none()\n        }\n    }\n\n    /// If self is Some, return self. Otherwise, return `other`.\n    pub fn or(self, other: Self) -> Self {\n        if self._is_some {\n            self\n        } else {\n            other\n        }\n    }\n\n    /// If self is Some, return self. Otherwise, return `default()`.\n    pub fn or_else<Env>(self, default: fn[Env]() -> Self) -> Self {\n        if self._is_some {\n            self\n        } else {\n            default()\n        }\n    }\n\n    // If only one of the two Options is Some, return that option.\n    // Otherwise, if both options are Some or both are None, None is returned.\n    pub fn xor(self, other: Self) -> Self {\n        if self._is_some {\n            if other._is_some {\n                Option::none()\n            } else {\n                self\n            }\n        } else if other._is_some {\n            other\n        } else {\n            Option::none()\n        }\n    }\n\n    /// Returns `Some(x)` if self is `Some(x)` and `predicate(x)` is true.\n    /// Otherwise, this returns `None`\n    pub fn filter<Env>(self, predicate: fn[Env](T) -> bool) -> Self {\n        if self._is_some {\n            if predicate(self._value) {\n                self\n            } else {\n                Option::none()\n            }\n        } else {\n            Option::none()\n        }\n    }\n\n    /// Flattens an Option<Option<T>> into a Option<T>.\n    /// This returns None if the outer Option is None. Otherwise, this returns the inner Option.\n    pub fn flatten(option: Option<Option<T>>) -> Option<T> {\n        if option._is_some {\n            option._value\n        } else {\n            Option::none()\n        }\n    }\n}\n\nimpl<T> Default for Option<T> {\n    fn default() -> Self {\n        Option::none()\n    }\n}\n\nimpl<T> Eq for Option<T>\nwhere\n    T: Eq,\n{\n    fn eq(self, other: Self) -> bool {\n        if self._is_some == other._is_some {\n            if self._is_some {\n                self._value == other._value\n            } else {\n                true\n            }\n        } else {\n            false\n        }\n    }\n}\n\nimpl<T> Hash for Option<T>\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self._is_some.hash(state);\n        if self._is_some {\n            self._value.hash(state);\n        }\n    }\n}\n\n// For this impl we're declaring Option::none < Option::some\nimpl<T> Ord for Option<T>\nwhere\n    T: Ord,\n{\n    fn cmp(self, other: Self) -> Ordering {\n        if self._is_some {\n            if other._is_some {\n                self._value.cmp(other._value)\n            } else {\n                Ordering::greater()\n            }\n        } else if other._is_some {\n            Ordering::less()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n"},"43":{"path":"std/panic.nr","source":"pub fn panic<T, U, let N: u32>(message: fmtstr<N, T>) -> U {\n    assert(false, message);\n    crate::mem::zeroed()\n}\n"},"52":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/capsules/mod.nr","source":"use crate::oracle::capsules;\nuse protocol_types::{address::AztecAddress, traits::{Deserialize, Serialize}};\n\n/// A dynamically sized array backed by PXE's non-volatile database (called capsules). Values are persisted until\n/// deleted, so they can be e.g. stored during simulation of a transaction and later retrieved during witness\n/// generation. All values are scoped per contract address, so external contracts cannot access them.\npub struct CapsuleArray<T> {\n    contract_address: AztecAddress,\n    /// The base slot is where the array length is stored in capsules. Array elements are stored in consecutive slots\n    /// after the base slot. For example, with base slot 5: the length is at slot 5, the first element (index 0) is at\n    /// slot 6, the second element (index 1) is at slot 7, and so on.\n    base_slot: Field,\n}\n\nimpl<T> CapsuleArray<T> {\n    /// Returns a CapsuleArray connected to a contract's capsules at a base slot. Array elements are stored in\n    /// contiguous slots following the base slot, so there should be sufficient space between array base slots to\n    /// accommodate elements. A reasonable strategy is to make the base slot a hash of a unique value.\n    pub unconstrained fn at(contract_address: AztecAddress, base_slot: Field) -> Self {\n        Self { contract_address, base_slot }\n    }\n\n    /// Returns the number of elements stored in the array.\n    pub unconstrained fn len(self) -> u32 {\n        // An uninitialized array defaults to a length of 0.\n        capsules::load(self.contract_address, self.base_slot).unwrap_or(0) as u32\n    }\n\n    /// Stores a value at the end of the array.\n    pub unconstrained fn push<let N: u32>(self, value: T)\n    where\n        T: Serialize<N>,\n    {\n        let current_length = self.len();\n\n        // The slot corresponding to the index `current_length` is the first slot immediately after the end of the\n        // array, which is where we want to place the new value.\n        capsules::store(self.contract_address, self.slot_at(current_length), value);\n\n        // Then we simply update the length.\n        let new_length = current_length + 1;\n        capsules::store(self.contract_address, self.base_slot, new_length);\n    }\n\n    /// Retrieves the value stored in the array at `index`. Throws if the index is out of bounds.\n    pub unconstrained fn get<let N: u32>(self, index: u32) -> T\n    where\n        T: Deserialize<N>,\n    {\n        assert(index < self.len(), \"Attempted to read past the length of a CapsuleArray\");\n\n        capsules::load(self.contract_address, self.slot_at(index)).unwrap()\n    }\n\n    /// Deletes the value stored in the array at `index`. Throws if the index is out of bounds.\n    pub unconstrained fn remove(self, index: u32) {\n        let current_length = self.len();\n        assert(index < current_length, \"Attempted to delete past the length of a CapsuleArray\");\n\n        // In order to be able to remove elements at arbitrary indices, we need to shift the entire contents of the\n        // array past the removed element one slot backward so that we don't end up with a gap and preserve the\n        // contiguous slots. We can skip this when deleting the last element however.\n        if index != current_length - 1 {\n            // The source and destination regions overlap, but `copy` supports this.\n            capsules::copy(\n                self.contract_address,\n                self.slot_at(index + 1),\n                self.slot_at(index),\n                current_length - index - 1,\n            );\n        }\n\n        // We can now delete the last element (which has either been copied to the slot immediately before it, or was\n        // the element we meant to delete in the first place) and update the length.\n        capsules::delete(self.contract_address, self.slot_at(current_length - 1));\n        capsules::store(self.contract_address, self.base_slot, current_length - 1);\n    }\n\n    /// Iterates over the entire array, calling the callback with all values and their array index. The order in which\n    /// values are processed is arbitrary.\n    ///\n    /// It is safe to delete the current element (and only the current element) from inside the callback via `remove`:\n    /// ```noir\n    /// array.for_each(|index, value| {\n    ///   if some_condition(value) {\n    ///     array.remove(index); // safe only for this index\n    ///   }\n    /// }\n    /// ```\n    ///\n    /// If all elements in the array need to iterated over and then removed, then using `for_each` results in optimal\n    /// efficiency.\n    ///\n    /// It is **not** safe to push new elements into the array from inside the callback.\n    pub unconstrained fn for_each<Env, let N: u32>(self, f: unconstrained fn[Env](u32, T) -> ())\n    where\n        T: Deserialize<N>,\n    {\n        // Iterating over all elements is simple, but we want to do it in such a way that a) deleting the current\n        // element is safe to do, and b) deleting *all* elements is optimally efficient. This is because CapsuleArrays\n        // are typically used to hold pending tasks, so iterating them while clearing completed tasks (sometimes\n        // unconditionally, resulting in a full clear) is a very common access pattern.\n        //\n        // The way we achieve this is by iterating backwards: each element can always be deleted since it won't change\n        // any preceding (lower) indices, and if every element is deleted then every element will (in turn) be the last\n        // element. This results in an optimal full clear since `remove` will be able to skip the `capsules::copy` call\n        // to shift any elements past the deleted one (because there will be none).\n        let mut i = self.len();\n        while i > 0 {\n            i -= 1;\n            f(i, self.get(i));\n        }\n    }\n\n    unconstrained fn slot_at(self, index: u32) -> Field {\n        // Elements are stored immediately after the base slot, so we add 1 to it to compute the slot for the first\n        // element.\n        self.base_slot + 1 + index as Field\n    }\n}\n\nmod test {\n    use crate::test::helpers::test_environment::TestEnvironment;\n    use super::CapsuleArray;\n    use protocol_types::address::AztecAddress;\n\n    global SLOT: Field = 1230;\n\n    unconstrained fn setup() -> AztecAddress {\n        TestEnvironment::new().utility().this_address()\n    }\n\n    #[test]\n    unconstrained fn empty_array() {\n        let contract_address = setup();\n\n        let array: CapsuleArray<Field> = CapsuleArray::at(contract_address, SLOT);\n        assert_eq(array.len(), 0);\n    }\n\n    #[test(should_fail_with = \"Attempted to read past the length of a CapsuleArray\")]\n    unconstrained fn empty_array_read() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n        let _: Field = array.get(0);\n    }\n\n    #[test]\n    unconstrained fn array_push() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n        array.push(5);\n\n        assert_eq(array.len(), 1);\n        assert_eq(array.get(0), 5);\n    }\n\n    #[test(should_fail_with = \"Attempted to read past the length of a CapsuleArray\")]\n    unconstrained fn read_past_len() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n        array.push(5);\n\n        let _ = array.get(1);\n    }\n\n    #[test]\n    unconstrained fn array_remove_last() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(5);\n        array.remove(0);\n\n        assert_eq(array.len(), 0);\n    }\n\n    #[test]\n    unconstrained fn array_remove_some() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(7);\n        array.push(8);\n        array.push(9);\n\n        assert_eq(array.len(), 3);\n        assert_eq(array.get(0), 7);\n        assert_eq(array.get(1), 8);\n        assert_eq(array.get(2), 9);\n\n        array.remove(1);\n\n        assert_eq(array.len(), 2);\n        assert_eq(array.get(0), 7);\n        assert_eq(array.get(1), 9);\n    }\n\n    #[test]\n    unconstrained fn array_remove_all() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(7);\n        array.push(8);\n        array.push(9);\n\n        array.remove(1);\n        array.remove(1);\n        array.remove(0);\n\n        assert_eq(array.len(), 0);\n    }\n\n    #[test]\n    unconstrained fn for_each_called_with_all_elements() {\n        let contract_address = setup();\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(4);\n        array.push(5);\n        array.push(6);\n\n        // We store all values that we were called with and check that all (value, index) tuples are present. Note that\n        // we do not care about the order in which each tuple was passed to the closure.\n        let called_with = &mut BoundedVec::<(u32, Field), 3>::new();\n        array.for_each(|index, value| { called_with.push((index, value)); });\n\n        assert_eq(called_with.len(), 3);\n        assert(called_with.any(|(index, value)| (index == 0) & (value == 4)));\n        assert(called_with.any(|(index, value)| (index == 1) & (value == 5)));\n        assert(called_with.any(|(index, value)| (index == 2) & (value == 6)));\n    }\n\n    #[test]\n    unconstrained fn for_each_remove_some() {\n        let contract_address = setup();\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(4);\n        array.push(5);\n        array.push(6);\n\n        array.for_each(|index, _| {\n            if index == 1 {\n                array.remove(index);\n            }\n        });\n\n        assert_eq(array.len(), 2);\n        assert_eq(array.get(0), 4);\n        assert_eq(array.get(1), 6);\n    }\n\n    #[test]\n    unconstrained fn for_each_remove_all() {\n        let contract_address = setup();\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(4);\n        array.push(5);\n        array.push(6);\n\n        array.for_each(|index, _| { array.remove(index); });\n\n        assert_eq(array.len(), 0);\n    }\n\n    // TODO: uncomment this test once OracleMock::count is implemented in the stdlib.\n    // #[test]\n    // unconstrained fn for_each_remove_all_no_copy() {\n    //     let contract_address = setup();\n    //     let array = CapsuleArray::at(contract_address, SLOT);\n\n    //     array.push(4);\n    //     array.push(5);\n    //     array.push(6);\n\n    //     // We test that the copyCapsule was never called, which is the expensive operation we want to avoid.\n    //     let mock = OracleMock::mock(\"copyCapsule\");\n\n    //     array.for_each(|index, _| {\n    //         array.remove(index);\n    //     });\n\n    //     assert_eq(mock.count(), 0);\n    // }\n}\n"},"6":{"path":"std/collections/bounded_vec.nr","source":"use crate::{cmp::Eq, convert::From, runtime::is_unconstrained, static_assert};\n\n/// A `BoundedVec<T, MaxLen>` is a growable storage similar to a `Vec<T>` except that it\n/// is bounded with a maximum possible length. Unlike `Vec`, `BoundedVec` is not implemented\n/// via slices and thus is not subject to the same restrictions slices are (notably, nested\n/// slices - and thus nested vectors as well - are disallowed).\n///\n/// Since a BoundedVec is backed by a normal array under the hood, growing the BoundedVec by\n/// pushing an additional element is also more efficient - the length only needs to be increased\n/// by one.\n///\n/// For these reasons `BoundedVec<T, N>` should generally be preferred over `Vec<T>` when there\n/// is a reasonable maximum bound that can be placed on the vector.\n///\n/// Example:\n///\n/// ```noir\n/// let mut vector: BoundedVec<Field, 10> = BoundedVec::new();\n/// for i in 0..5 {\n///     vector.push(i);\n/// }\n/// assert(vector.len() == 5);\n/// assert(vector.max_len() == 10);\n/// ```\npub struct BoundedVec<T, let MaxLen: u32> {\n    storage: [T; MaxLen],\n    len: u32,\n}\n\nimpl<T, let MaxLen: u32> BoundedVec<T, MaxLen> {\n    /// Creates a new, empty vector of length zero.\n    ///\n    /// Since this container is backed by an array internally, it still needs an initial value\n    /// to give each element. To resolve this, each element is zeroed internally. This value\n    /// is guaranteed to be inaccessible unless `get_unchecked` is used.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let empty_vector: BoundedVec<Field, 10> = BoundedVec::new();\n    /// assert(empty_vector.len() == 0);\n    /// ```\n    ///\n    /// Note that whenever calling `new` the maximum length of the vector should always be specified\n    /// via a type signature:\n    ///\n    /// ```noir\n    /// fn good() -> BoundedVec<Field, 10> {\n    ///     // Ok! MaxLen is specified with a type annotation\n    ///     let v1: BoundedVec<Field, 3> = BoundedVec::new();\n    ///     let v2 = BoundedVec::new();\n    ///\n    ///     // Ok! MaxLen is known from the type of `good`'s return value\n    ///     v2\n    /// }\n    ///\n    /// fn bad() {\n    ///     // Error: Type annotation needed\n    ///     // The compiler can't infer `MaxLen` from the following code:\n    ///     let mut v3 = BoundedVec::new();\n    ///     v3.push(5);\n    /// }\n    /// ```\n    ///\n    /// This defaulting of `MaxLen` (and numeric generics in general) to zero may change in future noir versions\n    /// but for now make sure to use type annotations when using bounded vectors. Otherwise, you will receive a\n    /// constraint failure at runtime when the vec is pushed to.\n    pub fn new() -> Self {\n        let zeroed = crate::mem::zeroed();\n        BoundedVec { storage: [zeroed; MaxLen], len: 0 }\n    }\n\n    /// Retrieves an element from the vector at the given index, starting from zero.\n    ///\n    /// If the given index is equal to or greater than the length of the vector, this\n    /// will issue a constraint failure.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn foo<let N: u32>(v: BoundedVec<u32, N>) {\n    ///     let first = v.get(0);\n    ///     let last = v.get(v.len() - 1);\n    ///     assert(first != last);\n    /// }\n    /// ```\n    pub fn get(self, index: u32) -> T {\n        assert(index < self.len, \"Attempted to read past end of BoundedVec\");\n        self.get_unchecked(index)\n    }\n\n    /// Retrieves an element from the vector at the given index, starting from zero, without\n    /// performing a bounds check.\n    ///\n    /// Since this function does not perform a bounds check on length before accessing the element,\n    /// it is unsafe! Use at your own risk!\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn sum_of_first_three<let N: u32>(v: BoundedVec<u32, N>) -> u32 {\n    ///     // Always ensure the length is larger than the largest\n    ///     // index passed to get_unchecked\n    ///     assert(v.len() > 2);\n    ///     let first = v.get_unchecked(0);\n    ///     let second = v.get_unchecked(1);\n    ///     let third = v.get_unchecked(2);\n    ///     first + second + third\n    /// }\n    /// ```\n    pub fn get_unchecked(self, index: u32) -> T {\n        self.storage[index]\n    }\n\n    /// Writes an element to the vector at the given index, starting from zero.\n    ///\n    /// If the given index is equal to or greater than the length of the vector, this will issue a constraint failure.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn foo<let N: u32>(v: BoundedVec<u32, N>) {\n    ///     let first = v.get(0);\n    ///     assert(first != 42);\n    ///     v.set(0, 42);\n    ///     let new_first = v.get(0);\n    ///     assert(new_first == 42);\n    /// }\n    /// ```\n    pub fn set(&mut self, index: u32, value: T) {\n        assert(index < self.len, \"Attempted to write past end of BoundedVec\");\n        self.set_unchecked(index, value)\n    }\n\n    /// Writes an element to the vector at the given index, starting from zero, without performing a bounds check.\n    ///\n    /// Since this function does not perform a bounds check on length before accessing the element, it is unsafe! Use at your own risk!\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn set_unchecked_example() {\n    ///     let mut vec: BoundedVec<u32, 5> = BoundedVec::new();\n    ///     vec.extend_from_array([1, 2]);\n    ///\n    ///     // Here we're safely writing within the valid range of `vec`\n    ///     // `vec` now has the value [42, 2]\n    ///     vec.set_unchecked(0, 42);\n    ///\n    ///     // We can then safely read this value back out of `vec`.\n    ///     // Notice that we use the checked version of `get` which would prevent reading unsafe values.\n    ///     assert_eq(vec.get(0), 42);\n    ///\n    ///     // We've now written past the end of `vec`.\n    ///     // As this index is still within the maximum potential length of `v`,\n    ///     // it won't cause a constraint failure.\n    ///     vec.set_unchecked(2, 42);\n    ///     println(vec);\n    ///\n    ///     // This will write past the end of the maximum potential length of `vec`,\n    ///     // it will then trigger a constraint failure.\n    ///     vec.set_unchecked(5, 42);\n    ///     println(vec);\n    /// }\n    /// ```\n    pub fn set_unchecked(&mut self, index: u32, value: T) {\n        self.storage[index] = value;\n    }\n\n    /// Pushes an element to the end of the vector. This increases the length\n    /// of the vector by one.\n    ///\n    /// Panics if the new length of the vector will be greater than the max length.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 2> = BoundedVec::new();\n    ///\n    /// v.push(1);\n    /// v.push(2);\n    ///\n    /// // Panics with failed assertion \"push out of bounds\"\n    /// v.push(3);\n    /// ```\n    pub fn push(&mut self, elem: T) {\n        assert(self.len < MaxLen, \"push out of bounds\");\n\n        self.storage[self.len] = elem;\n        self.len += 1;\n    }\n\n    /// Returns the current length of this vector\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 4> = BoundedVec::new();\n    /// assert(v.len() == 0);\n    ///\n    /// v.push(100);\n    /// assert(v.len() == 1);\n    ///\n    /// v.push(200);\n    /// v.push(300);\n    /// v.push(400);\n    /// assert(v.len() == 4);\n    ///\n    /// let _ = v.pop();\n    /// let _ = v.pop();\n    /// assert(v.len() == 2);\n    /// ```\n    pub fn len(self) -> u32 {\n        self.len\n    }\n\n    /// Returns the maximum length of this vector. This is always\n    /// equal to the `MaxLen` parameter this vector was initialized with.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 5> = BoundedVec::new();\n    ///\n    /// assert(v.max_len() == 5);\n    /// v.push(10);\n    /// assert(v.max_len() == 5);\n    /// ```\n    pub fn max_len(_self: BoundedVec<T, MaxLen>) -> u32 {\n        MaxLen\n    }\n\n    /// Returns the internal array within this vector.\n    ///\n    /// Since arrays in Noir are immutable, mutating the returned storage array will not mutate\n    /// the storage held internally by this vector.\n    ///\n    /// Note that uninitialized elements may be zeroed out!\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 5> = BoundedVec::new();\n    ///\n    /// assert(v.storage() == [0, 0, 0, 0, 0]);\n    ///\n    /// v.push(57);\n    /// assert(v.storage() == [57, 0, 0, 0, 0]);\n    /// ```\n    pub fn storage(self) -> [T; MaxLen] {\n        self.storage\n    }\n\n    /// Pushes each element from the given array to this vector.\n    ///\n    /// Panics if pushing each element would cause the length of this vector\n    /// to exceed the maximum length.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut vec: BoundedVec<Field, 3> = BoundedVec::new();\n    /// vec.extend_from_array([2, 4]);\n    ///\n    /// assert(vec.len == 2);\n    /// assert(vec.get(0) == 2);\n    /// assert(vec.get(1) == 4);\n    /// ```\n    pub fn extend_from_array<let Len: u32>(&mut self, array: [T; Len]) {\n        let new_len = self.len + array.len();\n        assert(new_len <= MaxLen, \"extend_from_array out of bounds\");\n        for i in 0..array.len() {\n            self.storage[self.len + i] = array[i];\n        }\n        self.len = new_len;\n    }\n\n    /// Pushes each element from the given slice to this vector.\n    ///\n    /// Panics if pushing each element would cause the length of this vector\n    /// to exceed the maximum length.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut vec: BoundedVec<Field, 3> = BoundedVec::new();\n    /// vec.extend_from_slice(&[2, 4]);\n    ///\n    /// assert(vec.len == 2);\n    /// assert(vec.get(0) == 2);\n    /// assert(vec.get(1) == 4);\n    /// ```\n    pub fn extend_from_slice(&mut self, slice: [T]) {\n        let new_len = self.len + slice.len();\n        assert(new_len <= MaxLen, \"extend_from_slice out of bounds\");\n        for i in 0..slice.len() {\n            self.storage[self.len + i] = slice[i];\n        }\n        self.len = new_len;\n    }\n\n    /// Pushes each element from the other vector to this vector. The length of\n    /// the other vector is left unchanged.\n    ///\n    /// Panics if pushing each element would cause the length of this vector\n    /// to exceed the maximum length.\n    ///\n    /// ```noir\n    /// let mut v1: BoundedVec<Field, 5> = BoundedVec::new();\n    /// let mut v2: BoundedVec<Field, 7> = BoundedVec::new();\n    ///\n    /// v2.extend_from_array([1, 2, 3]);\n    /// v1.extend_from_bounded_vec(v2);\n    ///\n    /// assert(v1.storage() == [1, 2, 3, 0, 0]);\n    /// assert(v2.storage() == [1, 2, 3, 0, 0, 0, 0]);\n    /// ```\n    pub fn extend_from_bounded_vec<let Len: u32>(&mut self, vec: BoundedVec<T, Len>) {\n        let append_len = vec.len();\n        let new_len = self.len + append_len;\n        assert(new_len <= MaxLen, \"extend_from_bounded_vec out of bounds\");\n\n        if is_unconstrained() {\n            for i in 0..append_len {\n                self.storage[self.len + i] = vec.get_unchecked(i);\n            }\n        } else {\n            let mut exceeded_len = false;\n            for i in 0..Len {\n                exceeded_len |= i == append_len;\n                if !exceeded_len {\n                    self.storage[self.len + i] = vec.get_unchecked(i);\n                }\n            }\n        }\n        self.len = new_len;\n    }\n\n    /// Creates a new vector, populating it with values derived from an array input.\n    /// The maximum length of the vector is determined based on the type signature.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let bounded_vec: BoundedVec<Field, 10> = BoundedVec::from_array([1, 2, 3])\n    /// ```\n    pub fn from_array<let Len: u32>(array: [T; Len]) -> Self {\n        static_assert(Len <= MaxLen, \"from array out of bounds\");\n        let mut vec: BoundedVec<T, MaxLen> = BoundedVec::new();\n        vec.extend_from_array(array);\n        vec\n    }\n\n    /// Pops the element at the end of the vector. This will decrease the length\n    /// of the vector by one.\n    ///\n    /// Panics if the vector is empty.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 2> = BoundedVec::new();\n    /// v.push(1);\n    /// v.push(2);\n    ///\n    /// let two = v.pop();\n    /// let one = v.pop();\n    ///\n    /// assert(two == 2);\n    /// assert(one == 1);\n    ///\n    /// // error: cannot pop from an empty vector\n    /// let _ = v.pop();\n    /// ```\n    pub fn pop(&mut self) -> T {\n        assert(self.len > 0);\n        self.len -= 1;\n\n        let elem = self.storage[self.len];\n        self.storage[self.len] = crate::mem::zeroed();\n        elem\n    }\n\n    /// Returns true if the given predicate returns true for any element\n    /// in this vector.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<u32, 3> = BoundedVec::new();\n    /// v.extend_from_array([2, 4, 6]);\n    ///\n    /// let all_even = !v.any(|elem: u32| elem % 2 != 0);\n    /// assert(all_even);\n    /// ```\n    pub fn any<Env>(self, predicate: fn[Env](T) -> bool) -> bool {\n        let mut ret = false;\n        if is_unconstrained() {\n            for i in 0..self.len {\n                ret |= predicate(self.storage[i]);\n            }\n        } else {\n            let mut ret = false;\n            let mut exceeded_len = false;\n            for i in 0..MaxLen {\n                exceeded_len |= i == self.len;\n                if !exceeded_len {\n                    ret |= predicate(self.storage[i]);\n                }\n            }\n        }\n        ret\n    }\n\n    /// Creates a new vector of equal size by calling a closure on each element in this vector.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n    /// let result = vec.map(|value| value * 2);\n    ///\n    /// let expected = BoundedVec::from_array([2, 4, 6, 8]);\n    /// assert_eq(result, expected);\n    /// ```\n    pub fn map<U, Env>(self, f: fn[Env](T) -> U) -> BoundedVec<U, MaxLen> {\n        let mut ret = BoundedVec::new();\n        ret.len = self.len();\n\n        if is_unconstrained() {\n            for i in 0..self.len() {\n                ret.storage[i] = f(self.get_unchecked(i));\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i < self.len() {\n                    ret.storage[i] = f(self.get_unchecked(i));\n                }\n            }\n        }\n\n        ret\n    }\n\n    /// Creates a new vector of equal size by calling a closure on each element\n    /// in this vector, along with its index.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n    /// let result = vec.mapi(|i, value| i + value * 2);\n    ///\n    /// let expected = BoundedVec::from_array([2, 5, 8, 11]);\n    /// assert_eq(result, expected);\n    /// ```\n    pub fn mapi<U, Env>(self, f: fn[Env](u32, T) -> U) -> BoundedVec<U, MaxLen> {\n        let mut ret = BoundedVec::new();\n        ret.len = self.len();\n\n        if is_unconstrained() {\n            for i in 0..self.len() {\n                ret.storage[i] = f(i, self.get_unchecked(i));\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i < self.len() {\n                    ret.storage[i] = f(i, self.get_unchecked(i));\n                }\n            }\n        }\n\n        ret\n    }\n\n    /// Calls a closure on each element in this vector.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n    /// let mut result = BoundedVec::<u32, 4>::new();\n    /// vec.for_each(|value| result.push(value * 2));\n    ///\n    /// let expected = BoundedVec::from_array([2, 4, 6, 8]);\n    /// assert_eq(result, expected);\n    /// ```\n    pub fn for_each<Env>(self, f: fn[Env](T) -> ()) {\n        if is_unconstrained() {\n            for i in 0..self.len() {\n                f(self.get_unchecked(i));\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i < self.len() {\n                    f(self.get_unchecked(i));\n                }\n            }\n        }\n    }\n\n    /// Calls a closure on each element in this vector, along with its index.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n    /// let mut result = BoundedVec::<u32, 4>::new();\n    /// vec.for_eachi(|i, value| result.push(i + value * 2));\n    ///\n    /// let expected = BoundedVec::from_array([2, 5, 8, 11]);\n    /// assert_eq(result, expected);\n    /// ```\n    pub fn for_eachi<Env>(self, f: fn[Env](u32, T) -> ()) {\n        if is_unconstrained() {\n            for i in 0..self.len() {\n                f(i, self.get_unchecked(i));\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i < self.len() {\n                    f(i, self.get_unchecked(i));\n                }\n            }\n        }\n    }\n\n    /// Creates a new BoundedVec from the given array and length.\n    /// The given length must be less than or equal to the length of the array.\n    ///\n    /// This function will zero out any elements at or past index `len` of `array`.\n    /// This incurs an extra runtime cost of O(MaxLen). If you are sure your array is\n    /// zeroed after that index, you can use `from_parts_unchecked` to remove the extra loop.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_parts([1, 2, 3, 0], 3);\n    /// assert_eq(vec.len(), 3);\n    /// ```\n    pub fn from_parts(mut array: [T; MaxLen], len: u32) -> Self {\n        assert(len <= MaxLen);\n        let zeroed = crate::mem::zeroed();\n\n        if is_unconstrained() {\n            for i in len..MaxLen {\n                array[i] = zeroed;\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i >= len {\n                    array[i] = zeroed;\n                }\n            }\n        }\n\n        BoundedVec { storage: array, len }\n    }\n\n    /// Creates a new BoundedVec from the given array and length.\n    /// The given length must be less than or equal to the length of the array.\n    ///\n    /// This function is unsafe because it expects all elements past the `len` index\n    /// of `array` to be zeroed, but does not check for this internally. Use `from_parts`\n    /// for a safe version of this function which does zero out any indices past the\n    /// given length. Invalidating this assumption can notably cause `BoundedVec::eq`\n    /// to give incorrect results since it will check even elements past `len`.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 0], 3);\n    /// assert_eq(vec.len(), 3);\n    ///\n    /// // invalid use!\n    /// let vec1: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 1], 3);\n    /// let vec2: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 2], 3);\n    ///\n    /// // both vecs have length 3 so we'd expect them to be equal, but this\n    /// // fails because elements past the length are still checked in eq\n    /// assert_eq(vec1, vec2); // fails\n    /// ```\n    pub fn from_parts_unchecked(array: [T; MaxLen], len: u32) -> Self {\n        assert(len <= MaxLen);\n        BoundedVec { storage: array, len }\n    }\n}\n\nimpl<T, let MaxLen: u32> Eq for BoundedVec<T, MaxLen>\nwhere\n    T: Eq,\n{\n    fn eq(self, other: BoundedVec<T, MaxLen>) -> bool {\n        // TODO: https://github.com/noir-lang/noir/issues/4837\n        //\n        // We make the assumption that the user has used the proper interface for working with `BoundedVec`s\n        // rather than directly manipulating the internal fields as this can result in an inconsistent internal state.\n        if self.len == other.len {\n            self.storage == other.storage\n        } else {\n            false\n        }\n    }\n}\n\nimpl<T, let MaxLen: u32, let Len: u32> From<[T; Len]> for BoundedVec<T, MaxLen> {\n    fn from(array: [T; Len]) -> BoundedVec<T, MaxLen> {\n        BoundedVec::from_array(array)\n    }\n}\n\nmod bounded_vec_tests {\n\n    mod get {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test(should_fail_with = \"Attempted to read past end of BoundedVec\")]\n        fn panics_when_reading_elements_past_end_of_vec() {\n            let vec: BoundedVec<Field, 5> = BoundedVec::new();\n\n            crate::println(vec.get(0));\n        }\n    }\n\n    mod set {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn set_updates_values_properly() {\n            let mut vec = BoundedVec::from_array([0, 0, 0, 0, 0]);\n\n            vec.set(0, 42);\n            assert_eq(vec.storage, [42, 0, 0, 0, 0]);\n\n            vec.set(1, 43);\n            assert_eq(vec.storage, [42, 43, 0, 0, 0]);\n\n            vec.set(2, 44);\n            assert_eq(vec.storage, [42, 43, 44, 0, 0]);\n\n            vec.set(1, 10);\n            assert_eq(vec.storage, [42, 10, 44, 0, 0]);\n\n            vec.set(0, 0);\n            assert_eq(vec.storage, [0, 10, 44, 0, 0]);\n        }\n\n        #[test(should_fail_with = \"Attempted to write past end of BoundedVec\")]\n        fn panics_when_writing_elements_past_end_of_vec() {\n            let mut vec: BoundedVec<Field, 5> = BoundedVec::new();\n            vec.set(0, 42);\n\n            // Need to use println to avoid DIE removing the write operation.\n            crate::println(vec.get(0));\n        }\n    }\n\n    mod map {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn applies_function_correctly() {\n            // docs:start:bounded-vec-map-example\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = vec.map(|value| value * 2);\n            // docs:end:bounded-vec-map-example\n            let expected = BoundedVec::from_array([2, 4, 6, 8]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn applies_function_that_changes_return_type() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = vec.map(|value| (value * 2) as Field);\n            let expected: BoundedVec<Field, 4> = BoundedVec::from_array([2, 4, 6, 8]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn does_not_apply_function_past_len() {\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([0, 1]);\n            let result = vec.map(|value| if value == 0 { 5 } else { value });\n            let expected = BoundedVec::from_array([5, 1]);\n\n            assert_eq(result, expected);\n            assert_eq(result.get_unchecked(2), 0);\n        }\n    }\n\n    mod mapi {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn applies_function_correctly() {\n            // docs:start:bounded-vec-mapi-example\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = vec.mapi(|i, value| i + value * 2);\n            // docs:end:bounded-vec-mapi-example\n            let expected = BoundedVec::from_array([2, 5, 8, 11]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn applies_function_that_changes_return_type() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = vec.mapi(|i, value| (i + value * 2) as Field);\n            let expected: BoundedVec<Field, 4> = BoundedVec::from_array([2, 5, 8, 11]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn does_not_apply_function_past_len() {\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([0, 1]);\n            let result = vec.mapi(|_, value| if value == 0 { 5 } else { value });\n            let expected = BoundedVec::from_array([5, 1]);\n\n            assert_eq(result, expected);\n            assert_eq(result.get_unchecked(2), 0);\n        }\n    }\n\n    mod for_each {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        // map in terms of for_each\n        fn for_each_map<T, U, Env, let MaxLen: u32>(\n            input: BoundedVec<T, MaxLen>,\n            f: fn[Env](T) -> U,\n        ) -> BoundedVec<U, MaxLen> {\n            let mut output = BoundedVec::<U, MaxLen>::new();\n            let output_ref = &mut output;\n            input.for_each(|x| output_ref.push(f(x)));\n            output\n        }\n\n        #[test]\n        fn smoke_test() {\n            let mut acc = 0;\n            let acc_ref = &mut acc;\n            // docs:start:bounded-vec-for-each-example\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([1, 2, 3]);\n            vec.for_each(|value| { *acc_ref += value; });\n            // docs:end:bounded-vec-for-each-example\n            assert_eq(acc, 6);\n        }\n\n        #[test]\n        fn applies_function_correctly() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = for_each_map(vec, |value| value * 2);\n            let expected = BoundedVec::from_array([2, 4, 6, 8]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn applies_function_that_changes_return_type() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = for_each_map(vec, |value| (value * 2) as Field);\n            let expected: BoundedVec<Field, 4> = BoundedVec::from_array([2, 4, 6, 8]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn does_not_apply_function_past_len() {\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([0, 1]);\n            let result = for_each_map(vec, |value| if value == 0 { 5 } else { value });\n            let expected = BoundedVec::from_array([5, 1]);\n\n            assert_eq(result, expected);\n            assert_eq(result.get_unchecked(2), 0);\n        }\n    }\n\n    mod for_eachi {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        // mapi in terms of for_eachi\n        fn for_eachi_mapi<T, U, Env, let MaxLen: u32>(\n            input: BoundedVec<T, MaxLen>,\n            f: fn[Env](u32, T) -> U,\n        ) -> BoundedVec<U, MaxLen> {\n            let mut output = BoundedVec::<U, MaxLen>::new();\n            let output_ref = &mut output;\n            input.for_eachi(|i, x| output_ref.push(f(i, x)));\n            output\n        }\n\n        #[test]\n        fn smoke_test() {\n            let mut acc = 0;\n            let acc_ref = &mut acc;\n            // docs:start:bounded-vec-for-eachi-example\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([1, 2, 3]);\n            vec.for_eachi(|i, value| { *acc_ref += i * value; });\n            // docs:end:bounded-vec-for-eachi-example\n\n            // 0 * 1 + 1 * 2 + 2 * 3\n            assert_eq(acc, 8);\n        }\n\n        #[test]\n        fn applies_function_correctly() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = for_eachi_mapi(vec, |i, value| i + value * 2);\n            let expected = BoundedVec::from_array([2, 5, 8, 11]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn applies_function_that_changes_return_type() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = for_eachi_mapi(vec, |i, value| (i + value * 2) as Field);\n            let expected: BoundedVec<Field, 4> = BoundedVec::from_array([2, 5, 8, 11]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn does_not_apply_function_past_len() {\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([0, 1]);\n            let result = for_eachi_mapi(vec, |_, value| if value == 0 { 5 } else { value });\n            let expected = BoundedVec::from_array([5, 1]);\n\n            assert_eq(result, expected);\n            assert_eq(result.get_unchecked(2), 0);\n        }\n    }\n\n    mod from_array {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn empty() {\n            let empty_array: [Field; 0] = [];\n            let bounded_vec = BoundedVec::from_array([]);\n\n            assert_eq(bounded_vec.max_len(), 0);\n            assert_eq(bounded_vec.len(), 0);\n            assert_eq(bounded_vec.storage(), empty_array);\n        }\n\n        #[test]\n        fn equal_len() {\n            let array = [1, 2, 3];\n            let bounded_vec = BoundedVec::from_array(array);\n\n            assert_eq(bounded_vec.max_len(), 3);\n            assert_eq(bounded_vec.len(), 3);\n            assert_eq(bounded_vec.storage(), array);\n        }\n\n        #[test]\n        fn max_len_greater_then_array_len() {\n            let array = [1, 2, 3];\n            let bounded_vec: BoundedVec<Field, 10> = BoundedVec::from_array(array);\n\n            assert_eq(bounded_vec.max_len(), 10);\n            assert_eq(bounded_vec.len(), 3);\n            assert_eq(bounded_vec.get(0), 1);\n            assert_eq(bounded_vec.get(1), 2);\n            assert_eq(bounded_vec.get(2), 3);\n        }\n\n        #[test(should_fail_with = \"from array out of bounds\")]\n        fn max_len_lower_then_array_len() {\n            let _: BoundedVec<Field, 2> = BoundedVec::from_array([0; 3]);\n        }\n    }\n\n    mod trait_from {\n        use crate::collections::bounded_vec::BoundedVec;\n        use crate::convert::From;\n\n        #[test]\n        fn simple() {\n            let array = [1, 2];\n            let bounded_vec: BoundedVec<Field, 10> = BoundedVec::from(array);\n\n            assert_eq(bounded_vec.max_len(), 10);\n            assert_eq(bounded_vec.len(), 2);\n            assert_eq(bounded_vec.get(0), 1);\n            assert_eq(bounded_vec.get(1), 2);\n        }\n    }\n\n    mod trait_eq {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn empty_equality() {\n            let mut bounded_vec1: BoundedVec<Field, 3> = BoundedVec::new();\n            let mut bounded_vec2: BoundedVec<Field, 3> = BoundedVec::new();\n\n            assert_eq(bounded_vec1, bounded_vec2);\n        }\n\n        #[test]\n        fn inequality() {\n            let mut bounded_vec1: BoundedVec<Field, 3> = BoundedVec::new();\n            let mut bounded_vec2: BoundedVec<Field, 3> = BoundedVec::new();\n            bounded_vec1.push(1);\n            bounded_vec2.push(2);\n\n            assert(bounded_vec1 != bounded_vec2);\n        }\n    }\n\n    mod from_parts {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn from_parts() {\n            // docs:start:from-parts\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_parts([1, 2, 3, 0], 3);\n            assert_eq(vec.len(), 3);\n\n            // Any elements past the given length are zeroed out, so these\n            // two BoundedVecs will be completely equal\n            let vec1: BoundedVec<u32, 4> = BoundedVec::from_parts([1, 2, 3, 1], 3);\n            let vec2: BoundedVec<u32, 4> = BoundedVec::from_parts([1, 2, 3, 2], 3);\n            assert_eq(vec1, vec2);\n            // docs:end:from-parts\n        }\n\n        #[test]\n        fn from_parts_unchecked() {\n            // docs:start:from-parts-unchecked\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 0], 3);\n            assert_eq(vec.len(), 3);\n\n            // invalid use!\n            let vec1: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 1], 3);\n            let vec2: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 2], 3);\n\n            // both vecs have length 3 so we'd expect them to be equal, but this\n            // fails because elements past the length are still checked in eq\n            assert(vec1 != vec2);\n            // docs:end:from-parts-unchecked\n        }\n    }\n}\n"},"61":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/context/public_context.nr","source":"use crate::context::gas::GasOpts;\nuse crate::hash::{\n    compute_l1_to_l2_message_hash, compute_l1_to_l2_message_nullifier, compute_secret_hash,\n};\nuse dep::protocol_types::abis::function_selector::FunctionSelector;\nuse dep::protocol_types::address::{AztecAddress, EthAddress};\nuse dep::protocol_types::constants::MAX_FIELD_VALUE;\nuse dep::protocol_types::traits::{Empty, FromField, Packable, Serialize, ToField};\n\npub struct PublicContext {\n    pub args_hash: Option<Field>,\n    pub compute_args_hash: fn() -> Field,\n}\n\nimpl PublicContext {\n    pub fn new(compute_args_hash: fn() -> Field) -> Self {\n        PublicContext { args_hash: Option::none(), compute_args_hash }\n    }\n\n    pub fn emit_public_log<T, let N: u32>(_self: &mut Self, log: T)\n    where\n        T: Serialize<N>,\n    {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_public_log(Serialize::serialize(log).as_slice()) };\n    }\n\n    pub fn note_hash_exists(_self: Self, note_hash: Field, leaf_index: Field) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { note_hash_exists(note_hash, leaf_index) } == 1\n    }\n\n    pub fn l1_to_l2_msg_exists(_self: Self, msg_hash: Field, msg_leaf_index: Field) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { l1_to_l2_msg_exists(msg_hash, msg_leaf_index) } == 1\n    }\n\n    pub fn nullifier_exists(_self: Self, unsiloed_nullifier: Field, address: AztecAddress) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { nullifier_exists(unsiloed_nullifier, address.to_field()) } == 1\n    }\n\n    pub fn consume_l1_to_l2_message(\n        &mut self,\n        content: Field,\n        secret: Field,\n        sender: EthAddress,\n        leaf_index: Field,\n    ) {\n        let secret_hash = compute_secret_hash(secret);\n        let message_hash = compute_l1_to_l2_message_hash(\n            sender,\n            self.chain_id(),\n            /*recipient=*/\n            self.this_address(),\n            self.version(),\n            content,\n            secret_hash,\n            leaf_index,\n        );\n        let nullifier = compute_l1_to_l2_message_nullifier(message_hash, secret);\n\n        assert(\n            !self.nullifier_exists(nullifier, self.this_address()),\n            \"L1-to-L2 message is already nullified\",\n        );\n        assert(\n            self.l1_to_l2_msg_exists(message_hash, leaf_index),\n            \"Tried to consume nonexistent L1-to-L2 message\",\n        );\n\n        self.push_nullifier(nullifier);\n    }\n\n    pub fn message_portal(_self: &mut Self, recipient: EthAddress, content: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { send_l2_to_l1_msg(recipient, content) };\n    }\n\n    pub unconstrained fn call_public_function(\n        _self: &mut Self,\n        contract_address: AztecAddress,\n        function_selector: FunctionSelector,\n        args: [Field],\n        gas_opts: GasOpts,\n    ) -> [Field] {\n        let calldata = args.push_front(function_selector.to_field());\n\n        call(\n            gas_opts.l2_gas.unwrap_or(MAX_FIELD_VALUE),\n            gas_opts.da_gas.unwrap_or(MAX_FIELD_VALUE),\n            contract_address,\n            calldata,\n        );\n        // Use success_copy to determine whether the call succeeded\n        let success = success_copy();\n\n        let result_data = returndata_copy(0, returndata_size());\n        if !success {\n            // Rethrow the revert data.\n            avm_revert(result_data);\n        }\n        result_data\n    }\n\n    pub unconstrained fn static_call_public_function(\n        _self: &mut Self,\n        contract_address: AztecAddress,\n        function_selector: FunctionSelector,\n        args: [Field],\n        gas_opts: GasOpts,\n    ) -> [Field] {\n        let calldata = args.push_front(function_selector.to_field());\n\n        call_static(\n            gas_opts.l2_gas.unwrap_or(MAX_FIELD_VALUE),\n            gas_opts.da_gas.unwrap_or(MAX_FIELD_VALUE),\n            contract_address,\n            calldata,\n        );\n        // Use success_copy to determine whether the call succeeded\n        let success = success_copy();\n\n        let result_data = returndata_copy(0, returndata_size());\n        if !success {\n            // Rethrow the revert data.\n            avm_revert(result_data);\n        }\n        result_data\n    }\n\n    pub fn push_note_hash(_self: &mut Self, note_hash: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_note_hash(note_hash) };\n    }\n    pub fn push_nullifier(_self: &mut Self, nullifier: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_nullifier(nullifier) };\n    }\n\n    pub fn this_address(_self: Self) -> AztecAddress {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            address()\n        }\n    }\n    pub fn msg_sender(_self: Self) -> AztecAddress {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            sender()\n        }\n    }\n    pub fn selector(_self: Self) -> FunctionSelector {\n        // The selector is the first element of the calldata when calling a public function through dispatch.\n        // Safety: AVM opcodes are constrained by the AVM itself\n        let raw_selector: [Field; 1] = unsafe { calldata_copy(0, 1) };\n        FunctionSelector::from_field(raw_selector[0])\n    }\n    pub fn get_args_hash(mut self) -> Field {\n        if !self.args_hash.is_some() {\n            self.args_hash = Option::some((self.compute_args_hash)());\n        }\n\n        self.args_hash.unwrap_unchecked()\n    }\n    pub fn transaction_fee(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            transaction_fee()\n        }\n    }\n\n    pub fn chain_id(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            chain_id()\n        }\n    }\n    pub fn version(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            version()\n        }\n    }\n    pub fn block_number(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            block_number()\n        }\n    }\n    pub fn timestamp(_self: Self) -> u64 {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            timestamp()\n        }\n    }\n    pub fn fee_per_l2_gas(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            fee_per_l2_gas()\n        }\n    }\n    pub fn fee_per_da_gas(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            fee_per_da_gas()\n        }\n    }\n\n    pub fn l2_gas_left(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            l2_gas_left()\n        }\n    }\n    pub fn da_gas_left(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            da_gas_left()\n        }\n    }\n    pub fn is_static_call(_self: Self) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { is_static_call() } == 1\n    }\n\n    pub fn raw_storage_read<let N: u32>(_self: Self, storage_slot: Field) -> [Field; N] {\n        let mut out = [0; N];\n        for i in 0..N {\n            // Safety: AVM opcodes are constrained by the AVM itself\n            out[i] = unsafe { storage_read(storage_slot + i as Field) };\n        }\n        out\n    }\n\n    pub fn storage_read<T, let N: u32>(self, storage_slot: Field) -> T\n    where\n        T: Packable<N>,\n    {\n        T::unpack(self.raw_storage_read(storage_slot))\n    }\n\n    pub fn raw_storage_write<let N: u32>(_self: Self, storage_slot: Field, values: [Field; N]) {\n        for i in 0..N {\n            // Safety: AVM opcodes are constrained by the AVM itself\n            unsafe { storage_write(storage_slot + i as Field, values[i]) };\n        }\n    }\n\n    pub fn storage_write<T, let N: u32>(self, storage_slot: Field, value: T)\n    where\n        T: Packable<N>,\n    {\n        self.raw_storage_write(storage_slot, value.pack());\n    }\n}\n\n// Unconstrained opcode wrappers (do not use directly).\nunconstrained fn address() -> AztecAddress {\n    address_opcode()\n}\nunconstrained fn sender() -> AztecAddress {\n    sender_opcode()\n}\nunconstrained fn transaction_fee() -> Field {\n    transaction_fee_opcode()\n}\nunconstrained fn chain_id() -> Field {\n    chain_id_opcode()\n}\nunconstrained fn version() -> Field {\n    version_opcode()\n}\nunconstrained fn block_number() -> Field {\n    block_number_opcode()\n}\nunconstrained fn timestamp() -> u64 {\n    timestamp_opcode()\n}\nunconstrained fn fee_per_l2_gas() -> Field {\n    fee_per_l2_gas_opcode()\n}\nunconstrained fn fee_per_da_gas() -> Field {\n    fee_per_da_gas_opcode()\n}\nunconstrained fn l2_gas_left() -> Field {\n    l2_gas_left_opcode()\n}\nunconstrained fn da_gas_left() -> Field {\n    da_gas_left_opcode()\n}\nunconstrained fn is_static_call() -> Field {\n    is_static_call_opcode()\n}\nunconstrained fn note_hash_exists(note_hash: Field, leaf_index: Field) -> u1 {\n    note_hash_exists_opcode(note_hash, leaf_index)\n}\nunconstrained fn emit_note_hash(note_hash: Field) {\n    emit_note_hash_opcode(note_hash)\n}\nunconstrained fn nullifier_exists(nullifier: Field, address: Field) -> u1 {\n    nullifier_exists_opcode(nullifier, address)\n}\nunconstrained fn emit_nullifier(nullifier: Field) {\n    emit_nullifier_opcode(nullifier)\n}\nunconstrained fn emit_public_log(message: [Field]) {\n    emit_public_log_opcode(message)\n}\nunconstrained fn l1_to_l2_msg_exists(msg_hash: Field, msg_leaf_index: Field) -> u1 {\n    l1_to_l2_msg_exists_opcode(msg_hash, msg_leaf_index)\n}\nunconstrained fn send_l2_to_l1_msg(recipient: EthAddress, content: Field) {\n    send_l2_to_l1_msg_opcode(recipient, content)\n}\nunconstrained fn call(\n    l2_gas_allocation: Field,\n    da_gas_allocation: Field,\n    address: AztecAddress,\n    args: [Field],\n) {\n    call_opcode(l2_gas_allocation, da_gas_allocation, address, args)\n}\n\nunconstrained fn call_static(\n    l2_gas_allocation: Field,\n    da_gas_allocation: Field,\n    address: AztecAddress,\n    args: [Field],\n) {\n    call_static_opcode(l2_gas_allocation, da_gas_allocation, address, args)\n}\n\npub unconstrained fn calldata_copy<let N: u32>(cdoffset: u32, copy_size: u32) -> [Field; N] {\n    calldata_copy_opcode(cdoffset, copy_size)\n}\n\n// `success_copy` is placed immediately after the CALL opcode to get the success value\nunconstrained fn success_copy() -> bool {\n    success_copy_opcode()\n}\n\nunconstrained fn returndata_size() -> u32 {\n    returndata_size_opcode()\n}\n\nunconstrained fn returndata_copy(rdoffset: u32, copy_size: u32) -> [Field] {\n    returndata_copy_opcode(rdoffset, copy_size)\n}\n\npub unconstrained fn avm_return(returndata: [Field]) {\n    return_opcode(returndata)\n}\n\n// This opcode reverts using the exact data given. In general it should only be used\n// to do rethrows, where the revert data is the same as the original revert data.\n// For normal reverts, use Noir's `assert` which, on top of reverting, will also add\n// an error selector to the revert data.\nunconstrained fn avm_revert(revertdata: [Field]) {\n    revert_opcode(revertdata)\n}\n\nunconstrained fn storage_read(storage_slot: Field) -> Field {\n    storage_read_opcode(storage_slot)\n}\n\nunconstrained fn storage_write(storage_slot: Field, value: Field) {\n    storage_write_opcode(storage_slot, value);\n}\n\nimpl Empty for PublicContext {\n    fn empty() -> Self {\n        PublicContext::new(|| 0)\n    }\n}\n\n// AVM oracles (opcodes) follow, do not use directly.\n#[oracle(avmOpcodeAddress)]\nunconstrained fn address_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodeSender)]\nunconstrained fn sender_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodeTransactionFee)]\nunconstrained fn transaction_fee_opcode() -> Field {}\n\n#[oracle(avmOpcodeChainId)]\nunconstrained fn chain_id_opcode() -> Field {}\n\n#[oracle(avmOpcodeVersion)]\nunconstrained fn version_opcode() -> Field {}\n\n#[oracle(avmOpcodeBlockNumber)]\nunconstrained fn block_number_opcode() -> Field {}\n\n#[oracle(avmOpcodeTimestamp)]\nunconstrained fn timestamp_opcode() -> u64 {}\n\n#[oracle(avmOpcodeFeePerL2Gas)]\nunconstrained fn fee_per_l2_gas_opcode() -> Field {}\n\n#[oracle(avmOpcodeFeePerDaGas)]\nunconstrained fn fee_per_da_gas_opcode() -> Field {}\n\n#[oracle(avmOpcodeL2GasLeft)]\nunconstrained fn l2_gas_left_opcode() -> Field {}\n\n#[oracle(avmOpcodeDaGasLeft)]\nunconstrained fn da_gas_left_opcode() -> Field {}\n\n#[oracle(avmOpcodeIsStaticCall)]\nunconstrained fn is_static_call_opcode() -> Field {}\n\n#[oracle(avmOpcodeNoteHashExists)]\nunconstrained fn note_hash_exists_opcode(note_hash: Field, leaf_index: Field) -> u1 {}\n\n#[oracle(avmOpcodeEmitNoteHash)]\nunconstrained fn emit_note_hash_opcode(note_hash: Field) {}\n\n#[oracle(avmOpcodeNullifierExists)]\nunconstrained fn nullifier_exists_opcode(nullifier: Field, address: Field) -> u1 {}\n\n#[oracle(avmOpcodeEmitNullifier)]\nunconstrained fn emit_nullifier_opcode(nullifier: Field) {}\n\n// TODO(#11124): rename unencrypted to public in avm\n#[oracle(avmOpcodeEmitUnencryptedLog)]\nunconstrained fn emit_public_log_opcode(message: [Field]) {}\n\n#[oracle(avmOpcodeL1ToL2MsgExists)]\nunconstrained fn l1_to_l2_msg_exists_opcode(msg_hash: Field, msg_leaf_index: Field) -> u1 {}\n\n#[oracle(avmOpcodeSendL2ToL1Msg)]\nunconstrained fn send_l2_to_l1_msg_opcode(recipient: EthAddress, content: Field) {}\n\n#[oracle(avmOpcodeCalldataCopy)]\nunconstrained fn calldata_copy_opcode<let N: u32>(cdoffset: u32, copy_size: u32) -> [Field; N] {}\n\n#[oracle(avmOpcodeReturndataSize)]\nunconstrained fn returndata_size_opcode() -> u32 {}\n\n#[oracle(avmOpcodeReturndataCopy)]\nunconstrained fn returndata_copy_opcode(rdoffset: u32, copy_size: u32) -> [Field] {}\n\n#[oracle(avmOpcodeReturn)]\nunconstrained fn return_opcode(returndata: [Field]) {}\n\n// This opcode reverts using the exact data given. In general it should only be used\n// to do rethrows, where the revert data is the same as the original revert data.\n// For normal reverts, use Noir's `assert` which, on top of reverting, will also add\n// an error selector to the revert data.\n#[oracle(avmOpcodeRevert)]\nunconstrained fn revert_opcode(revertdata: [Field]) {}\n\n#[oracle(avmOpcodeCall)]\nunconstrained fn call_opcode(\n    l2_gas_allocation: Field,\n    da_gas_allocation: Field,\n    address: AztecAddress,\n    args: [Field],\n) {}\n\n#[oracle(avmOpcodeStaticCall)]\nunconstrained fn call_static_opcode(\n    l2_gas_allocation: Field,\n    da_gas_allocation: Field,\n    address: AztecAddress,\n    args: [Field],\n) {}\n\n#[oracle(avmOpcodeSuccessCopy)]\nunconstrained fn success_copy_opcode() -> bool {}\n\n#[oracle(avmOpcodeStorageRead)]\nunconstrained fn storage_read_opcode(storage_slot: Field) -> Field {}\n\n#[oracle(avmOpcodeStorageWrite)]\nunconstrained fn storage_write_opcode(storage_slot: Field, value: Field) {}\n"},"63":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/context/utility_context.nr","source":"use crate::oracle::{\n    execution::{get_block_number, get_chain_id, get_contract_address, get_version},\n    storage::storage_read,\n};\nuse dep::protocol_types::{address::AztecAddress, traits::Packable};\n\npub struct UtilityContext {\n    block_number: u32,\n    contract_address: AztecAddress,\n    version: Field,\n    chain_id: Field,\n}\n\nimpl UtilityContext {\n    pub unconstrained fn new() -> Self {\n        // We could call these oracles on the getters instead of at creation, which makes sense given that they might\n        // not even be accessed. However any performance gains are minimal, and we'd rather fail early if a user\n        // incorrectly attempts to create a UtilityContext in an environment in which these oracles are not\n        // available.\n        let block_number = get_block_number();\n        let contract_address = get_contract_address();\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub unconstrained fn at(contract_address: AztecAddress) -> Self {\n        let block_number = get_block_number();\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub unconstrained fn at_historical(contract_address: AztecAddress, block_number: u32) -> Self {\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub fn block_number(self) -> u32 {\n        self.block_number\n    }\n\n    pub fn this_address(self) -> AztecAddress {\n        self.contract_address\n    }\n\n    pub fn version(self) -> Field {\n        self.version\n    }\n\n    pub fn chain_id(self) -> Field {\n        self.chain_id\n    }\n\n    pub unconstrained fn raw_storage_read<let N: u32>(\n        self: Self,\n        storage_slot: Field,\n    ) -> [Field; N] {\n        storage_read(self.this_address(), storage_slot, self.block_number())\n    }\n\n    pub unconstrained fn storage_read<T, let N: u32>(self, storage_slot: Field) -> T\n    where\n        T: Packable<N>,\n    {\n        T::unpack(self.raw_storage_read(storage_slot))\n    }\n}\n"},"84":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/keys/getters/mod.nr","source":"use crate::{\n    keys::constants::{NULLIFIER_INDEX, OUTGOING_INDEX},\n    oracle::{\n        key_validation_request::get_key_validation_request,\n        keys::get_public_keys_and_partial_address,\n    },\n};\nuse dep::protocol_types::{address::AztecAddress, public_keys::PublicKeys};\n\nmod test;\n\npub unconstrained fn get_nsk_app(npk_m_hash: Field) -> Field {\n    get_key_validation_request(npk_m_hash, NULLIFIER_INDEX).sk_app\n}\n\n// A helper function that gets app-siloed outgoing viewing key for a given `ovpk_m_hash`. This function is used\n// in unconstrained contexts only - when computing unconstrained note logs. The safe alternative is `request_ovsk_app`\n// function defined on `PrivateContext`.\npub unconstrained fn get_ovsk_app(ovpk_m_hash: Field) -> Field {\n    get_key_validation_request(ovpk_m_hash, OUTGOING_INDEX).sk_app\n}\n\n// Returns all public keys for a given account, applying proper constraints to the context. We read all\n// keys at once since the constraints for reading them all are actually fewer than if we read them one at a time - any\n// read keys that are not required by the caller can simply be discarded.\npub fn get_public_keys(account: AztecAddress) -> PublicKeys {\n    // Safety: Public keys are constrained by showing their inclusion in the address's preimage.\n    let (public_keys, partial_address) = unsafe { get_public_keys_and_partial_address(account) };\n    assert_eq(\n        account,\n        AztecAddress::compute(public_keys, partial_address),\n        \"Invalid public keys hint for address\",\n    );\n\n    public_keys\n}\n"},"88":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/macros/aztec.nr","source":"use crate::{\n    macros::{\n        dispatch::generate_public_dispatch,\n        functions::{stub_registry, utils::check_each_fn_macroified},\n        notes::{generate_note_export, NOTES},\n        storage::STORAGE_LAYOUT_NAME,\n        utils::{get_trait_impl_method, module_has_storage},\n    },\n    messages::discovery::private_notes::MAX_NOTE_PACKED_LEN,\n};\n\n/// Marks a contract as an Aztec contract, generating the interfaces for its functions and notes, as well as injecting\n/// the `sync_private_state` utility function.\n/// Note: This is a module annotation, so the returned quote gets injected inside the module (contract) itself.\npub comptime fn aztec(m: Module) -> Quoted {\n    let interface = generate_contract_interface(m);\n\n    // Functions that don't have #[private], #[public], #[utility], #[contract_library_method], or #[test] are not\n    // allowed in contracts.\n    check_each_fn_macroified(m);\n\n    let contract_library_method_compute_note_hash_and_nullifier =\n        generate_contract_library_method_compute_note_hash_and_nullifier();\n    let note_exports = generate_note_exports();\n    let public_dispatch = generate_public_dispatch(m);\n    let sync_private_state = generate_sync_private_state();\n\n    quote {\n        $note_exports\n        $interface\n        $contract_library_method_compute_note_hash_and_nullifier\n        $public_dispatch\n        $sync_private_state\n    }\n}\n\ncomptime fn generate_contract_interface(m: Module) -> Quoted {\n    let module_name = m.name();\n    let contract_stubs = stub_registry::get(m);\n    let fn_stubs_quote = if contract_stubs.is_some() {\n        contract_stubs.unwrap().join(quote {})\n    } else {\n        quote {}\n    };\n\n    let has_storage_layout = module_has_storage(m) & STORAGE_LAYOUT_NAME.get(m).is_some();\n    let storage_layout_getter = if has_storage_layout {\n        let storage_layout_name = STORAGE_LAYOUT_NAME.get(m).unwrap();\n        quote {\n            pub fn storage_layout() -> StorageLayoutFields {\n                $storage_layout_name.fields\n            }\n        }\n    } else {\n        quote {}\n    };\n\n    let library_storage_layout_getter = if has_storage_layout {\n        quote {\n            #[contract_library_method]\n            $storage_layout_getter\n        }\n    } else {\n        quote {}\n    };\n\n    quote {\n        pub struct $module_name {\n            pub target_contract: dep::aztec::protocol_types::address::AztecAddress\n        }\n\n        impl $module_name {\n            $fn_stubs_quote\n\n            pub fn at(\n                addr: aztec::protocol_types::address::AztecAddress\n            ) -> Self {\n                Self { target_contract: addr }\n            }\n\n            pub fn interface() -> Self {\n                Self { target_contract: aztec::protocol_types::address::AztecAddress::zero() }\n            }\n\n            $storage_layout_getter\n        }\n\n        #[contract_library_method]\n        pub fn at(\n            addr: aztec::protocol_types::address::AztecAddress\n        ) -> $module_name {\n            $module_name { target_contract: addr }\n        }\n\n        #[contract_library_method]\n        pub fn interface() -> $module_name {\n            $module_name { target_contract: aztec::protocol_types::address::AztecAddress::zero() }\n        }\n\n        $library_storage_layout_getter\n\n    }\n}\n\n/// Generates a contract library method called `_compute_note_hash_and_nullifier` which is used for note\n/// discovery (to create the `aztec::messages::discovery::ComputeNoteHashAndNullifier` function) and to implement the\n/// `compute_note_hash_and_nullifier` unconstrained contract function.\ncomptime fn generate_contract_library_method_compute_note_hash_and_nullifier() -> Quoted {\n    let notes = NOTES.entries();\n\n    if notes.len() > 0 {\n        let max_note_packed_len = notes.fold(\n            0,\n            |acc, (_, (_, len, _, _)): (Type, (TypeDefinition, u32, Field, [(Quoted, u32, bool)]))| {\n                if len > acc {\n                    len\n                } else {\n                    acc\n                }\n            },\n        );\n\n        if max_note_packed_len > MAX_NOTE_PACKED_LEN {\n            panic(\n                f\"One of the notes has packed len {max_note_packed_len} but the maximum is {MAX_NOTE_PACKED_LEN}\",\n            );\n        }\n\n        // Contracts that do define notes produce an if-else chain where `note_type_id` is matched against the\n        // `get_note_type_id()` function of each note type that we know of, in order to identify the note type. Once we\n        // know it we call we correct `unpack` method from the `Packable` trait to obtain the underlying note type, and\n        // compute the note hash (non-siloed) and inner nullifier (also non-siloed).\n\n        let mut if_note_type_id_match_statements_list = &[];\n        for i in 0..notes.len() {\n            let (typ, (_, packed_note_length, _, _)) = notes[i];\n\n            let get_note_type_id = get_trait_impl_method(\n                typ,\n                quote { crate::note::note_interface::NoteType },\n                quote { get_id },\n            );\n            let unpack = get_trait_impl_method(\n                typ,\n                quote { crate::protocol_types::traits::Packable<_> },\n                quote { unpack },\n            );\n\n            let compute_note_hash = get_trait_impl_method(\n                typ,\n                quote { crate::note::note_interface::NoteHash },\n                quote { compute_note_hash },\n            );\n\n            let compute_nullifier_unconstrained = get_trait_impl_method(\n                typ,\n                quote { crate::note::note_interface::NoteHash },\n                quote { compute_nullifier_unconstrained },\n            );\n\n            let if_or_else_if = if i == 0 {\n                quote { if }\n            } else {\n                quote { else if }\n            };\n\n            if_note_type_id_match_statements_list = if_note_type_id_match_statements_list.push_back(\n                quote {\n                    $if_or_else_if note_type_id == $get_note_type_id() {\n                        // As an extra safety check we make sure that the packed_note BoundedVec has the expected\n                        // length, since we're about to interpret it's raw storage as a fixed-size array by calling the\n                        // unpack function on it.\n                        let expected_len = $packed_note_length;\n                        let actual_len = packed_note.len();\n                        assert(\n                            actual_len == expected_len,\n                            f\"Expected packed note of length {expected_len} but got {actual_len} for note type id {note_type_id}\"\n                        );\n\n                        let note = $unpack(aztec::utils::array::subarray(packed_note.storage(), 0));\n\n                        let note_hash = $compute_note_hash(note, storage_slot);\n    \n                        // The message discovery process finds settled notes, that is, notes that were created in prior\n                        // transactions and are therefore already part of the note hash tree. We therefore compute the\n                        // nullification note hash by treating the note as a settled note with the provided nonce.\n                        let note_hash_for_nullify = aztec::note::utils::compute_note_hash_for_nullify(\n                            aztec::note::retrieved_note::RetrievedNote{ \n                                note, \n                                contract_address, \n                                metadata: aztec::note::note_metadata::SettledNoteMetadata::new(nonce).into() \n                            }, \n                            storage_slot,\n                        );\n\n                        let inner_nullifier = $compute_nullifier_unconstrained(note, note_hash_for_nullify);\n\n                        Option::some(\n                            aztec::messages::discovery::NoteHashAndNullifier {\n                                note_hash, inner_nullifier\n                            }\n                        )\n                    }\n                },\n            );\n        }\n\n        let if_note_type_id_match_statements = if_note_type_id_match_statements_list.join(quote {});\n\n        quote {\n            /// Unpacks an array into a note corresponding to `note_type_id` and then computes its note hash\n            /// (non-siloed) and inner nullifier (non-siloed) assuming the note has been inserted into the note hash\n            /// tree with `nonce`.\n            ///\n            /// The signature of this function notably matches the `aztec::messages::discovery::ComputeNoteHashAndNullifier` type,\n            /// and so it can be used to call functions from that module such as `discover_new_messages`, \n            /// `do_process_log` and `attempt_note_discovery`.\n            ///\n            /// This function is automatically injected by the `#[aztec]` macro.\n            #[contract_library_method]\n            unconstrained fn _compute_note_hash_and_nullifier(\n                packed_note: BoundedVec<Field, aztec::messages::discovery::private_notes::MAX_NOTE_PACKED_LEN>,\n                storage_slot: Field,\n                note_type_id: Field,\n                contract_address: aztec::protocol_types::address::AztecAddress,\n                nonce: Field,\n            ) -> Option<aztec::messages::discovery::NoteHashAndNullifier> {\n                $if_note_type_id_match_statements\n                else {\n                    Option::none()\n                }\n            }\n        }\n    } else {\n        // Contracts with no notes still implement this function to avoid having special-casing, the implementation\n        // simply throws immediately.\n        quote {\n            /// This contract does not use private notes, so this function should never be called as it will\n            /// unconditionally fail.\n            ///\n            /// This function is automatically injected by the `#[aztec]` macro.\n            #[contract_library_method]\n            unconstrained fn _compute_note_hash_and_nullifier(\n                _packed_note: BoundedVec<Field, aztec::messages::discovery::private_notes::MAX_NOTE_PACKED_LEN>,\n                _storage_slot: Field,\n                _note_type_id: Field,\n                _contract_address: aztec::protocol_types::address::AztecAddress,\n                _nonce: Field,\n            ) -> Option<aztec::messages::discovery::NoteHashAndNullifier> {\n                panic(f\"This contract does not use private notes\")\n            }\n        }\n    }\n}\n\ncomptime fn generate_note_exports() -> Quoted {\n    let notes = NOTES.values();\n    // Second value in each tuple is `note_packed_len` and that is ignored here because it's only used when\n    // generating partial note helper functions.\n    notes\n        .map(|(s, _, note_type_id, fields): (TypeDefinition, u32, Field, [(Quoted, u32, bool)])| {\n            generate_note_export(s, note_type_id, fields)\n        })\n        .join(quote {})\n}\n\ncomptime fn generate_sync_private_state() -> Quoted {\n    // We obtain the `utility` function on the next line instead of directly doing\n    // `#[aztec::macros::functions::utility]` in the returned quote because the latter would result in the function\n    // attribute having the full path in the ABI. This is undesirable because we use the information in the ABI only\n    // to determine whether a function is `private`, `public`, or `utility`.\n    let utility = crate::macros::functions::utility;\n\n    // All we need to do here is trigger message discovery, but this is already done by the #[utility] macro - we don't\n    // need to do anything extra.\n    quote {\n        #[$utility]\n        unconstrained fn sync_private_state() {\n        }\n    }\n}\n"},"89":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/macros/dispatch.nr","source":"use super::utils::compute_fn_selector;\nuse std::panic;\n\n/// Returns an `fn public_dispatch(...)` function for the given module that's assumed to be an Aztec contract.\npub comptime fn generate_public_dispatch(m: Module) -> Quoted {\n    let functions = m.functions();\n    let functions =\n        functions.filter(|function: FunctionDefinition| function.has_named_attribute(\"public\"));\n\n    let unit = get_type::<()>();\n\n    let ifs = functions.map(|function: FunctionDefinition| {\n        let parameters = function.parameters();\n        let return_type = function.return_type();\n\n        let selector: Field = compute_fn_selector(function);\n\n        let mut parameters_size = 0;\n        for param in parameters {\n            parameters_size += size_in_fields(param.1);\n        }\n\n        let initial_read = if parameters.len() == 0 {\n            quote {}\n        } else {\n            // The initial calldata_copy offset is 1 to skip the Field selector\n            // The expected calldata is the serialization of\n            // - FunctionSelector: the selector of the function intended to dispatch\n            // - Parameters: the parameters of the function intended to dispatch\n            // That is, exactly what is expected for a call to the target function,\n            // but with a selector added at the beginning.\n            quote {\n                let input_calldata: [Field; $parameters_size] = dep::aztec::context::public_context::calldata_copy(1, $parameters_size);\n                let mut reader = dep::aztec::protocol_types::utils::reader::Reader::new(input_calldata);\n            }\n        };\n\n        let parameter_index = &mut 0;\n        let reads = parameters.map(|param: (Quoted, Type)| {\n            let parameter_index_value = *parameter_index;\n            let param_name = f\"arg{parameter_index_value}\".quoted_contents();\n            let param_type = param.1;\n            let read = quote {\n                let $param_name: $param_type = reader.read_struct(dep::aztec::protocol_types::traits::Deserialize::deserialize);\n            };\n            *parameter_index += 1;\n            quote { $read }\n        });\n        let read = reads.join(quote { });\n\n        let mut args = &[];\n        for parameter_index in 0..parameters.len() {\n            let param_name = f\"arg{parameter_index}\".quoted_contents();\n            args = args.push_back(quote { $param_name });\n        }\n\n        let args = args.join(quote { , });\n        // name of the function is assigned just before the call so debug metadata doesn't span most of this macro when figuring out where the call comes from.\n        let name = function.name();\n        let call = quote { $name($args) };\n\n        let return_code = if return_type == unit {\n            quote {\n                $call;\n                // Force early return.\n                dep::aztec::context::public_context::avm_return([]);\n            }\n        } else {\n            quote {\n                let return_value = dep::aztec::protocol_types::traits::Serialize::serialize($call);\n                dep::aztec::context::public_context::avm_return(return_value.as_slice());\n            }\n        };\n\n        let if_ = quote {\n            if selector == $selector {\n                $initial_read\n                $read\n                $return_code\n            }\n        };\n        if_\n    });\n\n    if ifs.len() == 0 {\n        // No dispatch function if there are no public functions\n        quote {}\n    } else {\n        let ifs = ifs.push_back(quote { panic(f\"Unknown selector {selector}\") });\n        let dispatch = ifs.join(quote {  });\n\n        let body = quote {\n            // We mark this as public because our whole system depends on public\n            // functions having this attribute. However, the public MACRO will\n            // handle the public_dispatch function specially and do nothing.\n            #[public]\n            pub unconstrained fn public_dispatch(selector: Field) {\n                $dispatch\n            }\n        };\n\n        body\n    }\n}\n\ncomptime fn size_in_fields(typ: Type) -> u32 {\n    let size = array_size_in_fields(typ);\n    let size = size.or_else(|| bool_size_in_fields(typ));\n    let size = size.or_else(|| constant_size_in_fields(typ));\n    let size = size.or_else(|| field_size_in_fields(typ));\n    let size = size.or_else(|| int_size_in_fields(typ));\n    let size = size.or_else(|| str_size_in_fields(typ));\n    let size = size.or_else(|| struct_size_in_fields(typ));\n    let size = size.or_else(|| tuple_size_in_fields(typ));\n    if size.is_some() {\n        size.unwrap()\n    } else {\n        panic(f\"Can't determine size in fields of {typ}\")\n    }\n}\n\ncomptime fn array_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_array().and_then(|typ: (Type, Type)| {\n        let (typ, element_size) = typ;\n        element_size.as_constant().map(|x: u32| x * size_in_fields(typ))\n    })\n}\n\ncomptime fn bool_size_in_fields(typ: Type) -> Option<u32> {\n    if typ.is_bool() {\n        Option::some(1)\n    } else {\n        Option::none()\n    }\n}\n\ncomptime fn field_size_in_fields(typ: Type) -> Option<u32> {\n    if typ.is_field() {\n        Option::some(1)\n    } else {\n        Option::none()\n    }\n}\n\ncomptime fn int_size_in_fields(typ: Type) -> Option<u32> {\n    if typ.as_integer().is_some() {\n        Option::some(1)\n    } else {\n        Option::none()\n    }\n}\n\ncomptime fn constant_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_constant()\n}\n\ncomptime fn str_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_str().map(|typ| size_in_fields(typ))\n}\n\ncomptime fn struct_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_data_type().map(|typ: (TypeDefinition, [Type])| {\n        let struct_type = typ.0;\n        let generics = typ.1;\n        let mut size = 0;\n        for field in struct_type.fields(generics) {\n            size += size_in_fields(field.1);\n        }\n        size\n    })\n}\n\ncomptime fn tuple_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_tuple().map(|types: [Type]| {\n        let mut size = 0;\n        for typ in types {\n            size += size_in_fields(typ);\n        }\n        size\n    })\n}\n\ncomptime fn get_type<T>() -> Type {\n    let t: T = std::mem::zeroed();\n    std::meta::type_of(t)\n}\n"},"93":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/macros/functions/initialization_utils.nr","source":"use dep::protocol_types::{\n    abis::function_selector::FunctionSelector, address::AztecAddress,\n    constants::GENERATOR_INDEX__CONSTRUCTOR, hash::poseidon2_hash_with_separator, traits::ToField,\n};\n\nuse crate::{\n    context::{PrivateContext, PublicContext},\n    oracle::get_contract_instance::{\n        get_contract_instance, get_contract_instance_deployer_avm,\n        get_contract_instance_initialization_hash_avm,\n    },\n};\n\npub fn mark_as_initialized_public(context: &mut PublicContext) {\n    let init_nullifier =\n        compute_unsiloed_contract_initialization_nullifier((*context).this_address());\n    context.push_nullifier(init_nullifier);\n}\n\npub fn mark_as_initialized_private(context: &mut PrivateContext) {\n    let init_nullifier =\n        compute_unsiloed_contract_initialization_nullifier((*context).this_address());\n    context.push_nullifier(init_nullifier);\n}\n\npub fn assert_is_initialized_public(context: &mut PublicContext) {\n    let init_nullifier = compute_unsiloed_contract_initialization_nullifier(context.this_address());\n    assert(context.nullifier_exists(init_nullifier, context.this_address()), \"Not initialized\");\n}\n\npub fn assert_is_initialized_private(context: &mut PrivateContext) {\n    let init_nullifier = compute_unsiloed_contract_initialization_nullifier(context.this_address());\n    context.push_nullifier_read_request(init_nullifier);\n}\n\nfn compute_unsiloed_contract_initialization_nullifier(address: AztecAddress) -> Field {\n    address.to_field()\n}\n\npub fn assert_initialization_matches_address_preimage_public(context: PublicContext) {\n    let address = context.this_address();\n    let deployer = get_contract_instance_deployer_avm(address).unwrap();\n    let initialization_hash = get_contract_instance_initialization_hash_avm(address).unwrap();\n    let expected_init = compute_initialization_hash(context.selector(), context.get_args_hash());\n    assert(initialization_hash == expected_init, \"Initialization hash does not match\");\n    assert(\n        (deployer.is_zero()) | (deployer == context.msg_sender()),\n        \"Initializer address is not the contract deployer\",\n    );\n}\n\npub fn assert_initialization_matches_address_preimage_private(context: PrivateContext) {\n    let address = context.this_address();\n    let instance = get_contract_instance(address);\n    let expected_init = compute_initialization_hash(context.selector(), context.get_args_hash());\n    assert(instance.initialization_hash == expected_init, \"Initialization hash does not match\");\n    assert(\n        (instance.deployer.is_zero()) | (instance.deployer == context.msg_sender()),\n        \"Initializer address is not the contract deployer\",\n    );\n}\n\n/// This function is not only used in macros but it's also used by external people to check that an instance has been\n/// initialized with the correct constructor arguments. Don't hide this unless you implement factory functionality.\npub fn compute_initialization_hash(\n    init_selector: FunctionSelector,\n    init_args_hash: Field,\n) -> Field {\n    poseidon2_hash_with_separator(\n        [init_selector.to_field(), init_args_hash],\n        GENERATOR_INDEX__CONSTRUCTOR,\n    )\n}\n"},"96":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/macros/functions/utils.nr","source":"use crate::macros::{\n    functions::{abi_export::create_fn_abi_export, call_interface_stubs::stub_fn, stub_registry},\n    notes::NOTES,\n    utils::{\n        add_to_hasher, fn_has_noinitcheck, get_fn_visibility, is_fn_contract_library_method,\n        is_fn_initializer, is_fn_internal, is_fn_private, is_fn_public, is_fn_test, is_fn_utility,\n        is_fn_view, modify_fn_body, module_has_initializer, module_has_storage,\n    },\n};\nuse protocol_types::meta::generate_serialize_to_fields;\nuse std::meta::type_of;\n\npub(crate) comptime fn transform_private(f: FunctionDefinition) -> Quoted {\n    let fn_abi = create_fn_abi_export(f);\n    let fn_stub = stub_fn(f);\n    stub_registry::register(f.module(), fn_stub);\n\n    // If a function is further modified as unconstrained, we throw an error\n    if f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[private] but marked as unconstrained, remove unconstrained keyword\",\n        );\n    }\n\n    let module_has_initializer = module_has_initializer(f.module());\n    let module_has_storage = module_has_storage(f.module());\n\n    // Private functions undergo a lot of transformations from their Aztec.nr form into a circuit that can be fed to the\n    // Private Kernel Circuit.\n    // First we change the function signature so that it also receives `PrivateContextInputs`, which contain information\n    // about the execution context (e.g. the caller).\n    let original_params = f.parameters();\n    f.set_parameters(&[(\n        quote { inputs },\n        quote { crate::context::inputs::private_context_inputs::PrivateContextInputs }.as_type(),\n    )]\n        .append(original_params));\n\n    let mut body = f.body().as_block().unwrap();\n\n    // The original params are hashed and passed to the `context` object, so that the kernel can verify we've received\n    // the correct values.\n    // TODO: Optimize args_hasher for small number of arguments\n    let args_hasher_name = quote { args_hasher };\n    let args_hasher = original_params.fold(\n        quote {\n            let mut $args_hasher_name = dep::aztec::hash::ArgsHasher::new();\n        },\n        |args_hasher, param: (Quoted, Type)| {\n            let (name, typ) = param;\n            let appended_arg = add_to_hasher(args_hasher_name, name, typ);\n            quote {\n                $args_hasher\n                $appended_arg\n            }\n        },\n    );\n\n    let context_creation = quote {\n        let mut context = dep::aztec::context::private_context::PrivateContext::new(inputs, dep::aztec::protocol_types::traits::Hash::hash($args_hasher_name));\n    };\n\n    // Modifications introduced by the different marker attributes.\n    let internal_check = if is_fn_internal(f) {\n        create_internal_check(f)\n    } else {\n        quote {}\n    };\n\n    let view_check = if is_fn_view(f) {\n        create_view_check(f)\n    } else {\n        quote {}\n    };\n\n    let (assert_initializer, mark_as_initialized) = if is_fn_initializer(f) {\n        (create_assert_correct_initializer_args(f), create_mark_as_initialized(f))\n    } else {\n        (quote {}, quote {})\n    };\n\n    let storage_init = if module_has_storage {\n        quote {\n            // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n            // referenced. We instead ignore 'unused variable' warnings for it.\n            #[allow(unused_variables)]\n            let storage = Storage::init(&mut context);\n        }\n    } else {\n        quote {}\n    };\n\n    // Initialization checks are not included in contracts that don't have initializers.\n    let init_check = if module_has_initializer & !is_fn_initializer(f) & !fn_has_noinitcheck(f) {\n        create_init_check(f)\n    } else {\n        quote {}\n    };\n\n    // All private functions perform message discovery, since they may need to access notes. This is slightly\n    // inefficient and could be improved by only doing it once we actually attempt to read any.\n    let message_discovery_call = if NOTES.len() > 0 {\n        create_message_discovery_call()\n    } else {\n        quote {}\n    };\n\n    // Finally, we need to change the return type to be `PrivateCircuitPublicInputs`, which is what the Private Kernel\n    // circuit expects.\n    let return_value_var_name = quote { macro__returned__values };\n\n    let return_value_type = f.return_type();\n    let return_value = if body.len() == 0 {\n        quote {}\n    } else if return_value_type != type_of(()) {\n        // The original return value is passed to a second args hasher which the context receives.\n        let (body_without_return, last_body_expr) = body.pop_back();\n        let return_value = last_body_expr.quoted();\n        let return_value_assignment =\n            quote { let $return_value_var_name: $return_value_type = $return_value; };\n        let return_hasher_name = quote { return_hasher };\n        let return_value_into_hasher =\n            add_to_hasher(return_hasher_name, return_value_var_name, return_value_type);\n\n        body = body_without_return;\n\n        quote {\n            let mut $return_hasher_name = dep::aztec::hash::ArgsHasher::new();\n            $return_value_assignment\n            $return_value_into_hasher\n            context.set_return_hash($return_hasher_name);\n        }\n    } else {\n        let (body_without_return, last_body_expr) = body.pop_back();\n        if !last_body_expr.has_semicolon()\n            & last_body_expr.as_for().is_none()\n            & last_body_expr.as_assert().is_none()\n            & last_body_expr.as_for_range().is_none()\n            & last_body_expr.as_assert_eq().is_none()\n            & last_body_expr.as_let().is_none() {\n            let unused_return_value_name = f\"_{return_value_var_name}\".quoted_contents();\n            body = body_without_return.push_back(\n                quote { let $unused_return_value_name = $last_body_expr; }.as_expr().unwrap(),\n            );\n        }\n        quote {}\n    };\n\n    let context_finish = quote { context.finish() };\n\n    let to_prepend = quote {\n        $args_hasher\n        $context_creation\n        $assert_initializer\n        $init_check\n        $internal_check\n        $view_check\n        $storage_init\n        $message_discovery_call\n    };\n\n    let to_append = quote {\n        $return_value\n        $mark_as_initialized\n        $context_finish\n    };\n    let modified_body = modify_fn_body(body, to_prepend, to_append);\n    f.set_body(modified_body);\n    f.set_return_type(\n        quote { dep::protocol_types::abis::private_circuit_public_inputs::PrivateCircuitPublicInputs }\n            .as_type(),\n    );\n    f.set_return_data();\n\n    fn_abi\n}\n\npub(crate) comptime fn transform_public(f: FunctionDefinition) -> Quoted {\n    let fn_abi = create_fn_abi_export(f);\n    let fn_stub = stub_fn(f);\n    stub_registry::register(f.module(), fn_stub);\n\n    // If a function is further modified as unconstrained, we throw an error\n    if f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[public] but marked as unconstrained, remove unconstrained keyword\",\n        );\n    }\n\n    let module_has_initializer = module_has_initializer(f.module());\n    let module_has_storage = module_has_storage(f.module());\n\n    // Public functions undergo a lot of transformations from their Aztec.nr form.\n    let original_params = f.parameters();\n    let args_len = original_params\n        .map(|(name, typ): (Quoted, Type)| {\n            generate_serialize_to_fields(name, typ, false).0.len()\n        })\n        .fold(0, |acc: u32, val: u32| acc + val);\n\n    // Unlike in the private case, in public the `context` does not need to receive the hash of the original params.\n    let context_creation = quote {\n        let mut context = dep::aztec::context::public_context::PublicContext::new(|| {\n        // We start from 1 because we skip the selector for the dispatch function.\n        let serialized_args : [Field; $args_len] = dep::aztec::context::public_context::calldata_copy(1, $args_len);\n        dep::aztec::hash::hash_args_array(serialized_args)\n        });\n    };\n\n    // Modifications introduced by the different marker attributes.\n    let internal_check = if is_fn_internal(f) {\n        create_internal_check(f)\n    } else {\n        quote {}\n    };\n\n    let view_check = if is_fn_view(f) {\n        create_view_check(f)\n    } else {\n        quote {}\n    };\n\n    let (assert_initializer, mark_as_initialized) = if is_fn_initializer(f) {\n        (create_assert_correct_initializer_args(f), create_mark_as_initialized(f))\n    } else {\n        (quote {}, quote {})\n    };\n\n    let storage_init = if module_has_storage {\n        // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n        // referenced. We instead ignore 'unused variable' warnings for it.\n        quote {\n            #[allow(unused_variables)]\n            let storage = Storage::init(&mut context);\n        }\n    } else {\n        quote {}\n    };\n\n    // Initialization checks are not included in contracts that don't have initializers.\n    let init_check = if module_has_initializer & !fn_has_noinitcheck(f) & !is_fn_initializer(f) {\n        create_init_check(f)\n    } else {\n        quote {}\n    };\n\n    let to_prepend = quote {\n        $context_creation\n        $assert_initializer\n        $init_check\n        $internal_check\n        $view_check\n        $storage_init\n    };\n\n    let to_append = quote {\n        $mark_as_initialized\n    };\n\n    let body = f.body().as_block().unwrap();\n    let modified_body = modify_fn_body(body, to_prepend, to_append);\n    f.set_body(modified_body);\n\n    // All public functions are automatically made unconstrained, even if they were not marked as such. This is because\n    // instead of compiling into a circuit, they will compile to bytecode that will be later transpiled into AVM\n    // bytecode.\n    f.set_unconstrained(true);\n    f.set_return_public(true);\n\n    fn_abi\n}\n\npub(crate) comptime fn transform_utility(f: FunctionDefinition) -> Quoted {\n    let fn_abi = create_fn_abi_export(f);\n    let fn_stub = stub_fn(f);\n    stub_registry::register(f.module(), fn_stub);\n\n    // Check if function is marked as unconstrained\n    if !f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[utility] but not marked as unconstrained, add unconstrained keyword\",\n        );\n    }\n\n    // Create utility context\n    let context_creation =\n        quote { let mut context = dep::aztec::context::utility_context::UtilityContext::new(); };\n    let module_has_storage = module_has_storage(f.module());\n\n    // Initialize Storage if module has storage\n    let storage_init = if module_has_storage {\n        quote {\n            // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n            // referenced. We instead ignore 'unused variable' warnings for it.\n            #[allow(unused_variables)]\n            let storage = Storage::init(context);\n        }\n    } else {\n        quote {}\n    };\n\n    // All utility functions perform message discovery, since they may need to access private notes that would be\n    // found during this process. This is slightly inefficient and could be improved by only doing it once we actually\n    // attempt to read any.\n    let message_discovery_call = if NOTES.len() > 0 {\n        create_message_discovery_call()\n    } else {\n        quote {}\n    };\n\n    // Inject context creation, storage initialization, and message discovery call at the beginning of the function\n    // body.\n    let to_prepend = quote {\n        $context_creation\n        $storage_init\n        $message_discovery_call\n    };\n    let body = f.body().as_block().unwrap();\n    let modified_body = modify_fn_body(body, to_prepend, quote {});\n    f.set_body(modified_body);\n\n    f.set_return_public(true);\n\n    fn_abi\n}\n\ncomptime fn create_internal_check(f: FunctionDefinition) -> Quoted {\n    let name = f.name();\n    let assertion_message = f\"Function {name} can only be called internally\";\n    quote { assert(context.msg_sender() == context.this_address(), $assertion_message); }\n}\n\ncomptime fn create_view_check(f: FunctionDefinition) -> Quoted {\n    let name = f.name();\n    let assertion_message = f\"Function {name} can only be called statically\";\n    if is_fn_private(f) {\n        // Here `context` is of type context::PrivateContext\n        quote { assert(context.inputs.call_context.is_static_call == true, $assertion_message); }\n    } else {\n        // Here `context` is of type context::PublicContext\n        quote { assert(context.is_static_call(), $assertion_message); }\n    }\n}\n\ncomptime fn create_assert_correct_initializer_args(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::assert_initialization_matches_address_preimage_{fn_visibility}(context);\"\n        .quoted_contents()\n}\n\ncomptime fn create_mark_as_initialized(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::mark_as_initialized_{fn_visibility}(&mut context);\"\n        .quoted_contents()\n}\n\ncomptime fn create_init_check(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::assert_is_initialized_{fn_visibility}(&mut context);\"\n        .quoted_contents()\n}\n\n/// Injects a call to `aztec::messages::discovery::discover_new_messages`, causing for new notes to be added to PXE and made\n/// available for the current execution.\npub(crate) comptime fn create_message_discovery_call() -> Quoted {\n    quote {\n        /// Safety: message discovery returns nothing and is performed solely for its side-effects. It is therefore\n        /// always safe to call.\n        unsafe {\n            dep::aztec::messages::discovery::discover_new_messages(\n                context.this_address(),\n                _compute_note_hash_and_nullifier,\n            );\n        };\n    }\n}\n\n/// Checks if each function in the module is marked with either #[private], #[public], #[utility],\n/// #[contract_library_method], or #[test]. Non-macroified functions are not allowed in contracts.\npub(crate) comptime fn check_each_fn_macroified(m: Module) {\n    for f in m.functions() {\n        let name = f.name();\n        if !is_fn_private(f)\n            & !is_fn_public(f)\n            & !is_fn_utility(f)\n            & !is_fn_contract_library_method(f)\n            & !is_fn_test(f) {\n            panic(\n                f\"Function {name} must be marked as either #[private], #[public], #[utility], #[contract_library_method], or #[test]\",\n            );\n        }\n    }\n}\n"},"98":{"path":"/home/lucholeonel/nargo/github.com/AztecProtocol/aztec-packages/v0.87.8/noir-projects/aztec-nr/aztec/src/macros/notes.nr","source":"use crate::{macros::utils::AsStrQuote, note::note_getter_options::PropertySelector};\nuse poseidon::poseidon2::Poseidon2Hasher;\nuse protocol_types::meta::{derive_packable_and_get_packed_len, generate_serialize_to_fields};\nuse std::{\n    collections::umap::UHashMap,\n    hash::{BuildHasherDefault, Hash, Hasher},\n    meta::{type_of, unquote},\n};\n\n/// A map from note type to (note_struct_definition, note_packed_len, note_type_id, fields).\n/// `fields` is an array of tuples where each tuple contains the name of the field/struct member (e.g. `amount`\n/// in `TokenNote`), the index of where the packed member starts in the packed note and a flag indicating\n/// whether the field is nullable or not.\npub comptime mut global NOTES: UHashMap<Type, (TypeDefinition, u32, Field, [(Quoted, u32, bool)]), BuildHasherDefault<Poseidon2Hasher>> =\n    UHashMap::default();\n\npub comptime mut global NOTE_TYPE_ID_COUNTER: u32 = 0;\n\n/// The note type id is set by enumerating the note types.\ncomptime fn get_next_note_type_id() -> Field {\n    // We assert that the note type id fits within 7 bits\n    assert(\n        NOTE_TYPE_ID_COUNTER < 128 as u32,\n        \"A contract can contain at most 128 different note types\",\n    );\n\n    let note_type_id = NOTE_TYPE_ID_COUNTER as Field;\n    NOTE_TYPE_ID_COUNTER += 1;\n    note_type_id\n}\n\n/// Generates a quote that implements `Packable` for a given struct `s`.\n/// If the note struct already implements `Packable`, we return an empty quote.\ncomptime fn derive_packable_if_not_implemented_and_get_len(s: TypeDefinition) -> (Quoted, u32) {\n    // We try to get the packed length of the note struct. If it does not implement `Packable`, we get Option::none()\n    let packed_len_typ = std::meta::typ::fresh_type_variable();\n    // We don't care about the result of the implements check. We just want the get the packed length.\n    let _ = s.as_type().implements(\n        quote { crate::protocol_types::traits::Packable<$packed_len_typ> }.as_trait_constraint(),\n    );\n    let maybe_packed_length = packed_len_typ.as_constant();\n\n    if maybe_packed_length.is_some() {\n        // We got some packed length meaning that the note struct implements `Packable`. For this reason we return\n        // an empty quote for the implementation and the packed length.\n        (quote {}, maybe_packed_length.unwrap())\n    } else {\n        // We didn't manage to get the packed length which means the note struct doesn't implement `Packable`\n        // so we derive it and return it along with the packed length.\n        derive_packable_and_get_packed_len(s)\n    }\n}\n\n/// Generates default `NoteType` implementation for a given note struct `s` and returns it as a quote.\n///\n/// impl NoteType for NoteStruct {\n///     fn get_id() -> Field {\n///         ...\n///     }\n/// }\ncomptime fn generate_note_interface(s: TypeDefinition, note_type_id: Field) -> Quoted {\n    let name = s.name();\n\n    quote {\n        impl aztec::note::note_interface::NoteType for $name {\n            fn get_id() -> Field {\n                $note_type_id\n            }\n        }\n    }\n}\n\n/// Generates default `NoteHash` trait implementation for a given note struct `s` and returns it as a quote.\n///\n/// # Generated Implementation\n/// ```\n/// impl NoteHash for NoteStruct {\n///     fn compute_note_hash(self, storage_slot: Field) -> Field { ... }\n///\n///     fn compute_nullifier(self, context: &mut PrivateContext, note_hash_for_nullify: Field) -> Field { ... }\n///\n///     unconstrained fn compute_nullifier_unconstrained(note_hash_for_nullify: Field) -> Field { ... }\n/// }\n/// ```\ncomptime fn generate_note_hash_trait_impl(s: TypeDefinition) -> Quoted {\n    let name = s.name();\n\n    quote {\n        impl aztec::note::note_interface::NoteHash for $name {\n            fn compute_note_hash(self, storage_slot: Field) -> Field {\n                let inputs = aztec::protocol_types::utils::arrays::array_concat(aztec::protocol_types::traits::Packable::pack(self), [storage_slot]);\n                aztec::protocol_types::hash::poseidon2_hash_with_separator(inputs, aztec::protocol_types::constants::GENERATOR_INDEX__NOTE_HASH)\n            }\n\n            fn compute_nullifier(\n                self,\n                context: &mut aztec::prelude::PrivateContext,\n                note_hash_for_nullify: Field,\n            ) -> Field {\n                let owner_npk_m = aztec::keys::getters::get_public_keys(self.owner).npk_m;\n                // We invoke hash as a static trait function rather than calling owner_npk_m.hash() directly\n                // in the quote to avoid \"trait not in scope\" compiler warnings.\n                let owner_npk_m_hash = aztec::protocol_types::traits::Hash::hash(owner_npk_m);\n                let secret = context.request_nsk_app(owner_npk_m_hash);\n                aztec::protocol_types::hash::poseidon2_hash_with_separator(\n                    [note_hash_for_nullify, secret],\n                    aztec::protocol_types::constants::GENERATOR_INDEX__NOTE_NULLIFIER as Field,\n                )\n            }\n\n            unconstrained fn compute_nullifier_unconstrained(\n                self,\n                note_hash_for_nullify: Field,\n            ) -> Field {\n                let owner_npk_m = aztec::keys::getters::get_public_keys(self.owner).npk_m;\n                // We invoke hash as a static trait function rather than calling owner_npk_m.hash() directly\n                // in the quote to avoid \"trait not in scope\" compiler warnings.\n                let owner_npk_m_hash = aztec::protocol_types::traits::Hash::hash(owner_npk_m);\n                let secret = aztec::keys::getters::get_nsk_app(owner_npk_m_hash);\n                aztec::protocol_types::hash::poseidon2_hash_with_separator(\n                    [note_hash_for_nullify, secret],\n                    aztec::protocol_types::constants::GENERATOR_INDEX__NOTE_NULLIFIER as Field,\n                )\n            }\n        }\n    }\n}\n\n/// Generates note properties struct for a given note struct `s`.\n///\n/// Example:\n/// ```\n/// struct TokenNoteProperties {\n///     amount: aztec::note::note_getter_options::PropertySelector,\n///     npk_m_hash: aztec::note::note_getter_options::PropertySelector\n///     randomness: aztec::note::note_getter_options::PropertySelector\n/// }\n///\n/// impl aztec::note::note_interface::NoteProperties<TokenNoteProperties> for TokenNote {\n///     fn properties() -> TokenNoteProperties {\n///         Self {\n///             amount: aztec::note::note_getter_options::PropertySelector { index: 0, offset: 0, length: 32 },\n///             npk_m_hash: aztec::note::note_getter_options::PropertySelector { index: 1, offset: 0, length: 32 },\n///             randomness: aztec::note::note_getter_options::PropertySelector { index: 2, offset: 0, length: 32 }\n///         }\n///     }\n/// }\n/// ```\ncomptime fn generate_note_properties(s: TypeDefinition) -> Quoted {\n    let name = s.name();\n\n    let struct_name = f\"{name}Properties\".quoted_contents();\n\n    let property_selector_type = type_of(PropertySelector { index: 0, offset: 0, length: 0 });\n\n    let note_fields = s.fields_as_written();\n\n    let properties_types = note_fields\n        .map(|(name, _): (Quoted, Type)| quote { pub $name: $property_selector_type })\n        .join(quote {,});\n\n    // TODO #8694: Properly handle non-field types https://github.com/AztecProtocol/aztec-packages/issues/8694\n    let mut properties_list = &[];\n    for i in 0..note_fields.len() {\n        let (name, _) = note_fields[i];\n        properties_list = properties_list.push_back(\n            quote { $name: aztec::note::note_getter_options::PropertySelector { index: $i, offset: 0, length: 32 } },\n        );\n    }\n\n    let properties = properties_list.join(quote {,});\n\n    quote {\n        pub struct $struct_name {\n            $properties_types\n        }\n\n        impl aztec::note::note_interface::NoteProperties<$struct_name> for $name {\n            fn properties() -> $struct_name {\n                $struct_name {\n                    $properties\n                }\n            }\n        }\n    }\n}\n\n/// Generates note export for a given note struct `s`. The export is a global variable that contains note type id,\n/// note name and information about note fields (field name, index and whether the field is nullable or not).\n///\n/// Example:\n/// ```\n/// struct TokenNoteFields_5695262104 {\n///     amount: aztec::note::note_field::NoteField,\n///     owner: aztec::note::note_field::NoteField\n/// }\n///\n/// #[abi(notes)]\n/// global TokenNote_EXPORTS_5695262104: (Field, str<8>, TokenNoteFields_5695262104) = (\n///     0,\n///     \"TokenNote\",\n///     TokenNoteFields_5695262104 {\n///         amount: aztec::note::note_field::NoteField { index: 0, nullable: false },\n///         owner: aztec::note::note_field::NoteField { index: 1, nullable: false }\n///     }\n/// );\n///\n/// Randomly looking value at the end of the export name is generated by hashing the note struct type and is included\n/// to prevent naming collisions in case there are multiple notes with the same name imported in a contract.\npub(crate) comptime fn generate_note_export(\n    s: TypeDefinition,\n    note_type_id: Field,\n    fields: [(Quoted, u32, bool)],\n) -> Quoted {\n    let name = s.name();\n    let mut hasher = Poseidon2Hasher::default();\n    s.as_type().hash(&mut hasher);\n    let hash = hasher.finish() as u32;\n    let global_export_name = f\"{name}_EXPORTS_{hash}\".quoted_contents();\n    let note_fields_name = f\"{name}Fields_{hash}\".quoted_contents();\n    let (note_name_as_str, _) = name.as_str_quote();\n    let note_name_str_len = unquote!(quote { $note_name_as_str.as_bytes().len() });\n\n    let mut note_fields = &[];\n    let mut note_field_constructors = &[];\n    for field in fields {\n        let (name, index, nullable) = field;\n        note_fields = note_fields.push_back(quote { $name: aztec::note::note_field::NoteField });\n        note_field_constructors = note_field_constructors.push_back(\n            quote { $name: aztec::note::note_field::NoteField { index: $index, nullable: $nullable }},\n        );\n    }\n\n    let note_fields = note_fields.join(quote {,});\n    let note_field_constructors = note_field_constructors.join(quote {,});\n\n    quote {\n        pub struct $note_fields_name {\n            pub $note_fields\n        }\n\n        #[abi(notes)]\n        global $global_export_name: (Field, str<$note_name_str_len>, $note_fields_name) = ($note_type_id, $note_name_as_str, $note_fields_name { $note_field_constructors });\n    }\n}\n\n/// Registers a note struct `note` with the given `note_packed_len`, `note_type_id`, `fixed_fields` and\n/// `nullable_fields` in the global `NOTES` map.\ncomptime fn register_note(\n    note: TypeDefinition,\n    note_packed_len: u32,\n    note_type_id: Field,\n    fixed_fields: [(Quoted, Type, u32)],\n    nullable_fields: [(Quoted, Type, u32)],\n) {\n    let mut fields = &[];\n    for field in fixed_fields {\n        let (name, _, index) = field;\n        fields = fields.push_back((name, index, false));\n    }\n    for field in nullable_fields {\n        let (name, _, index) = field;\n        fields = fields.push_back((name, index, true));\n    }\n\n    NOTES.insert(note.as_type(), (note, note_packed_len, note_type_id, fields));\n}\n\n/// Separates note struct members into fixed and nullable ones. It also stores the index of where each struct member\n/// starts in the serialized note. Note that each struct member can occupy multiple fields (as in Field type).\ncomptime fn index_note_fields(\n    s: TypeDefinition,\n    nullable_fields: [Quoted],\n) -> ([(Quoted, Type, u32)], [(Quoted, Type, u32)]) {\n    let mut indexed_fixed_fields: [(Quoted, Type, u32)] = &[];\n    let mut indexed_nullable_fields = &[];\n    let mut counter: u32 = 0;\n    for field in s.fields_as_written() {\n        let (name, typ) = field;\n        if nullable_fields.all(|field| field != name) {\n            indexed_fixed_fields = indexed_fixed_fields.push_back((name, typ, counter));\n        } else {\n            indexed_nullable_fields = indexed_nullable_fields.push_back((name, typ, counter));\n        }\n        let (serialization_fields, _) = generate_serialize_to_fields(name, typ, true);\n        // Each struct member can occupy multiple fields so we need to increment the counter accordingly\n        counter += serialization_fields.len();\n    }\n    (indexed_fixed_fields, indexed_nullable_fields)\n}\n\n/// Generates the following:\n/// - NoteTypeProperties\n/// - NoteType trait implementation\n/// - NoteHash trait implementation\n/// - Packable implementation\n///\n/// Registers the note in the global `NOTES` map.\n///\n/// For more details on the generated code, see the individual functions.\npub comptime fn note(s: TypeDefinition) -> Quoted {\n    assert_has_owner(s);\n\n    let (indexed_fixed_fields, indexed_nullable_fields) = index_note_fields(s, &[]);\n\n    let note_properties = generate_note_properties(s);\n    let note_type_id = get_next_note_type_id();\n    let note_interface_impl = generate_note_interface(s, note_type_id);\n    let note_hash_impl = generate_note_hash_trait_impl(s);\n    let (packable_impl, note_packed_len) = derive_packable_if_not_implemented_and_get_len(s);\n\n    register_note(\n        s,\n        note_packed_len,\n        note_type_id,\n        indexed_fixed_fields,\n        indexed_nullable_fields,\n    );\n\n    quote {\n        $note_properties\n        $note_interface_impl\n        $note_hash_impl\n        $packable_impl\n    }\n}\n\n/// Generates code for a custom note implementation that requires specialized note hash or nullifier computation.\n///\n/// # Generated Code\n/// - NoteTypeProperties: Defines the structure and properties of note fields\n/// - NoteType trait implementation: Provides the note type ID\n/// - Packable implementation: Enables serialization/deserialization of the note\n///\n/// # Registration\n/// Registers the note in the global `NOTES` map with:\n/// - Note type ID\n/// - Packed length\n/// - Field indices and nullability\n///\n/// # Use Cases\n/// Use this macro when implementing a note that needs custom:\n/// - Note hash computation logic\n/// - Nullifier computation logic\n///\n/// The macro omits generating default NoteHash trait implementation, allowing you to provide your own.\n///\n/// # Example\n/// ```\n/// #[custom_note]\n/// struct CustomNote {\n///     value: Field,\n///     metadata: Field\n/// }\n///\n/// impl NoteHash for CustomNote {\n///     // Custom note hash computation...\n///     fn compute_note_hash(...) -> Field { ... }\n///\n///     // Custom nullifier computation...\n///     fn compute_nullifier(...) -> Field { ... }\n///     fn compute_nullifier_unconstrained(...) -> Field { ... }\n/// }\n/// ```\npub comptime fn custom_note(s: TypeDefinition) -> Quoted {\n    let (packable_impl, note_packed_len) = derive_packable_if_not_implemented_and_get_len(s);\n    let note_type_id = get_next_note_type_id();\n\n    let (indexed_fixed_fields, indexed_nullable_fields) = index_note_fields(s, &[]);\n    register_note(\n        s,\n        note_packed_len,\n        note_type_id,\n        indexed_fixed_fields,\n        indexed_nullable_fields,\n    );\n\n    let note_properties = generate_note_properties(s);\n    let note_interface_impl = generate_note_interface(s, note_type_id);\n\n    quote {\n        $note_properties\n        $note_interface_impl\n        $packable_impl\n    }\n}\n\n/// Asserts that the note has an 'owner' field.\n///\n/// We require notes implemented with #[note] macro macro to have an 'owner' field because our\n/// auto-generated nullifier functions expect it. This requirement is most likely only temporary.\ncomptime fn assert_has_owner(note: TypeDefinition) {\n    let fields = note.fields_as_written();\n    let mut has_owner = false;\n    for i in 0..fields.len() {\n        let (field_name, _) = fields[i];\n        if field_name == quote { owner } {\n            has_owner = true;\n            break;\n        }\n    }\n    assert(\n        has_owner,\n        \"Note must have an 'owner' field. If your notes have no owner, use #[custom_note] insteadof #[note] and implement the NoteHashing trait manually.\",\n    );\n}\n"}}}